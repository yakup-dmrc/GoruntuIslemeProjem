# -*- coding: utf-8 -*-
"""107_DesenKodla (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ai7ef26FLj5s6Yl19MbJ3_Vq7tH8OTkE
"""

#2ss

#kenar kodla 2) Sadece organ bölgesindeki (label yardımıyla) piksellerden tek bir Hog vektörü üret çıktı ve Hdd ye kaydet.

#Kütüphaneler

import numpy as np
import matplotlib.pyplot as plt
import cv2
import math
import numpy as np
from kymatio import Scattering2D
from skimage import measure

#en uygun pipeline uygulandı. L2 Norm + AdaptifMedian + Parlaklık

import cv2
import numpy as np
from matplotlib import pyplot as plt

# Görüntü dosyalarının yolları
image_paths = [
    r"C:\Users\yakup\Desktop\demirci\image (3).jpg",
    r"C:\Users\yakup\Desktop\demirci\image (4).jpg",
    r"C:\Users\yakup\Desktop\demirci\image (5).jpg"
]

label_paths = [
    r"C:\Users\yakup\Desktop\labels\image (3).png",
    r"C:\Users\yakup\Desktop\labels\image (4).png",
    r"C:\Users\yakup\Desktop\labels\image (5).png"
]

# Adım 1: L2 Norm Normalizasyonu
def normalize_image(image):
    norm = np.linalg.norm(image)  # L2 normu hesapla
    normalized_image = image / norm  # Görüntüyü normalleştir
    return (normalized_image * 255).astype(np.uint8)  # [0, 255] aralığına geri çevir

# Adım 2: Adaptif Median Filtresi
def adaptive_median_filter(image, max_kernel_size=7):
    return cv2.medianBlur(image, max_kernel_size)  # Adaptif median filtreleme

# Adım 3: Parlaklık Artırma
def increase_brightness(image, brightness_increase=25):
    return cv2.add(image, np.full_like(image, brightness_increase))

# Etiketli bölgeyi çıkarma işlemi
def process_image(image_path, label_path):
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    label_image = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)  # Etiket (tek kanallı)

    # Adım 1: Normalizasyon
    normalized_image = normalize_image(image)

    # Adım 2: Adaptif Median Filtresi
    adaptive_median_filtered = adaptive_median_filter(normalized_image, max_kernel_size=7)

    # Adım 3: Parlaklık Artırma
    brightened_image = increase_brightness(adaptive_median_filtered, brightness_increase=25)

    # Etiketli bölgeyi çıkarma (Aşındırma işlemi yok)
    masked_image = cv2.bitwise_and(brightened_image, brightened_image, mask=label_image)

    return image, label_image, masked_image

# Görselleri işleme
processed_images = [process_image(image_paths[i], label_paths[i]) for i in range(3)]

# masked_image'leri adlandırma
masked_image, masked_image2, masked_image3 = [masked for _, _, masked in processed_images]

# Sonuçları görselleştirme
plt.figure(figsize=(15, 15))

for i, (original, label, masked) in enumerate(processed_images):
    plt.subplot(3, 3, i*3+1)
    plt.title(f"Orijinal Görüntü {i+1}")
    plt.imshow(original, cmap="gray")
    plt.axis("off")

    plt.subplot(3, 3, i*3+2)
    plt.title(f"Etiket {i+1}")
    plt.imshow(label, cmap="gray")
    plt.axis("off")

    plt.subplot(3, 3, i*3+3)
    plt.title(f"L2 Norm + AdaptifMedian + Parlaklık {i+1}")
    plt.imshow(masked, cmap="gray")
    plt.axis("off")

plt.show()

# masked_image'leri kullanabilirsiniz:
print(f"masked_image Boyutları: {masked_image.shape}")
print(f"masked_image2 Boyutları: {masked_image2.shape}")
print(f"masked_image3 Boyutları: {masked_image3.shape}")

#FONKSİYON KISMI

def Drawing(img, EdgePoints=None, EdgeLines=None, EdgePatchs=None, title=None, circle_radius=10):
    output_img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)

    if EdgePoints is not None:
        for point in EdgePoints:
            x, y = int(point[1]), int(point[0])  # x ve y koordinatları ters çevrilir
            cv2.circle(output_img, (x, y), circle_radius, (0, 0, 255), -1)  # Kırmızı daire

    if EdgeLines is not None:
        for Line in EdgeLines:
            start_point = Line["StartPointYX"]
            stop_point = Line["StopPointYX"]
            cv2.line(output_img, start_point[::-1], stop_point[::-1], color=(255, 255, 0), thickness=2)

    if EdgePatchs is not None:
        # Img üzerine Patch çiz
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 1
        color = (255, 0, 0)
        thickness = 2
        for k, (x, y, PatchSize) in enumerate(EdgePatchs):  # (x, y, PatchSize) bekleniyor
            top_left = (x - PatchSize, y - PatchSize)
            bottom_right = (x + PatchSize, y + PatchSize)
            cv2.rectangle(output_img, top_left, bottom_right, (0, 0, 255), 2)
            cv2.putText(output_img, str(k), (x, y - 10), font, font_scale, color, thickness, cv2.LINE_AA)

    # Görüntü boyutlarına göre figsize hesaplama
    height, width = img.shape[:2]
    aspect_ratio = width / height
    figsize = (15 * aspect_ratio, 15)  # Oranı koruyarak uygun bir ölçekleme

    plt.figure(figsize=figsize)
    plt.imshow(cv2.cvtColor(output_img, cv2.COLOR_BGR2RGB))
    if title is not None:
        plt.title(title, fontsize=30)
    plt.axis('off')
    plt.show()

#EN İYİ GÖRÜNTÜYÜ ÜZERİNE İŞLEYİP, SIFT İLE ANAHTAR NOKTALARINI BULUYORUZ.

import cv2
import numpy as np
from matplotlib import pyplot as plt

# SIFT anahtar noktaları alma fonksiyonu
def extract_sift_keypoints(image):
    sift = cv2.SIFT_create()
    keypoints, descriptors = sift.detectAndCompute(image, None)  # Anahtar noktaları ve descriptor'lar
    return keypoints, descriptors

# Siyah olmayan piksellerin maskesini oluşturma
def get_non_black_pixels(image):
    # Siyah olmayan pikselleri bul
    non_black_mask = image > 0
    return non_black_mask.astype(np.uint8) * 255  # Maskeyi oluştur, siyah olmayan bölgeleri beyaz yap

# Anahtar noktaları çizme fonksiyonu (Kırmızı noktalar olarak göstermek için)
def draw_keypoints(image, keypoints, title=None, circle_radius=10):
    output_image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)  # Renkli hale getir
    for kp in keypoints:
        x, y = int(kp.pt[0]), int(kp.pt[1])  # Anahtar noktanın koordinatlarını al
        cv2.circle(output_image, (x, y), circle_radius, (0, 0, 255), -1)  # Kırmızı noktalar çiz

    plt.figure(figsize=(10, 10))
    plt.imshow(output_image)
    if title:
        plt.title(title)
    plt.axis('off')
    plt.show()

# Görselleri işleme
for i, masked_image in enumerate([masked_image, masked_image2, masked_image3]):
    non_black_mask = get_non_black_pixels(masked_image)  # Siyah olmayan pikselleri al
    keypoints, _ = extract_sift_keypoints(non_black_mask)  # SIFT anahtar noktalarını çıkar
    draw_keypoints(masked_image, keypoints, title=f"(ANAHTAR NOKTA) SONUÇ= {i+1}", circle_radius=10)  # Anahtar noktalarını kırmızı olarak görselleştir

#GÖRSELLERDEN ALINAN PATCHLER ↓

import cv2
import numpy as np
from matplotlib import pyplot as plt

# SIFT anahtar noktaları alma fonksiyonu
def extract_sift_keypoints(image):
    sift = cv2.SIFT_create()
    keypoints, descriptors = sift.detectAndCompute(image, None)  # Anahtar noktaları ve descriptor'lar
    return keypoints, descriptors

# Siyah olmayan piksellerin maskesini oluşturma
def get_non_black_pixels(image):
    # Siyah olmayan pikselleri bul
    non_black_mask = image > 0
    return non_black_mask.astype(np.uint8) * 255  # Maskeyi oluştur, siyah olmayan bölgeleri beyaz yap

# Anahtar noktaları çizme fonksiyonu (Kırmızı noktalar olarak göstermek için)
def draw_keypoints(image, keypoints, title=None, circle_radius=10):
    output_image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)  # Renkli hale getir
    for kp in keypoints:
        x, y = int(kp.pt[0]), int(kp.pt[1])  # Anahtar noktanın koordinatlarını al
        cv2.circle(output_image, (x, y), circle_radius, (0, 0, 255), -1)  # Kırmızı noktalar çiz

    plt.figure(figsize=(10, 10))
    plt.imshow(output_image)
    if title:
        plt.title(title)
    plt.axis('off')
    plt.show()

# Patch almak için fonksiyon
def GetPatchsFromNonBlackPixels(img, NonBlackPixels, PatchSize=11, draw=True):
    """
    Siyah olmayan piksellerden yamalar alır.
    Args:
        img: Giriş görüntüsü (tek kanallı).
        NonBlackPixels: Siyah olmayan piksellerin (y, x) koordinatları.
        PatchSize: Yamaların boyutu (2 * PatchSize + 1, 2 * PatchSize + 1).
        draw: Yamaları görselleştirmek isteyip istemediğiniz.
    Returns:
        Patchs: Siyah olmayan piksellerden alınan yamalar.
        PatchsInfo: Yamaların konum ve boyut bilgileri.
    """
    Patchs = []
    PatchsInfo = []
    rows, cols = img.shape

    for y, x in NonBlackPixels:
        # Yamayı sınır kontrolü yaparak al
        y_start, y_end = y - PatchSize, y + PatchSize + 1
        x_start, x_end = x - PatchSize, x + PatchSize + 1

        if y_start < 0 or y_end > rows or x_start < 0 or x_end > cols:
            # Yama görüntü sınırlarının dışında, atla
            continue

        Patch = img[y_start:y_end, x_start:x_end]
        Patchs.append(Patch)
        PatchsInfo.append((x, y, PatchSize))

    if draw:
        Drawing(img, EdgePoints=NonBlackPixels, EdgePatchs=PatchsInfo)

    return Patchs, PatchsInfo

# Görselleri işleme
for i, masked_image in enumerate([masked_image, masked_image2, masked_image3]):
    non_black_mask = get_non_black_pixels(masked_image)  # Siyah olmayan pikselleri al
    keypoints, _ = extract_sift_keypoints(non_black_mask)  # SIFT anahtar noktalarını çıkar
    img_Patchs, img_PatchsInfo = GetPatchsFromNonBlackPixels(masked_image, [(int(kp.pt[1]), int(kp.pt[0])) for kp in keypoints], PatchSize=30, draw=True)  # Patch'leri al ve çiz

#ŞİMDİ DE BU PATCH'LER HOG İLE KODLANIYOR. TEK DOSYA OLARAK KAYDEDİLİYOR.

def save_hog_features_with_coords(patches, patch_info, output_file):
    # Örnek bir fonksiyon implementasyonu
    # HOG özelliklerini ve koordinat bilgilerini kaydetmek için kod yazabilirsiniz.
    with open(output_file, 'w') as f:
        for patch, info in zip(patches, patch_info):
            # Burada patch ve info'yu uygun formatta kaydedebilirsiniz
            f.write(f'{info}: {patch}\n')

output_file_with_coords = "sift_hog.txt"
def GetPatchsFromNonBlackPixels(img, NonBlackPixels, PatchSize=11, draw=True):
    """
    Siyah olmayan piksellerden yamalar alır.
    Args:
        img: Giriş görüntüsü (tek kanallı).
        NonBlackPixels: Siyah olmayan piksellerin (y, x) koordinatları.
        PatchSize: Yamaların boyutu (2 * PatchSize + 1, 2 * PatchSize + 1).
        draw: Yamaları görselleştirmek isteyip istemediğiniz.
    Returns:
        Patchs: Siyah olmayan piksellerden alınan yamalar.
        PatchsInfo: Yamaların konum ve boyut bilgileri.
    """
    Patchs = []
    PatchsInfo = []
    rows, cols = img.shape

    for y, x in NonBlackPixels:
        # Yamayı sınır kontrolü yaparak al
        y_start, y_end = int(y - PatchSize), int(y + PatchSize + 1)
        x_start, x_end = int(x - PatchSize), int(x + PatchSize + 1)

        if y_start < 0 or y_end > rows or x_start < 0 or x_end > cols:
            # Yama görüntü sınırlarının dışında, atla
            continue

        Patch = img[y_start:y_end, x_start:x_end]
        Patchs.append(Patch)
        PatchsInfo.append((x, y, PatchSize))

    if draw:
        Drawing(img, EdgePoints=NonBlackPixels, EdgePatchs=PatchsInfo)

    return Patchs, PatchsInfo

# Görselleri işleme ve HOG özelliklerini kaydetme
all_patches = []
all_patch_info = []

for img, img_info in zip([masked_image, masked_image2, masked_image3], [img_PatchsInfo, img_PatchsInfo, img_PatchsInfo]):
    # Siyah olmayan piksellerden patch'ler alınacak
    patches, patch_info = GetPatchsFromNonBlackPixels(img, [(kp.pt[1], kp.pt[0]) for kp in extract_sift_keypoints(img)[0]], PatchSize=30, draw=False)
    all_patches.extend(patches)
    all_patch_info.extend(patch_info)

save_hog_features_with_coords(all_patches, all_patch_info, output_file_with_coords)

#EĞİTİM BİTTİ, ŞİMDİ TEST AŞAMASINA GEÇİYORUZ

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Görüntü ve etiketleri yükleyen fonksiyon
def GetImageLabel(imgStr, labelStr, draw=False):
    img = cv2.imread(imgStr, cv2.IMREAD_GRAYSCALE)
    label = cv2.imread(labelStr, cv2.IMREAD_GRAYSCALE)
    if draw:
        # Görüntü ve etiketleri yan yana çiz
        plt.figure(figsize=(12, 6))  # Şekil boyutunu ayarla
        plt.subplot(1, 2, 1)  # 1 satır, 2 sütun, ilk eksen
        plt.imshow(img, cmap='gray')  # img görüntüsünü göster
        plt.title(imgStr)  # Başlık
        plt.axis('off')  # Eksenleri kapat

        plt.subplot(1, 2, 2)  # 1 satır, 2 sütun, ikinci eksen
        plt.imshow(label, cmap='gray')  # label görüntüsünü göster
        plt.title(labelStr)  # Başlık
        plt.axis('off')  # Eksenleri kapat

        plt.tight_layout()
        plt.show()  # Şekli göster
    return img, label

# Görüntü dosyalarının yolları
image_paths = [
    r"C:\Users\yakup\Desktop\demirci\image (6).jpg",
    r"C:\Users\yakup\Desktop\demirci\image (7).jpg",
    r"C:\Users\yakup\Desktop\demirci\image (8).jpg",
    r"C:\Users\yakup\Desktop\demirci\image (9).jpg",
    r"C:\Users\yakup\Desktop\demirci\image (10).jpg"
]

label_paths = [
    r"C:\Users\yakup\Desktop\labels\image (6).png",
    r"C:\Users\yakup\Desktop\labels\image (7).png",
    r"C:\Users\yakup\Desktop\labels\image (8).png",
    r"C:\Users\yakup\Desktop\labels\image (9).png",
    r"C:\Users\yakup\Desktop\labels\image (10).png"
]

# Adımlar
def process_image(image_path, label_path):
    # Görüntüyü ve etiketi yükle
    img, label = GetImageLabel(image_path, label_path, draw=False)

    # I1 Norm Normalizasyonu
    normalized_image = img / 255.0  # Piksel değerlerini [0, 1] aralığına getir
    normalized_image = (normalized_image * 255).astype(np.uint8)  # [0, 255] aralığına geri çevir

    #  Keskinleştirme (Unsharp Masking)
    def mean_filter(image, kernel_size=5):
        return cv2.blur(image, (kernel_size, kernel_size))  # Ortalama filtre uygula

    mean_filtered = mean_filter(normalized_image, kernel_size=5)

    # Ortalama (Mean) Filtreleme
    brightness_increase = 20  # Parlaklık artırma miktarı
    brightened_image = cv2.add(mean_filtered, np.full_like(mean_filtered, brightness_increase))

    # Parlaklık Artırma
    def sharpen_image(image):
        blurred = cv2.GaussianBlur(image, (5, 5), 1.5)  # Gaussian blur uygula
        sharpened = cv2.addWeighted(image, 1.5, blurred, -0.5, 0)  # Keskinleştirme işlemi
        return sharpened

    sharpened_image = sharpen_image(brightened_image)

    return sharpened_image, label  # Hem işlenmiş görüntü hem de label döndürülüyor

# İşlenmiş görüntüleri ve etiketleri saklamak için listeler
sharpened_images = []
labels = []

# Görüntüleri işleme ve son hali yazdırma
for i, (image_path, label_path) in enumerate(zip(image_paths, label_paths)):
    sharpened_image, label = process_image(image_path, label_path)
    sharpened_images.append(sharpened_image)  # İşlenmiş görüntüyü listeye ekle
    labels.append(label)  # Etiketi listeye ekle

    # Görüntüleri ve etiketleri yan yana çiz
    plt.figure(figsize=(12, 6))
    plt.subplot(1, 2, 1)
    plt.imshow(sharpened_image, cmap='gray')
    plt.title(f"İşlenmiş Görüntü ({i+6})")
    plt.axis('off')  # Eksenleri kapat

    plt.subplot(1, 2, 2)
    plt.imshow(label, cmap='gray')
    plt.title(f"Label Görüntüsü ({i+6})")
    plt.axis('off')  # Eksenleri kapat

    plt.tight_layout()
    plt.show()



#TESTLERDEN NE KADAR HOG'TAN SONRA PATCH ALINDI VE KAYDEDİLİĞİ, TUTULDUĞU DOSYANIN BELİRLENDİĞİ KISIM

# Önceden tanımlı Drawing fonksiyonu
def Drawing(img, EdgePoints, circle_radius=10):
    """
    Görüntü üzerine belirtilen noktaları çizen fonksiyon
    """
    img_copy = img.copy()
    for point in EdgePoints:
        cv2.circle(img_copy, tuple(point[::-1]), circle_radius, (0, 0, 255), -1)  # Kırmızı nokta çizer
    plt.imshow(img_copy, cmap='gray')
    plt.axis('off')  # Eksenleri kapat
    plt.show()

# Siyah olmayan pikselleri alan fonksiyon
def GetNonBlackPixels(img, sparsity_factor=1, draw=False, circle_radius=10):
    """
    Siyah olmayan pikselleri alır, görüntüyü yukarı ve aşağı bölgelere ayırarak farklı eşik değerleri uygular.
    Args:
        img: Giriş görüntüsü (tek kanallı).
        sparsity_factor: Piksel seyrekleştirme faktörü.
        draw: Piksel noktalarını çizmek isteyip istemediğiniz.
        circle_radius: Çizim sırasında noktaların yarıçapı.
    Returns:
        pixels: Siyah olmayan piksellerin (y, x) koordinatları.
    """
    # Görüntünün boyutlarını al
    height, width = img.shape

    # Görüntüyü yukarı ve aşağı olarak iki bölgeye ayır
    top_half = img[:height // 2, :]
    bottom_half = img[height // 2:, :]

    # Yukarı bölge için eşikleme
    y_top, x_top = np.where(top_half > 210)
    pixels_top = np.vstack((y_top, x_top)).T

    # Aşağı bölge için eşikleme
    y_bottom, x_bottom = np.where(bottom_half > 140)
    y_bottom += height // 2  # Aşağı bölgenin y koordinatını düzelt
    pixels_bottom = np.vstack((y_bottom, x_bottom)).T

    # Yukarı ve aşağı bölgelerin piksellerini birleştir
    pixels = np.vstack((pixels_top, pixels_bottom))

    # Sparsity factor ile seyrekleştirme
    if sparsity_factor > 1:
        pixels = pixels[::sparsity_factor]

    # Çizim yapmak istenirse
    if draw:
        Drawing(img, EdgePoints=pixels, circle_radius=circle_radius)

    return pixels

# Her bir işlenmiş görüntü için siyah olmayan pikselleri al ve çiz
for i, img in enumerate(sharpened_images, start=6):
    # Siyah olmayan pikselleri al
    test_img_Points = GetNonBlackPixels(img, sparsity_factor=300, circle_radius=10, draw=True)

import cv2
import numpy as np
import os
from skimage.feature import hog

# HOG özelliklerini çıkaran ve kaydeden fonksiyon
def save_hog_features_with_coords(patches, patch_info, output_file):
    hog_features = []
    coords = []

    for patch, info in zip(patches, patch_info):
        # HOG özelliğini çıkar
        fd, _ = hog(patch, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)
        hog_features.append(fd)
        coords.append(info)

    # Özellikleri ve koordinatları dosyaya kaydet
    np.savez_compressed(output_file, hog_features=hog_features, coords=coords)

# Görüntüler ve isimleri
sharpened_images = sharpened_images
image_names = ['test_image6', 'test_image7', 'test_image8', 'test_image9', 'test_image10']
output_directory = r"C:\Users\yakup\Desktop\sifthogdosyasi"
reference_output_path = r"C:\Users\yakup\Desktop\sifthogdosyasi\hog_features_with_coords.npz"

# Referans HOG vektörü için bir değişken
reference_hog = None

# Her bir görüntü için patch'leri al ve HOG özelliklerini kaydet
for img, img_name in zip(sharpened_images, image_names):
    # Siyah olmayan pikselleri al
    non_black_pixels = GetNonBlackPixels(img, sparsity_factor=300, circle_radius=10, draw=False)  # Noktaları al

    # Patch'leri al
    patches, patch_info = GetPatchsFromNonBlackPixels(img, non_black_pixels, PatchSize=30, draw=False)

    # HOG özelliklerini ve koordinatlarını kaydet
    output_file = os.path.join(output_directory, f"{img_name}_hog_features_with_coords.npz")
    save_hog_features_with_coords(patches, patch_info, output_file)

    # Referans HOG vektörünü seç (ilk görüntünün ilk patch'inden alınacak)
    if reference_hog is None and patches:
        reference_patch = patches[0]
        reference_hog, _ = hog(reference_patch, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)

    # Başarı mesajı
    print(f"Kayıt başarılı: {output_file}")

# Referans HOG vektörünü kaydet
if reference_hog is not None:
    np.savez_compressed(reference_output_path, reference_hog=reference_hog)
    print(f"Referans HOG kaydedildi: {reference_output_path}")
else:
    print("Referans HOG vektörü kaydedilemedi. Patch bulunamadı!")

patches_dict = {}  # Her bir görüntü için patch'leri saklayacak bir sözlük

# Görüntülerin listesi ve isimleri
# Burada işlenmiş görüntüleri kullanıyoruz
sharpened_images = sharpened_images  # İşlenmiş görüntüler
image_names = ['test_sharpened_image6', 'test_sharpened_image7', 'test_sharpened_image8', 'test_sharpened_image9', 'test_sharpened_image10']

# Her bir görüntüde siyah olmayan pikselleri al ve patch'leri al
for img, img_name in zip(sharpened_images, image_names):
    # Siyah olmayan pikselleri al
    non_black_pixels = GetNonBlackPixels(img, sparsity_factor=300, circle_radius=10, draw=False)  # Noktaları al

    # Patch'leri al
    patches, patch_info = GetPatchsFromNonBlackPixels(img, non_black_pixels, PatchSize=30, draw=False)

    # Görüntü ismi ile patch'leri sözlüğe ekle
    patches_dict[img_name] = {
        'patches': patches,
        'patch_info': patch_info
    }

# Her bir görüntünün patch'lerine erişmek için
for img_name, patch_data in patches_dict.items():
    print(f"{img_name} için toplam patch sayısı: {len(patch_data['patches'])}")

#5 TEST GÖRSELİNİN PACHLERİ HOG İLE KODLANARAK KAYIT EDİLİYOR
#HER GÖRSELİN HOG KODUNU AYRI AYRI KAYDETTİK.

import numpy as np
import cv2
import matplotlib.pyplot as plt
from scipy.spatial.distance import cdist

# Optimize edilmiş çapraz korelasyon fonksiyonu
def compute_cross_correlation_optimized(vectors1, vectors2):
    return 1 - cdist(vectors1, vectors2, metric='correlation')  # Korelasyon mesafesi

# HDD'deki referans HOG vektörlerini yükleme
stored_hog_vectors = np.load(r"C:\Users\yakup\OneDrive\Desktop\desen_2\hog_features_with_coords.npz")['features']

# İşlenecek test görüntüleri, etiketler ve HOG dosyalarının yolları
test_image_paths = [
    r"C:\Users\yakup\OneDrive\Desktop\image_demirci\image (6).jpg",
    r"C:\Users\yakup\OneDrive\Desktop\image_demirci\image (7).jpg",
    r"C:\Users\yakup\OneDrive\Desktop\image_demirci\image (8).jpg",
    r"C:\Users\yakup\OneDrive\Desktop\image_demirci\image (9).jpg",
    r"C:\Users\yakup\OneDrive\Desktop\image_demirci\image (10).jpg"
]

label_image_paths = [
    r"C:\Users\yakup\OneDrive\Desktop\label_demirci\image (6).png",
    r"C:\Users\yakup\OneDrive\Desktop\label_demirci\image (7).png",
    r"C:\Users\yakup\OneDrive\Desktop\label_demirci\image (8).png",
    r"C:\Users\yakup\OneDrive\Desktop\label_demirci\image (9).png",
    r"C:\Users\yakup\OneDrive\Desktop\label_demirci\image (10).png"
]

hog_files = [
    r"C:\Users\yakup\OneDrive\Desktop\desen_2\test_image6_hog_features_with_coords.npz",
    r"C:\Users\yakup\OneDrive\Desktop\desen_2\test_image7_hog_features_with_coords.npz",
    r"C:\Users\yakup\OneDrive\Desktop\desen_2\test_image8_hog_features_with_coords.npz",
    r"C:\Users\yakup\OneDrive\Desktop\desen_2\test_image9_hog_features_with_coords.npz",
    r"C:\Users\yakup\OneDrive\Desktop\desen_2\test_image10_hog_features_with_coords.npz"
]

# Görüntü işleme ve korelasyon hesaplama
plt.figure(figsize=(15, len(test_image_paths) * 5))
for idx, (test_image_path, label_image_path, hog_file) in enumerate(zip(test_image_paths, label_image_paths, hog_files)):
    # Test HOG vektörlerini ve koordinatlarını yükleme
    hog_data = np.load(hog_file)
    test_hog_vectors = hog_data['hog_features']
    test_coords = hog_data['coords']

    # Test görüntüsünü yükleme
    test_image = cv2.imread(test_image_path)
    output_img = np.zeros_like(test_image)  # Siyah bir görüntü oluşturma

    # Etiket görüntüsünü yükleme
    label_image = cv2.imread(label_image_path)

    # Çapraz korelasyonu hızlı hesaplama
    correlations_matrix = compute_cross_correlation_optimized(test_hog_vectors, stored_hog_vectors)
    threshold = 0.30
    high_correlation_indices = np.argwhere(correlations_matrix >= threshold)

    # Yüksek korelasyon eşleşmelerini işleme
    matching_coords_count = 0
    for test_idx, stored_idx in high_correlation_indices:
        coord = test_coords[test_idx]
        x, y = int(coord[0]), int(coord[1])
        cv2.circle(output_img, (x, y), 12, (255, 255, 255), -1)
        matching_coords_count += 1

    # Görüntü adını dosya yolundan çıkarma
    image_name = test_image_path.split("\\")[-1]

    # Orijinal görüntü, etiket ve çıktı görselleştirme
    plt.subplot(len(test_image_paths), 3, idx * 3 + 1)
    plt.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))
    plt.title(f"Original - {image_name}")
    plt.axis('off')

    plt.subplot(len(test_image_paths), 3, idx * 3 + 2)
    plt.imshow(cv2.cvtColor(label_image, cv2.COLOR_BGR2RGB))
    plt.title(f"Label - {image_name}")
    plt.axis('off')

    plt.subplot(len(test_image_paths), 3, idx * 3 + 3)
    plt.imshow(cv2.cvtColor(output_img, cv2.COLOR_BGR2RGB))
    plt.title(f"Output_test_img{idx + 6} (Eşleşme Sayısı: {matching_coords_count})")
    plt.axis('off')

plt.tight_layout()
plt.show()

# Dosyanın içeriğini kontrol etme
hog_data = np.load(r"C:\Users\yakup\Desktop\sifthogdosyasi\test_image6_hog_features_with_coords.npz")
print(hog_data.files)  # Dosyanın içinde hangi anahtarların bulunduğunu gösterir

npz_file = np.load(r"C:\Users\yakup\Desktop\sifthogdosyasi\hog_features_with_coords.npz")
print(npz_file.files)  # Dosyadaki anahtarları yazdırır

# Her iki vektörü de aynı boyutta olacak şekilde ayarlayın
test_hog_vectors_resized = np.resize(test_hog_vectors, stored_hog_vectors.shape)

#ŞİMDİ BU HOG DOSYALARINI AYRI AYRI CROSS KORELASYON İŞLEMİ İLE TEKKARŞILAŞTIRALIM

import matplotlib.pyplot as plt

# IoU hesaplama fonksiyonu
def calculate_iou(predicted_image, label_image):
    # İkili görüntüye dönüştürme (thresholding)
    _, pred_binary = cv2.threshold(cv2.cvtColor(predicted_image, cv2.COLOR_BGR2GRAY), 127, 255, cv2.THRESH_BINARY)
    _, label_binary = cv2.threshold(cv2.cvtColor(label_image, cv2.COLOR_BGR2GRAY), 127, 255, cv2.THRESH_BINARY)

    # Kesişim ve birleşim
    intersection = np.logical_and(pred_binary > 0, label_binary > 0).sum()
    union = np.logical_or(pred_binary > 0, label_binary > 0).sum()

    # IoU hesaplama
    iou = intersection / union if union != 0 else 0
    return iou

# IoU hesaplama ve çıktı
ious = []
for idx, (test_image_path, label_image_path, hog_file) in enumerate(zip(test_image_paths, label_image_paths, hog_files)):
    # Çıkış görüntüsü
    output_img = np.zeros_like(cv2.imread(test_image_path))
    hog_data = np.load(hog_file)
    test_hog_vectors = hog_data['hog_features']
    test_coords = hog_data['coords']

    correlations_matrix = compute_cross_correlation_optimized(test_hog_vectors, stored_hog_vectors)
    high_correlation_indices = np.argwhere(correlations_matrix >= threshold)

    for test_idx, _ in high_correlation_indices:
        coord = test_coords[test_idx]
        x, y = int(coord[0]), int(coord[1])
        cv2.circle(output_img, (x, y), 12, (255, 255, 255), -1)

    # Etiket görüntüsünü yükleme
    label_image = cv2.imread(label_image_path)

    # IoU hesaplama
    iou = calculate_iou(output_img, label_image)
    ious.append(iou)
    print(f"Test Image {idx + 6}: IoU = {iou:.4f}")

# Ortalama IoU
mean_iou = np.mean(ious)
print(f"\n(Görüntü + Label + Hog + Cross Kolerasyon)Ortalama IoU: {mean_iou:.4f}")

# IoU Grafik Çıktısı
image_names = [f"Image {i+6}" for i in range(len(ious))]
plt.figure(figsize=(4, 6))
plt.bar(image_names, ious, color='skyblue', edgecolor='black')
plt.axhline(mean_iou, color='red', linestyle='--', label=f'Ortalama IoU = {mean_iou:.4f}')
plt.xlabel('Görüntüler')
plt.ylabel('IoU Değeri')
plt.title('2 ) IoU Değerleri ve Ortalama IoU')
plt.legend()
plt.tight_layout()
plt.show()

#LABEL YARDIMIYLA ORGAN + HOG + HIZLANDIRILMIŞ CROSS KOLERASYON + IoU HESAPLAMA
#(HIZLANDIRILMIŞ CROSS KOLERASYON İLE TEK HOG VEKTÖRÜNE YAKIN HIZDA İŞLEM BAŞARISI YAKALADIK)
#PROJE SONUNDA GÖRÜLDÜĞÜ GİBİ +4 MİLYON EŞLEŞMELER YAKALADIK

#MODELLEME AŞAMASI

import numpy as np
import matplotlib.pyplot as plt
import cv2
import math
import numpy as np
from kymatio import Scattering2D
from skimage import measure

#3 ADET TEST GÖRSELİ VE LABELLERİ ÖN İŞLEMDEN GEÇİRİLEREK GÖRSELLEŞTİRİLİYOR

import cv2
import numpy as np
from matplotlib import pyplot as plt

# Görüntü dosyalarının yolları
image_paths = [
    r"C:\Users\yakup\Desktop\demirci\image (2).jpg",
    r"C:\Users\yakup\Desktop\demirci\image (4).jpg",
    r"C:\Users\yakup\Desktop\demirci\image (6).jpg"
]

label_paths = [
    r"C:\Users\yakup\Desktop\labels\image (2).png",
    r"C:\Users\yakup\Desktop\labels\image (4).png",
    r"C:\Users\yakup\Desktop\labels\image (6).png"
]

# Adım 1: L2 Norm Normalizasyonu
def normalize_image(image):
    norm = np.linalg.norm(image)  # L2 normu hesapla
    normalized_image = image / norm  # Görüntüyü normalleştir
    return (normalized_image * 255).astype(np.uint8)  # [0, 255] aralığına geri çevir

# Adım 2: Adaptif Median Filtresi
def adaptive_median_filter(image, max_kernel_size=7):
    return cv2.medianBlur(image, max_kernel_size)  # Adaptif median filtreleme

# Adım 3: Parlaklık Artırma
def increase_brightness(image, brightness_increase=25):
    return cv2.add(image, np.full_like(image, brightness_increase))

# Etiketli bölgeyi çıkarma işlemi
def process_image(image_path, label_path):
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    label_image = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)  # Etiket (tek kanallı)

    # Adım 1: Normalizasyon
    normalized_image = normalize_image(image)

    # Adım 2: Adaptif Median Filtresi
    adaptive_median_filtered = adaptive_median_filter(normalized_image, max_kernel_size=7)

    # Adım 3: Parlaklık Artırma
    brightened_image = increase_brightness(adaptive_median_filtered, brightness_increase=25)

    # Etiketli bölgeyi çıkarma (Aşındırma işlemi yok)
    masked_image = cv2.bitwise_and(brightened_image, brightened_image, mask=label_image)

    return image, label_image, masked_image

# Görselleri işleme
processed_images = [process_image(image_paths[i], label_paths[i]) for i in range(3)]

# masked_image'leri adlandırma
masked_image, masked_image2, masked_image3 = [masked for _, _, masked in processed_images]

# Sonuçları görselleştirme
plt.figure(figsize=(15, 15))

for i, (original, label, masked) in enumerate(processed_images):
    plt.subplot(3, 3, i*3+1)
    plt.title(f"Orijinal Görüntü {i+1}")
    plt.imshow(original, cmap="gray")
    plt.axis("off")

    plt.subplot(3, 3, i*3+2)
    plt.title(f"Etiket {i+1}")
    plt.imshow(label, cmap="gray")
    plt.axis("off")

    plt.subplot(3, 3, i*3+3)
    plt.title(f"L2 Norm + AdaptifMedian + Parlaklık {i+1}")
    plt.imshow(masked, cmap="gray")
    plt.axis("off")

plt.show()

# masked_image'leri kullanabilirsiniz:
print(f"masked_image Boyutları: {masked_image.shape}")
print(f"masked_image2 Boyutları: {masked_image2.shape}")
print(f"masked_image3 Boyutları: {masked_image3.shape}")

#YAZDIRMA FONKSİYONU

def Drawing(img, EdgePoints=None, EdgeLines=None, EdgePatchs=None, title=None, circle_radius=10):
    output_img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)

    if EdgePoints is not None:
        for point in EdgePoints:
            x, y = int(point[1]), int(point[0])  # x ve y koordinatları ters çevrilir
            cv2.circle(output_img, (x, y), circle_radius, (0, 0, 255), -1)  # Kırmızı daire

    if EdgeLines is not None:
        for Line in EdgeLines:
            start_point = Line["StartPointYX"]
            stop_point = Line["StopPointYX"]
            cv2.line(output_img, start_point[::-1], stop_point[::-1], color=(255, 255, 0), thickness=2)

    if EdgePatchs is not None:
        # Img üzerine Patch çiz
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 1
        color = (255, 0, 0)
        thickness = 2
        for k, (x, y, PatchSize) in enumerate(EdgePatchs):  # (x, y, PatchSize) bekleniyor
            top_left = (x - PatchSize, y - PatchSize)
            bottom_right = (x + PatchSize, y + PatchSize)
            cv2.rectangle(output_img, top_left, bottom_right, (0, 0, 255), 2)
            cv2.putText(output_img, str(k), (x, y - 10), font, font_scale, color, thickness, cv2.LINE_AA)

    # Görüntü boyutlarına göre figsize hesaplama
    height, width = img.shape[:2]
    aspect_ratio = width / height
    figsize = (15 * aspect_ratio, 15)  # Oranı koruyarak uygun bir ölçekleme

    plt.figure(figsize=figsize)
    plt.imshow(cv2.cvtColor(output_img, cv2.COLOR_BGR2RGB))
    if title is not None:
        plt.title(title, fontsize=30)
    plt.axis('off')
    plt.show()

#GÖRSELDEN PİKSELLER ALINMASI (SEYRELTİLEREK)

import matplotlib.pyplot as plt
import numpy as np

def GetNonBlackPixels(img, sparsity_factor=1, draw=False, circle_radius=10):
    """
    Siyah olmayan pikselleri alır.
    Args:
        img: Giriş görüntüsü (tek kanallı).
        sparsity_factor: Piksel seyrekleştirme faktörü.
        draw: Piksel noktalarını çizmek isteyip istemediğiniz.
        circle_radius: Çizim sırasında noktaların yarıçapı.
    Returns:
        pixels: Siyah olmayan piksellerin (y, x) koordinatları.
    """
    # Siyah olmayan piksellerin koordinatlarını al
    y, x = np.where(img > 0)
    pixels = np.vstack((y, x)).T  # (y, x) -> [[y1, x1], [y2, x2], ...]

    # Sparsity factor ile seyrekleştirme
    if sparsity_factor > 1:
        pixels = pixels[::sparsity_factor]

    # Çizim yapmak istenirse
    if draw:
        Drawing(img, EdgePoints=pixels, circle_radius=circle_radius)

    return pixels

# Görselleri ve isimlerini listeleyin
masked_images = [masked_image, masked_image2, masked_image3]
image_titles = ["Masked Image 1", "Masked Image 2", "Masked Image 3"]

# Noktalar işaretlenmiş görselleri tutmak için
point_masked_images1 = masked_image.copy()
point_masked_images2 = masked_image2.copy()
point_masked_images3 = masked_image3.copy()

# Görselleştirme
plt.figure(figsize=(15, 5))

# Her bir görüntü için noktaları işaretleyin
for i, masked_image in enumerate(masked_images):
    # Siyah olmayan pikselleri al ve noktaları çiz
    if i == 0:
        img_Points1 = GetNonBlackPixels(point_masked_images1, sparsity_factor=300, circle_radius=10, draw=True)
    elif i == 1:
        img_Points2 = GetNonBlackPixels(point_masked_images2, sparsity_factor=300, circle_radius=10, draw=True)
    elif i == 2:
        img_Points3 = GetNonBlackPixels(point_masked_images3, sparsity_factor=300, circle_radius=10, draw=True)

    # Görselleştirme
    plt.subplot(1, 3, i + 1)
    plt.imshow(masked_image, cmap='gray')
    plt.title(f"{image_titles[i]} - Noktalar")
    plt.axis('off')

plt.tight_layout()
plt.show()

#BELİRLENEN PİKSELLERDEN PACH ALINMASI

def GetPatchsFromNonBlackPixels(img, NonBlackPixels, PatchSize=11, draw=True):
    """
    Siyah olmayan piksellerden yamalar alır.
    Args:
        img: Giriş görüntüsü (tek kanallı).
        NonBlackPixels: Siyah olmayan piksellerin (y, x) koordinatları.
        PatchSize: Yamaların boyutu (2 * PatchSize + 1, 2 * PatchSize + 1).
        draw: Yamaları görselleştirmek isteyip istemediğiniz.
    Returns:
        Patchs: Siyah olmayan piksellerden alınan yamalar.
        PatchsInfo: Yamaların konum ve boyut bilgileri.
    """
    Patchs = []
    PatchsInfo = []
    rows, cols = img.shape

    for y, x in NonBlackPixels:
        # Yamayı sınır kontrolü yaparak al
        y_start, y_end = y - PatchSize, y + PatchSize + 1
        x_start, x_end = x - PatchSize, x + PatchSize + 1

        if y_start < 0 or y_end > rows or x_start < 0 or x_end > cols:
            # Yama görüntü sınırlarının dışında, atla
            continue

        Patch = img[y_start:y_end, x_start:x_end]
        Patchs.append(Patch)
        PatchsInfo.append((x, y, PatchSize))

    if draw:
        Drawing(img, EdgePoints=NonBlackPixels, EdgePatchs=PatchsInfo)

    return Patchs, PatchsInfo

# GetPatchsFromNonBlackPixels fonksiyonunu kullanarak her bir görselde patch'ler alalım
img_Patchs1, img_PatchsInfo1 = GetPatchsFromNonBlackPixels(point_masked_images1, img_Points1, PatchSize=30, draw=True)
img_Patchs2, img_PatchsInfo2 = GetPatchsFromNonBlackPixels(point_masked_images2, img_Points2, PatchSize=30, draw=True)
img_Patchs3, img_PatchsInfo3 = GetPatchsFromNonBlackPixels(point_masked_images3, img_Points3, PatchSize=30, draw=True)

# Örnek olarak, her bir görselde alınan patch'leri görmek için:
print(f"Image 1 Patch Sayısı: {len(img_Patchs1)}")
print(f"Image 2 Patch Sayısı: {len(img_Patchs2)}")
print(f"Image 3 Patch Sayısı: {len(img_Patchs3)}")

# Patch'leri görselleştirme
plt.figure(figsize=(15, 5))

# Her bir görsel için yamaları görselleştir
for i, (img_Patchs, img_PatchsInfo) in enumerate(zip([img_Patchs1, img_Patchs2, img_Patchs3],
                                                    [img_PatchsInfo1, img_PatchsInfo2, img_PatchsInfo3])):
    plt.subplot(1, 3, i + 1)
    plt.imshow(img_Patchs[0], cmap='gray')  # İlk yamayı görüntüleyelim
    plt.title(f"Image {i + 1} - Patch")
    plt.axis('off')

plt.tight_layout()
plt.show()

#PACHLERİN HOG İLE KODLANIP TEK DOSYA OLARAK KAYDEDİLMESİ. (Toplam 9176 patch HOG ile kodlandı.)

import cv2
import numpy as np
import os

# HOG özelliklerini hesaplayan fonksiyon
def compute_hog_features(image, cell_size=(8, 8), block_size=(2, 2), nbins=9):
    """
    Verilen görüntü için HOG özelliklerini hesaplar.
    """
    hog = cv2.HOGDescriptor(
        _winSize=(image.shape[1] // cell_size[1] * cell_size[1],
                  image.shape[0] // cell_size[0] * cell_size[0]),
        _blockSize=(block_size[1] * cell_size[1], block_size[0] * cell_size[0]),
        _blockStride=(cell_size[1], cell_size[0]),
        _cellSize=(cell_size[1], cell_size[0]),
        _nbins=nbins
    )
    features = hog.compute(image)
    return features.flatten()

# HOG özelliklerini ve koordinatlarını kaydeden fonksiyon
def save_hog_features_with_coords(patches, patch_info, output_path, cell_size=(8, 8), block_size=(2, 2), nbins=9):
    """
    Patch'lerin HOG özelliklerini ve koordinatlarını HDD'ye kaydeder.
    """
    all_features = []
    all_coords = []

    for i, (patch, info) in enumerate(zip(patches, patch_info)):
        features = compute_hog_features(patch, cell_size, block_size, nbins)
        all_features.append(features)
        all_coords.append(info)

    all_features = np.array(all_features)
    all_coords = np.array(all_coords)

    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    np.savez(output_path, features=all_features, coords=all_coords)
    print(f"HOG özellikleri ve koordinatlar kaydedildi: {output_path}")

# GetPatchsFromNonBlackPixels fonksiyonunu kullanarak her bir görselde patch'ler alalım
img_Patchs1, img_PatchsInfo1 = GetPatchsFromNonBlackPixels(point_masked_images1, img_Points1, PatchSize=30, draw=True)
img_Patchs2, img_PatchsInfo2 = GetPatchsFromNonBlackPixels(point_masked_images2, img_Points2, PatchSize=30, draw=True)
img_Patchs3, img_PatchsInfo3 = GetPatchsFromNonBlackPixels(point_masked_images3, img_Points3, PatchSize=30, draw=True)

# Tüm patch'leri ve koordinatları birleştir
all_patches = img_Patchs1 + img_Patchs2 + img_Patchs3
all_patch_info = img_PatchsInfo1 + img_PatchsInfo2 + img_PatchsInfo3

# HOG özelliklerini kaydetme
output_file_with_coords = r"C:\Users\yakup\Desktop\sifthogdosyasi\hog_features_with_coords.npz"
save_hog_features_with_coords(all_patches, all_patch_info, output_file_with_coords)

# Sonuç olarak toplam kaç patch kodlandığını yazdır
print(f"Toplam {len(all_patches)} patch HOG ile kodlandı.")

#5 ADET TEST GÖRSELİ ÖN İŞLEMDEN GEÇİRİLİP LABELLERİYLE BERABER GÖRÜNTÜLENİYOR.
#5 ADET TEST GÖRSELİNDEN HEDEF ORGANDAN RAST GELE NOKTALAR ALINIYOR.
#HER TEST GÖRSELİNDEN KAÇARTANE PACH ALINDIĞI BULUNUYOR
#5 TEST GÖRSELİNİN PACHLERİ HOG İLE KODLANARAK KAYIT EDİLİYOR
#CROSSKOLERASYON İLE HOG KODLARI BENZERLİK YÖNÜNDEN KARŞILAŞTIRILIYOR.
#BENZER OLAN İNDEKSLERDEKİ HOG KODLARININ KORDİNATLARI ALINARAK TEST GÖRSELİNDE NOKTA OLARAK İŞARETLENİYOR.

#TEST GÖRÜNTÜLERİNİ AL VE ÖNİŞLEMEDEN GEÇİR. (5 ADET TEST GÖRÜNTÜSÜ)
#LABELLERİYLE BERABER GÖRSELLEŞTİR

import cv2
import numpy as np
from matplotlib import pyplot as plt

# Görüntü dosyalarının yolları
image_paths = [
    r"C:\Users\yakup\Desktop\demirci\image (1).jpg",
    r"C:\Users\yakup\Desktop\demirci\image (3).jpg",
    r"C:\Users\yakup\Desktop\demirci\image (5).jpg",
    r"C:\Users\yakup\Desktop\demirci\image (7).jpg",
    r"C:\Users\yakup\Desktop\demirci\image (9).jpg"
]

label_paths = [
    r"C:\Users\yakup\Desktop\labels\image (1).png",
    r"C:\Users\yakup\Desktop\labels\image (3).png",
    r"C:\Users\yakup\Desktop\labels\image (5).png",
    r"C:\Users\yakup\Desktop\labels\image (7).png",
    r"C:\Users\yakup\Desktop\labels\image (9).png"
]

# Adım 1: L2 Norm Normalizasyonu
def normalize_image(image):
    norm = np.linalg.norm(image)  # L2 normu hesapla
    normalized_image = image / norm  # Görüntüyü normalleştir
    return (normalized_image * 255).astype(np.uint8)  # [0, 255] aralığına geri çevir

# Adım 2: Adaptif Median Filtresi
def adaptive_median_filter(image, max_kernel_size=7):
    return cv2.medianBlur(image, max_kernel_size)  # Adaptif median filtreleme

# Adım 3: Parlaklık Artırma
def increase_brightness(image, brightness_increase=25):
    return cv2.add(image, np.full_like(image, brightness_increase))

# Etiketli bölgeyi çıkarma işlemi
def process_image(image_path, label_path):
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    label_image = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)  # Etiket (tek kanallı)

    # Adım 1: Normalizasyon
    normalized_image = normalize_image(image)

    # Adım 2: Adaptif Median Filtresi
    adaptive_median_filtered = adaptive_median_filter(normalized_image, max_kernel_size=7)

    # Adım 3: Parlaklık Artırma
    brightened_image = increase_brightness(adaptive_median_filtered, brightness_increase=25)

    # Etiketli bölgeyi çıkarma (Aşındırma işlemi yok)
    masked_image = cv2.bitwise_and(brightened_image, brightened_image, mask=label_image)

    return image, label_image, masked_image

# Görselleri işleme
processed_images = [process_image(image_paths[i], label_paths[i]) for i in range(5)]  # 5 görsel

# masked_image'leri adlandırma
masked_images = [masked for _, _, masked in processed_images]

# Sonuçları görselleştirme
plt.figure(figsize=(20, 20))

for i, (original, label, masked) in enumerate(processed_images):
    # Orijinal Görüntü
    plt.subplot(5, 3, i*3+1)
    plt.title(f"Orijinal Görüntü {i+1}")
    plt.imshow(original, cmap="gray")
    plt.axis("off")

    # Etiket
    plt.subplot(5, 3, i*3+2)
    plt.title(f"Etiket {i+1}")
    plt.imshow(label, cmap="gray")
    plt.axis("off")

    # L2 Norm + Adaptif Median + Parlaklık
    plt.subplot(5, 3, i*3+3)
    plt.title(f"L2 Norm + AdaptifMedian + Parlaklık {i+1}")
    plt.imshow(masked, cmap="gray")
    plt.axis("off")

plt.show()

# masked_image'leri kullanabilirsiniz:
for idx, masked in enumerate(masked_images):
    print(f"masked_image{idx+1} Boyutları: {masked.shape}")

#TEST GÖRSELLERİNDEN HEDEF ORGANDAN RAST GELE ALINAN NOKTALAR.

# Önceden tanımlı Drawing fonksiyonu
def Drawing(img, EdgePoints, circle_radius=10):
    """
    Görüntü üzerine belirtilen noktaları çizen fonksiyon
    """
    img_copy = img.copy()
    for point in EdgePoints:
        cv2.circle(img_copy, tuple(point[::-1]), circle_radius, (0, 0, 255), -1)  # Kırmızı nokta çizer
    plt.imshow(img_copy, cmap='gray')
    plt.axis('off')  # Eksenleri kapat
    plt.show()

# Siyah olmayan pikselleri alan fonksiyon
def GetNonBlackPixels(img, sparsity_factor=1, draw=False, circle_radius=10):
    """
    Siyah olmayan pikselleri alır, görüntüyü yukarı ve aşağı bölgelere ayırarak farklı eşik değerleri uygular.
    Args:
        img: Giriş görüntüsü (tek kanallı).
        sparsity_factor: Piksel seyrekleştirme faktörü.
        draw: Piksel noktalarını çizmek isteyip istemediğiniz.
        circle_radius: Çizim sırasında noktaların yarıçapı.
    Returns:
        pixels: Siyah olmayan piksellerin (y, x) koordinatları.
    """
    # Görüntünün boyutlarını al
    height, width = img.shape

    # Görüntüyü yukarı ve aşağı olarak iki bölgeye ayır
    top_half = img[:height // 2, :]
    bottom_half = img[height // 2:, :]

    # Yukarı bölge için eşikleme
    y_top, x_top = np.where(top_half > 210)
    pixels_top = np.vstack((y_top, x_top)).T

    # Aşağı bölge için eşikleme
    y_bottom, x_bottom = np.where(bottom_half > 140)
    y_bottom += height // 2  # Aşağı bölgenin y koordinatını düzelt
    pixels_bottom = np.vstack((y_bottom, x_bottom)).T

    # Yukarı ve aşağı bölgelerin piksellerini birleştir
    pixels = np.vstack((pixels_top, pixels_bottom))

    # Sparsity factor ile seyrekleştirme
    if sparsity_factor > 1:
        pixels = pixels[::sparsity_factor]

    # Çizim yapmak istenirse
    if draw:
        Drawing(img, EdgePoints=pixels, circle_radius=circle_radius)

    return pixels

# Her bir işlenmiş görüntü için siyah olmayan pikselleri al ve çiz
for i, img in enumerate(sharpened_images, start=6):
    # Siyah olmayan pikselleri al
    test_img_Points = GetNonBlackPixels(img, sparsity_factor=200, circle_radius=10, draw=True)

#HER TEST GÖRSELİNDEN KAÇARTANE PACH ALINDI

# Patch almak için fonksiyonu her bir görüntüde uygulamak
patches_dict = {}  # Her bir görüntü için patch'leri saklayacak bir sözlük

# Görüntülerin listesi ve isimleri
# Burada işlenmiş görüntüleri kullanıyoruz
sharpened_images = sharpened_images  # İşlenmiş görüntüler
image_names = ['test_sharpened_image1', 'test_sharpened_image3', 'test_sharpened_image5', 'test_sharpened_image7', 'test_sharpened_image9']

# Her bir görüntüde siyah olmayan pikselleri al ve patch'leri al
for img, img_name in zip(sharpened_images, image_names):
    # Siyah olmayan pikselleri al
    non_black_pixels = GetNonBlackPixels(img, sparsity_factor=300, circle_radius=10, draw=False)  # Noktaları al

    # Patch'leri al
    patches, patch_info = GetPatchsFromNonBlackPixels(img, non_black_pixels, PatchSize=30, draw=False)

    # Görüntü ismi ile patch'leri sözlüğe ekle
    patches_dict[img_name] = {
        'patches': patches,
        'patch_info': patch_info
    }

# Her bir görüntünün patch'lerine erişmek için
for img_name, patch_data in patches_dict.items():
    print(f"{img_name} için toplam patch sayısı: {len(patch_data['patches'])}")

#5 TEST GÖRSELİNİN PACHLERİ HOG İLE KODLANARAK KAYIT EDİLİYOR
#HER GÖRSELİN HOG KODUNU AYRI AYRI KAYDETTİK.

import cv2
import numpy as np
import os
from skimage.feature import hog

# HOG özelliklerini çıkaran ve kaydeden fonksiyon
def save_hog_features_with_coords(patches, patch_info, output_file):
    """
    HOG özelliklerini ve koordinat bilgilerini kaydeder.
    Args:
        patches: HOG özelliklerini çıkarmak için kullanılan yamalar.
        patch_info: Her patch için koordinatlar.
        output_file: Kaydedilecek dosya yolu.
    """
    hog_features = []
    coords = []

    for patch, info in zip(patches, patch_info):
        # HOG özelliğini çıkar
        fd, _ = hog(patch, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)
        hog_features.append(fd)
        coords.append(info)

    # Özellikleri ve koordinatları dosyaya kaydet
    np.savez_compressed(output_file, hog_features=hog_features, coords=coords)

# Görüntüler ve isimleri
sharpened_images = sharpened_images
image_names = ['test_image1', 'test_image3', 'test_image5', 'test_image7', 'test_image9']
output_directory = r"C:\Users\yakup\Desktop\sifthogdosyasi"

# Her bir görüntü için patch'leri al ve HOG özelliklerini kaydet
for img, img_name in zip(sharpened_images, image_names):
    # Siyah olmayan pikselleri al
    non_black_pixels = GetNonBlackPixels(img, sparsity_factor=300, circle_radius=10, draw=False)  # Noktaları al

    # Patch'leri al
    patches, patch_info = GetPatchsFromNonBlackPixels(img, non_black_pixels, PatchSize=30, draw=False)

    # HOG özelliklerini kaydet
    output_file = os.path.join(output_directory, f"{img_name}_hog_features_with_coords.npz")
    save_hog_features_with_coords(patches, patch_info, output_file)

    # Başarı mesajı
    print(f"Kayıt başarılı: {output_file}")

#DOSYADA Kİ KAYITLI KLASÖRÜN ANAHTARINI SORGULAYAN KOD

# Dosyanın içeriğini kontrol etme
hog_data = np.load(r"C:\Users\yakup\Desktop\sifthogdosyasi\test_image1_hog_features_with_coords.npz")
print(hog_data.files)  # Dosyanın içinde hangi anahtarların bulunduğunu gösterir

#HOG KODLARINI CROSS KOLERASYONLA KARŞILAŞTIRDIK.

#BU AŞAMADA EĞİTİM İÇİN KULLANDIĞIMIZ 3 GÖRSELDEN SHİFT ANAHTAR NOKTALARINDAN ALDIĞIMIZ PACHLERİN HOG KODLARIYLA
#TEST İÇİN KULLANDIĞIMIZ 5 GÖRSELİN HEDEF ORGANINDAN ALDIĞIMIZ PACHLERİN HOG KODLARINI (HER GÖRSELİN HOG KODUNU AYRI DOSYADA TUTUK)
#CROSSKOLERASYONLA KARŞILAŞTIRDIK EN YÜKSEK KOLERASYON 0,96 ÇIKMAKTI.
#DAHA FAZLA NOKTA TESPİT ETMEK İÇİN 0,30 VE ÜSTÜ KOLERASYON DEĞERİNE SAHİP EŞLEŞMELERİ TUTUK.
#TEST GÖRÜNTÜSÜNDE EŞLEŞEN NOKTALARIN KORDİNATLARI YARDIMIYLA NOKTALARI TEST GÖRÜNTÜSÜNDE İŞARETLEDİK.
#BU ŞEKİLDE HEDEF ORGANI SEGMENTE ETMİŞ OLDUK.

import numpy as np
import cv2
import matplotlib.pyplot as plt
from scipy.spatial.distance import cdist

# Optimize edilmiş çapraz korelasyon fonksiyonu
def compute_cross_correlation_optimized(vectors1, vectors2):
    return 1 - cdist(vectors1, vectors2, metric='correlation')  # Korelasyon mesafesi

# HDD'deki referans HOG vektörlerini yükleme
stored_hog_vectors = np.load(r"C:\Users\yakup\Desktop\sifthogdosyasi\hog_features_with_coords.npz")['features']

# İşlenecek test görüntüleri, etiketler ve HOG dosyalarının yolları
test_image_paths = [
    r"C:\Users\yakup\Desktop\demirci\image (1).jpg",
    r"C:\Users\yakup\Desktop\demirci\image (3).jpg",
    r"C:\Users\yakup\Desktop\demirci\image (5).jpg",
    r"C:\Users\yakup\Desktop\demirci\image (7).jpg",
    r"C:\Users\yakup\Desktop\demirci\image (9).jpg"
]

label_image_paths = [
   r"C:\Users\yakup\Desktop\labels\image (1).png",
    r"C:\Users\yakup\Desktop\labels\image (3).png",
    r"C:\Users\yakup\Desktop\labels\image (5).png",
    r"C:\Users\yakup\Desktop\labels\image (7).png",
    r"C:\Users\yakup\Desktop\labels\image (9).png"
]

hog_files = [
    r"C:\Users\yakup\Desktop\sifthogdosyasi\test_image1_hog_features_with_coords.npz",
    r"C:\Users\yakup\Desktop\sifthogdosyasi\test_image3_hog_features_with_coords.npz",
    r"C:\Users\yakup\Desktop\sifthogdosyasi\test_image5_hog_features_with_coords.npz",
    r"C:\Users\yakup\Desktop\sifthogdosyasi\test_image7_hog_features_with_coords.npz",
    r"C:\Users\yakup\Desktop\sifthogdosyasi\test_image9_hog_features_with_coords.npz"
]

# Görüntü işleme ve korelasyon hesaplama
plt.figure(figsize=(15, len(test_image_paths) * 5))
for idx, (test_image_path, label_image_path, hog_file) in enumerate(zip(test_image_paths, label_image_paths, hog_files)):
    # Test HOG vektörlerini ve koordinatlarını yükleme
    hog_data = np.load(hog_file)
    test_hog_vectors = hog_data['hog_features']
    test_coords = hog_data['coords']

    # Test görüntüsünü yükleme
    test_image = cv2.imread(test_image_path)
    output_img = np.zeros_like(test_image)  # Siyah bir görüntü oluşturma

    # Etiket görüntüsünü yükleme
    label_image = cv2.imread(label_image_path)

    # Çapraz korelasyonu hızlı hesaplama
    correlations_matrix = compute_cross_correlation_optimized(test_hog_vectors, stored_hog_vectors)
    threshold = 0.30
    high_correlation_indices = np.argwhere(correlations_matrix >= threshold)

    # Yüksek korelasyon eşleşmelerini işleme
    matching_coords_count = 0
    for test_idx, stored_idx in high_correlation_indices:
        coord = test_coords[test_idx]
        x, y = int(coord[0]), int(coord[1])
        cv2.circle(output_img, (x, y), 12, (255, 255, 255), -1)
        matching_coords_count += 1

    # Görüntü adını dosya yolundan çıkarma
    image_name = test_image_path.split("\\")[-1]

    # Orijinal görüntü, etiket ve çıktı görselleştirme
    plt.subplot(len(test_image_paths), 3, idx * 3 + 1)
    plt.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))
    plt.title(f"Original - {image_name}")
    plt.axis('off')

    plt.subplot(len(test_image_paths), 3, idx * 3 + 2)
    plt.imshow(cv2.cvtColor(label_image, cv2.COLOR_BGR2RGB))
    plt.title(f"Label - {image_name}")
    plt.axis('off')

    plt.subplot(len(test_image_paths), 3, idx * 3 + 3)
    plt.imshow(cv2.cvtColor(output_img, cv2.COLOR_BGR2RGB))
    plt.title(f"Output_test_img{idx + 6} (Eşleşme Sayısı: {matching_coords_count})")
    plt.axis('off')

plt.tight_layout()
plt.show()

#ELDE ETTİĞİMİZ 5 TEST GÖRSELİNİN lABELLERLE KARŞILAŞTIRMASINI YAPARAK IoU HESAPLAMASINI YAPIYORUZ.

#NOKTALAR GENELLİKLE DOĞRU YERLERİ BULMUŞLAR. MORFOLOJİK DÜZELTMELER YAPMAK KOMBİNASYONLAR ARASINDA (SIFT+HOG / LABEL + HOG / EROİSİON + HOG)
#ADİL BİR IoU KARŞILAŞTIRMASININ ÖNÜNE GEÇTİĞİ İÇİN HER KOMBİNASYONUN NOKTASAL ÇIKTILARINA KARIŞMADAN IoU HESAPLATIP KARŞILAŞTIRACAĞIM.

#ÇÜNKÜ BAZI KOMBİNASYONLARDAN SONRA MORFOLOJİK DÜZELTMELER DAHA BAŞARILI OLMAKTADIR. BUDA HANGİ KOMBİNASYONUN DAHA İYİ OLDUĞUNUN ANLAŞILMAMASINA SEBEB OLMAKTADIR.
#ÖRNEK VERECEK OLURSAK EROSİON İLE YAPILAN MODELLEMEDE NOKTALAR BİR BİRİNE UZAK ÇIKIYOR ALT KEMİK-ÜST KEMİK ARASI DAHA AÇIK OLDUĞUNDAN ..
#MORFOLOJİK DÜZELTME EROSİON DA ÇOK DAHA BAŞARILI OLARAK YANILTICI BİR IoU VERMEKTEDİR.

import matplotlib.pyplot as plt

# IoU hesaplama fonksiyonu
def calculate_iou(predicted_image, label_image):
    # İkili görüntüye dönüştürme (thresholding)
    _, pred_binary = cv2.threshold(cv2.cvtColor(predicted_image, cv2.COLOR_BGR2GRAY), 127, 255, cv2.THRESH_BINARY)
    _, label_binary = cv2.threshold(cv2.cvtColor(label_image, cv2.COLOR_BGR2GRAY), 127, 255, cv2.THRESH_BINARY)

    # Kesişim ve birleşim
    intersection = np.logical_and(pred_binary > 0, label_binary > 0).sum()
    union = np.logical_or(pred_binary > 0, label_binary > 0).sum()

    # IoU hesaplama
    iou = intersection / union if union != 0 else 0
    return iou

# IoU hesaplama ve çıktı
ious = []
for idx, (test_image_path, label_image_path, hog_file) in enumerate(zip(test_image_paths, label_image_paths, hog_files)):
    # Çıkış görüntüsü
    output_img = np.zeros_like(cv2.imread(test_image_path))
    hog_data = np.load(hog_file)
    test_hog_vectors = hog_data['hog_features']
    test_coords = hog_data['coords']

    correlations_matrix = compute_cross_correlation_optimized(test_hog_vectors, stored_hog_vectors)
    high_correlation_indices = np.argwhere(correlations_matrix >= threshold)

    for test_idx, _ in high_correlation_indices:
        coord = test_coords[test_idx]
        x, y = int(coord[0]), int(coord[1])
        cv2.circle(output_img, (x, y), 12, (255, 255, 255), -1)

    # Etiket görüntüsünü yükleme
    label_image = cv2.imread(label_image_path)

    # IoU hesaplama
    iou = calculate_iou(output_img, label_image)
    ious.append(iou)
    print(f"Test Image {idx + 6}: IoU = {iou:.4f}")

# Ortalama IoU
mean_iou = np.mean(ious)
print(f"\n(Görüntü + Label + Hog + Cross Kolerasyon)Ortalama IoU: {mean_iou:.4f}")

# IoU Grafik Çıktısı
image_names = [f"Image {i+6}" for i in range(len(ious))]
plt.figure(figsize=(10, 6))
plt.bar(image_names, ious, color='skyblue', edgecolor='black')
plt.axhline(mean_iou, color='red', linestyle='--', label=f'Ortalama IoU = {mean_iou:.4f}')
plt.xlabel('Görüntüler')
plt.ylabel('IoU Değeri')
plt.title('(Görüntü + Label + Hog + Cross Kolerasyon)IoU Değerleri ve Ortalama IoU')
plt.legend()
plt.tight_layout()
plt.show()

#LABEL YARDIMIYLA ORGAN + LBP + HOG + HIZLANDIRILMIŞ CROSS KOLERASYON + IoU HESAPLAMA

import numpy as np
import matplotlib.pyplot as plt
import cv2
import math
import numpy as np
from kymatio import Scattering2D
from skimage import measure

#3 ADET TEST GÖRSELİ VE LABELLERİ ÖN İŞLEMDEN GEÇİRİLEREK GÖRSELLEŞTİRİLİYOR

import cv2
import numpy as np
from matplotlib import pyplot as plt

# Görüntü dosyalarının yolları
image_paths = [
    r"C:\Users\yakup\Desktop\demirci\image (1).jpg",
    r"C:\Users\yakup\Desktop\demirci\image (3).jpg",
    r"C:\Users\yakup\Desktop\demirci\image (5).jpg"
]

label_paths = [
    r"C:\Users\yakup\Desktop\labels\image (1).png",
    r"C:\Users\yakup\Desktop\labels\image (3).png",
    r"C:\Users\yakup\Desktop\labels\image (5).png"
]

# Adım 1: L2 Norm Normalizasyonu
def normalize_image(image):
    norm = np.linalg.norm(image)  # L2 normu hesapla
    normalized_image = image / norm  # Görüntüyü normalleştir
    return (normalized_image * 255).astype(np.uint8)  # [0, 255] aralığına geri çevir

# Adım 2: Adaptif Median Filtresi
def adaptive_median_filter(image, max_kernel_size=7):
    return cv2.medianBlur(image, max_kernel_size)  # Adaptif median filtreleme

# Adım 3: Parlaklık Artırma
def increase_brightness(image, brightness_increase=25):
    return cv2.add(image, np.full_like(image, brightness_increase))

# Etiketli bölgeyi çıkarma işlemi
def process_image(image_path, label_path):
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    label_image = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)  # Etiket (tek kanallı)

    # Adım 1: Normalizasyon
    normalized_image = normalize_image(image)

    # Adım 2: Adaptif Median Filtresi
    adaptive_median_filtered = adaptive_median_filter(normalized_image, max_kernel_size=7)

    # Adım 3: Parlaklık Artırma
    brightened_image = increase_brightness(adaptive_median_filtered, brightness_increase=25)

    # Etiketli bölgeyi çıkarma (Aşındırma işlemi yok)
    masked_image = cv2.bitwise_and(brightened_image, brightened_image, mask=label_image)

    return image, label_image, masked_image

# Görselleri işleme
processed_images = [process_image(image_paths[i], label_paths[i]) for i in range(3)]

# masked_image'leri adlandırma
masked_image, masked_image2, masked_image3 = [masked for _, _, masked in processed_images]

# Sonuçları görselleştirme
plt.figure(figsize=(15, 15))

for i, (original, label, masked) in enumerate(processed_images):
    plt.subplot(3, 3, i*3+1)
    plt.title(f"Orijinal Görüntü {i+1}")
    plt.imshow(original, cmap="gray")
    plt.axis("off")

    plt.subplot(3, 3, i*3+2)
    plt.title(f"Etiket {i+1}")
    plt.imshow(label, cmap="gray")
    plt.axis("off")

    plt.subplot(3, 3, i*3+3)
    plt.title(f"L2 Norm + AdaptifMedian + Parlaklık {i+1}")
    plt.imshow(masked, cmap="gray")
    plt.axis("off")

plt.show()

# masked_image'leri kullanabilirsiniz:
print(f"masked_image Boyutları: {masked_image.shape}")
print(f"masked_image2 Boyutları: {masked_image2.shape}")
print(f"masked_image3 Boyutları: {masked_image3.shape}")

#GÖRSELLERE ÖN İŞLEMEDEN SONRA LBP UYGULUYORUZ

from skimage.feature import local_binary_pattern

# LBP işlemi (yalnızca siyah olmayan kısımlara uygulama)
def apply_lbp_to_nonblack(image, radius=1, n_points=8, threshold=10):
    """
    Siyah olmayan piksellere LBP uygular.
    Args:
        image: Giriş görüntüsü (tek kanallı).
        radius: LBP yarıçapı.
        n_points: LBP noktalarının sayısı.
        threshold: Siyah pikselleri belirlemek için eşik değeri.
    Returns:
        lbp_image: LBP uygulanan görüntü.
    """
    # Girdi görüntüsünün 2D olduğundan emin olun
    if len(image.shape) != 2:
        raise ValueError("Giriş görüntüsü 2D olmalıdır!")

    # Siyah olmayan alanları belirle
    non_black_mask = image > threshold

    # Boş bir LBP görüntüsü oluştur
    lbp_image = np.zeros_like(image, dtype=np.float32)

    # LBP yalnızca siyah olmayan bölgelerde uygulanabilir
    if np.any(non_black_mask):  # Siyah olmayan piksel varsa
        lbp_image[non_black_mask] = local_binary_pattern(
            image[non_black_mask].reshape(-1, 1),  # 1D'yi 2D'ye dönüştür
            n_points,
            radius,
            method="uniform",
        ).ravel()  # Sonuçları geri düzleştir

    return lbp_image

# Görseller için LBP uygulaması
lbp_images = [
    apply_lbp_to_nonblack(masked, radius=1, n_points=8, threshold=10)
    for _, _, masked in processed_images
]

# LBP sonuçlarını görselleştirme
plt.figure(figsize=(15, 20))

for i, (original, label, masked, lbp) in enumerate(zip(
    [img for img, _, _ in processed_images],
    [lbl for _, lbl, _ in processed_images],
    [msk for _, _, msk in processed_images],
    lbp_images
)):
    # Orijinal görüntü
    plt.subplot(3, 4, i*4+1)
    plt.title(f"Orijinal Görüntü {i+1}")
    plt.imshow(original, cmap="gray")
    plt.axis("off")

    # Etiket
    plt.subplot(3, 4, i*4+2)
    plt.title(f"Etiket {i+1}")
    plt.imshow(label, cmap="gray")
    plt.axis("off")

    # İşlenmiş görüntü
    plt.subplot(3, 4, i*4+3)
    plt.title(f"L1 Norm + Mean + Parlaklık(20) + Keskinleştirme {i+1}")
    plt.imshow(masked, cmap="gray")
    plt.axis("off")

    # LBP sonuçları
    plt.subplot(3, 4, i*4+4)
    plt.title(f"LBP {i+1} (Siyah olmayan alanlara)")
    plt.imshow(lbp, cmap="gray")
    plt.axis("off")

plt.tight_layout()
plt.show()

# LBP sonuçlarını değişkenlerde tutabilirsiniz
lbp_image1, lbp_image2, lbp_image3 = lbp_images

#YAZDIRMA FONKSİYONU

def Drawing(img, EdgePoints=None, EdgeLines=None, EdgePatchs=None, title=None, circle_radius=10):
    output_img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)

    if EdgePoints is not None:
        for point in EdgePoints:
            x, y = int(point[1]), int(point[0])  # x ve y koordinatları ters çevrilir
            cv2.circle(output_img, (x, y), circle_radius, (0, 0, 255), -1)  # Kırmızı daire

    if EdgeLines is not None:
        for Line in EdgeLines:
            start_point = Line["StartPointYX"]
            stop_point = Line["StopPointYX"]
            cv2.line(output_img, start_point[::-1], stop_point[::-1], color=(255, 255, 0), thickness=2)

    if EdgePatchs is not None:
        # Img üzerine Patch çiz
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 1
        color = (255, 0, 0)
        thickness = 2
        for k, (x, y, PatchSize) in enumerate(EdgePatchs):  # (x, y, PatchSize) bekleniyor
            top_left = (x - PatchSize, y - PatchSize)
            bottom_right = (x + PatchSize, y + PatchSize)
            cv2.rectangle(output_img, top_left, bottom_right, (0, 0, 255), 2)
            cv2.putText(output_img, str(k), (x, y - 10), font, font_scale, color, thickness, cv2.LINE_AA)

    # Görüntü boyutlarına göre figsize hesaplama
    height, width = img.shape[:2]
    aspect_ratio = width / height
    figsize = (15 * aspect_ratio, 15)  # Oranı koruyarak uygun bir ölçekleme

    plt.figure(figsize=figsize)
    plt.imshow(cv2.cvtColor(output_img, cv2.COLOR_BGR2RGB))
    if title is not None:
        plt.title(title, fontsize=30)
    plt.axis('off')
    plt.show()

#GÖRSELDEN PİKSELLER ALINMASI (SEYRELTİLEREK)

import matplotlib.pyplot as plt
import numpy as np

def GetNonBlackPixels(img, sparsity_factor=1, draw=False, circle_radius=10):
    """
    Siyah olmayan pikselleri alır.
    Args:
        img: Giriş görüntüsü (tek kanallı).
        sparsity_factor: Piksel seyrekleştirme faktörü.
        draw: Piksel noktalarını çizmek isteyip istemediğiniz.
        circle_radius: Çizim sırasında noktaların yarıçapı.
    Returns:
        pixels: Siyah olmayan piksellerin (y, x) koordinatları.
    """
    # Siyah olmayan piksellerin koordinatlarını al
    y, x = np.where(img > 0)
    pixels = np.vstack((y, x)).T  # (y, x) -> [[y1, x1], [y2, x2], ...]

    # Sparsity factor ile seyrekleştirme
    if sparsity_factor > 1:
        pixels = pixels[::sparsity_factor]

    # Çizim yapmak istenirse
    if draw:
        img_uint8 = (img * 255).astype(np.uint8) if img.max() <= 1 else img.astype(np.uint8)
        Drawing(img_uint8, EdgePoints=pixels, circle_radius=circle_radius)

    return pixels


# Görselleri ve isimlerini listeleyin
masked_images = [lbp_image1, lbp_image2, lbp_image3]
image_titles = ["Masked Image 1", "Masked Image 2", "Masked Image 3"]

# Noktalar işaretlenmiş görselleri tutmak için
point_masked_images1 = lbp_image1.copy()
point_masked_images2 = lbp_image2.copy()
point_masked_images3 = lbp_image3.copy()

# Görselleştirme
plt.figure(figsize=(15, 5))

# Her bir görüntü için noktaları işaretleyin
for i, lbp_image1 in enumerate(masked_images):
    # Siyah olmayan pikselleri al ve noktaları çiz
    if i == 0:
        img_Points1 = GetNonBlackPixels(point_masked_images1, sparsity_factor=500, circle_radius=10, draw=True)
    elif i == 1:
        img_Points2 = GetNonBlackPixels(point_masked_images2, sparsity_factor=500, circle_radius=10, draw=True)
    elif i == 2:
        img_Points3 = GetNonBlackPixels(point_masked_images3, sparsity_factor=500, circle_radius=10, draw=True)

    # Görselleştirme
    plt.subplot(1, 3, i + 1)
    plt.imshow(lbp_image1, cmap='gray')
    plt.title(f"{image_titles[i]} - Noktalar")
    plt.axis('off')

plt.tight_layout()
plt.show()

#BELİRLENEN PİKSELLERDEN PACH ALINMASI

def GetPatchsFromNonBlackPixels(img, NonBlackPixels, PatchSize=11, draw=True):
    """
    Siyah olmayan piksellerden yamalar alır.
    Args:
        img: Giriş görüntüsü (tek kanallı).
        NonBlackPixels: Siyah olmayan piksellerin (y, x) koordinatları.
        PatchSize: Yamaların boyutu (2 * PatchSize + 1, 2 * PatchSize + 1).
        draw: Yamaları görselleştirmek isteyip istemediğiniz.
    Returns:
        Patchs: Siyah olmayan piksellerden alınan yamalar.
        PatchsInfo: Yamaların konum ve boyut bilgileri.
    """
    Patchs = []
    PatchsInfo = []
    rows, cols = img.shape

    for y, x in NonBlackPixels:
        # Yamayı sınır kontrolü yaparak al
        y_start, y_end = y - PatchSize, y + PatchSize + 1
        x_start, x_end = x - PatchSize, x + PatchSize + 1

        if y_start < 0 or y_end > rows or x_start < 0 or x_end > cols:
            # Yama görüntü sınırlarının dışında, atla
            continue

        Patch = img[y_start:y_end, x_start:x_end]
        Patchs.append(Patch)
        PatchsInfo.append((x, y, PatchSize))

    if draw:
        Drawing(img, EdgePoints=NonBlackPixels, EdgePatchs=PatchsInfo)

    return Patchs, PatchsInfo

# GetPatchsFromNonBlackPixels fonksiyonunu kullanarak her bir görselde patch'ler alalım
img_Patchs1, img_PatchsInfo1 = GetPatchsFromNonBlackPixels(point_masked_images1, img_Points1, PatchSize=30, draw=True)
img_Patchs2, img_PatchsInfo2 = GetPatchsFromNonBlackPixels(point_masked_images2, img_Points2, PatchSize=30, draw=True)
img_Patchs3, img_PatchsInfo3 = GetPatchsFromNonBlackPixels(point_masked_images3, img_Points3, PatchSize=30, draw=True)

# Örnek olarak, her bir görselde alınan patch'leri görmek için:
print(f"Image 1 Patch Sayısı: {len(img_Patchs1)}")
print(f"Image 2 Patch Sayısı: {len(img_Patchs2)}")
print(f"Image 3 Patch Sayısı: {len(img_Patchs3)}")

# Yamaları görselleştirme
plt.figure(figsize=(15, 5))

# Her bir görsel için yamaları görselleştir
for i, (img_Patchs, img_PatchsInfo) in enumerate(zip(
    [img_Patchs1, img_Patchs2, img_Patchs3],
    [img_PatchsInfo1, img_PatchsInfo2, img_PatchsInfo3]
)):
    # İlk yamayı al
    patch = img_Patchs[0]

    # Görselleştirme için yamayı normalize et
    if patch.dtype != np.uint8:
        patch = (patch - patch.min()) / (patch.max() - patch.min())  # [0, 1] aralığına normalizasyon

    plt.subplot(1, 3, i + 1)
    plt.imshow(patch, cmap='gray')
    plt.title(f"Image {i + 1} - Patch")
    plt.axis('off')

plt.tight_layout()
plt.show()

#PACHLERİN HOG İLE KODLANIP TEK DOSYA OLARAK KAYDEDİLMESİ. (Toplam 5366 patch HOG ile kodlandı.)

import cv2
import numpy as np
import os

# HOG özelliklerini hesaplayan fonksiyon
def compute_hog_features(image, cell_size=(8, 8), block_size=(2, 2), nbins=9):
    """
    Verilen görüntü için HOG özelliklerini hesaplar.
    """
    # Görüntünün tek kanallı ve 8-bit olduğundan emin olun
    if image.ndim == 3:  # RGB görüntü ise, gri tonlamaya çevir
        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    if image.dtype != np.uint8:  # Veri tipi uint8 değilse, dönüştür
        image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)

    hog = cv2.HOGDescriptor(
        _winSize=(image.shape[1] // cell_size[1] * cell_size[1],
                  image.shape[0] // cell_size[0] * cell_size[0]),
        _blockSize=(block_size[1] * cell_size[1], block_size[0] * cell_size[0]),
        _blockStride=(cell_size[1], cell_size[0]),
        _cellSize=(cell_size[1], cell_size[0]),
        _nbins=nbins
    )
    features = hog.compute(image)
    return features.flatten()


# HOG özelliklerini ve koordinatlarını kaydeden fonksiyon
def save_hog_features_with_coords(patches, patch_info, output_path, cell_size=(8, 8), block_size=(2, 2), nbins=9):
    """
    Patch'lerin HOG özelliklerini ve koordinatlarını HDD'ye kaydeder.
    """
    all_features = []
    all_coords = []

    for i, (patch, info) in enumerate(zip(patches, patch_info)):
        features = compute_hog_features(patch, cell_size, block_size, nbins)
        all_features.append(features)
        all_coords.append(info)

    all_features = np.array(all_features)
    all_coords = np.array(all_coords)

    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    np.savez(output_path, features=all_features, coords=all_coords)
    print(f"HOG özellikleri ve koordinatlar kaydedildi: {output_path}")

# GetPatchsFromNonBlackPixels fonksiyonunu kullanarak her bir görselde patch'ler alalım
img_Patchs1, img_PatchsInfo1 = GetPatchsFromNonBlackPixels(point_masked_images1, img_Points1, PatchSize=30, draw=True)
img_Patchs2, img_PatchsInfo2 = GetPatchsFromNonBlackPixels(point_masked_images2, img_Points2, PatchSize=30, draw=True)
img_Patchs3, img_PatchsInfo3 = GetPatchsFromNonBlackPixels(point_masked_images3, img_Points3, PatchSize=30, draw=True)

# Tüm patch'leri ve koordinatları birleştir
all_patches = img_Patchs1 + img_Patchs2 + img_Patchs3
all_patch_info = img_PatchsInfo1 + img_PatchsInfo2 + img_PatchsInfo3

# HOG özelliklerini kaydetme
output_file_with_coords = r"C:\Users\yakup\Desktop\sifthogdosyasi\hog_features_with_coords.npz"
save_hog_features_with_coords(all_patches, all_patch_info, output_file_with_coords)

# Sonuç olarak toplam kaç patch kodlandığını yazdır
print(f"Toplam {len(all_patches)} patch HOG ile kodlandı.")

#TEST AŞAMASI

#TEST GÖRÜNTÜLERİNİ AL VE ÖNİŞLEMEDEN GEÇİR. (5 ADET TEST GÖRÜNTÜSÜ)
#LABELLERİYLE BERABER GÖRSELLEŞTİR

import cv2
import numpy as np
from matplotlib import pyplot as plt

# Görüntü dosyalarının yolları
image_paths = [
    r"C:\Users\yakup\Desktop\demirci\image (6).jpg",
    r"C:\Users\yakup\Desktop\demirci\image (7).jpg",
    r"C:\Users\yakup\Desktop\demirci\image (8).jpg",
    r"C:\Users\yakup\Desktop\demirci\image (9).jpg",
    r"C:\Users\yakup\Desktop\demirci\image (10).jpg"
]

label_paths = [
    r"C:\Users\yakup\Desktop\labels\image (6).png",
    r"C:\Users\yakup\Desktop\labels\image (7).png",
    r"C:\Users\yakup\Desktop\labels\image (8).png",
    r"C:\Users\yakup\Desktop\labels\image (9).png",
    r"C:\Users\yakup\Desktop\labels\image (10).png"
]

# Adım 1: L2 Norm Normalizasyonu
def normalize_image(image):
    norm = np.linalg.norm(image)  # L2 normu hesapla
    normalized_image = image / norm  # Görüntüyü normalleştir
    return (normalized_image * 255).astype(np.uint8)  # [0, 255] aralığına geri çevir

# Adım 2: Adaptif Median Filtresi
def adaptive_median_filter(image, max_kernel_size=7):
    return cv2.medianBlur(image, max_kernel_size)  # Adaptif median filtreleme

# Adım 3: Parlaklık Artırma
def increase_brightness(image, brightness_increase=25):
    return cv2.add(image, np.full_like(image, brightness_increase))

# Etiketli bölgeyi çıkarma işlemi
def process_image(image_path, label_path):
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    label_image = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)  # Etiket (tek kanallı)

    # Adım 1: Normalizasyon
    normalized_image = normalize_image(image)

    # Adım 2: Adaptif Median Filtresi
    adaptive_median_filtered = adaptive_median_filter(normalized_image, max_kernel_size=7)

    # Adım 3: Parlaklık Artırma
    brightened_image = increase_brightness(adaptive_median_filtered, brightness_increase=25)

    # Etiketli bölgeyi çıkarma (Aşındırma işlemi yok)
    masked_image = cv2.bitwise_and(brightened_image, brightened_image, mask=label_image)

    return image, label_image, masked_image

# Görselleri işleme
processed_images = [process_image(image_paths[i], label_paths[i]) for i in range(5)]  # 5 görsel

# masked_image'leri adlandırma
masked_images = [masked for _, _, masked in processed_images]

# Sonuçları görselleştirme
plt.figure(figsize=(20, 20))

for i, (original, label, masked) in enumerate(processed_images):
    # Orijinal Görüntü
    plt.subplot(5, 3, i*3+1)
    plt.title(f"Orijinal Görüntü {i+1}")
    plt.imshow(original, cmap="gray")
    plt.axis("off")

    # Etiket
    plt.subplot(5, 3, i*3+2)
    plt.title(f"Etiket {i+1}")
    plt.imshow(label, cmap="gray")
    plt.axis("off")

    # L2 Norm + Adaptif Median + Parlaklık
    plt.subplot(5, 3, i*3+3)
    plt.title(f"L2 Norm + AdaptifMedian + Parlaklık {i+1}")
    plt.imshow(masked, cmap="gray")
    plt.axis("off")

plt.show()

# masked_image'leri kullanabilirsiniz:
for idx, masked in enumerate(masked_images):
    print(f"masked_image{idx+1} Boyutları: {masked.shape}")

#TEST GÖRSELLERİNDEN HEDEF ORGANDAN RAST GELE ALINAN NOKTALAR.

# Önceden tanımlı Drawing fonksiyonu
def Drawing(img, EdgePoints, circle_radius=10):
    """
    Görüntü üzerine belirtilen noktaları çizen fonksiyon
    """
    img_copy = img.copy()
    for point in EdgePoints:
        cv2.circle(img_copy, tuple(point[::-1]), circle_radius, (0, 0, 255), -1)  # Kırmızı nokta çizer
    plt.imshow(img_copy, cmap='gray')
    plt.axis('off')  # Eksenleri kapat
    plt.show()

# Siyah olmayan pikselleri alan fonksiyon
def GetNonBlackPixels(img, sparsity_factor=1, draw=False, circle_radius=10):
    """
    Siyah olmayan pikselleri alır, görüntüyü yukarı ve aşağı bölgelere ayırarak farklı eşik değerleri uygular.
    Args:
        img: Giriş görüntüsü (tek kanallı).
        sparsity_factor: Piksel seyrekleştirme faktörü.
        draw: Piksel noktalarını çizmek isteyip istemediğiniz.
        circle_radius: Çizim sırasında noktaların yarıçapı.
    Returns:
        pixels: Siyah olmayan piksellerin (y, x) koordinatları.
    """
    # Görüntünün boyutlarını al
    height, width = img.shape

    # Görüntüyü yukarı ve aşağı olarak iki bölgeye ayır
    top_half = img[:height // 2, :]
    bottom_half = img[height // 2:, :]

    # Yukarı bölge için eşikleme
    y_top, x_top = np.where(top_half > 210)
    pixels_top = np.vstack((y_top, x_top)).T

    # Aşağı bölge için eşikleme
    y_bottom, x_bottom = np.where(bottom_half > 140)
    y_bottom += height // 2  # Aşağı bölgenin y koordinatını düzelt
    pixels_bottom = np.vstack((y_bottom, x_bottom)).T

    # Yukarı ve aşağı bölgelerin piksellerini birleştir
    pixels = np.vstack((pixels_top, pixels_bottom))

    # Sparsity factor ile seyrekleştirme
    if sparsity_factor > 1:
        pixels = pixels[::sparsity_factor]

    # Çizim yapmak istenirse
    if draw:
        Drawing(img, EdgePoints=pixels, circle_radius=circle_radius)

    return pixels

# Her bir işlenmiş görüntü için siyah olmayan pikselleri al ve çiz
for i, img in enumerate(sharpened_images, start=6):
    # Siyah olmayan pikselleri al
    test_img_Points = GetNonBlackPixels(img, sparsity_factor=200, circle_radius=10, draw=True)

#HER TEST GÖRSELİNDEN KAÇARTANE PACH ALINDI

# Patch almak için fonksiyonu her bir görüntüde uygulamak
patches_dict = {}  # Her bir görüntü için patch'leri saklayacak bir sözlük

# Görüntülerin listesi ve isimleri
# Burada işlenmiş görüntüleri kullanıyoruz
sharpened_images = sharpened_images  # İşlenmiş görüntüler
image_names = ['test_sharpened_image6', 'test_sharpened_image7', 'test_sharpened_image8', 'test_sharpened_image9', 'test_sharpened_image10']

# Her bir görüntüde siyah olmayan pikselleri al ve patch'leri al
for img, img_name in zip(sharpened_images, image_names):
    # Siyah olmayan pikselleri al
    non_black_pixels = GetNonBlackPixels(img, sparsity_factor=300, circle_radius=10, draw=False)  # Noktaları al

    # Patch'leri al
    patches, patch_info = GetPatchsFromNonBlackPixels(img, non_black_pixels, PatchSize=30, draw=False)

    # Görüntü ismi ile patch'leri sözlüğe ekle
    patches_dict[img_name] = {
        'patches': patches,
        'patch_info': patch_info
    }

# Her bir görüntünün patch'lerine erişmek için
for img_name, patch_data in patches_dict.items():
    print(f"{img_name} için toplam patch sayısı: {len(patch_data['patches'])}")

#5 TEST GÖRSELİNİN PACHLERİ HOG İLE KODLANARAK KAYIT EDİLİYOR
#HER GÖRSELİN HOG KODUNU AYRI AYRI KAYDETTİK.

import cv2
import numpy as np
import os
from skimage.feature import hog

# HOG özelliklerini çıkaran ve kaydeden fonksiyon
def save_hog_features_with_coords(patches, patch_info, output_file):
    """
    HOG özelliklerini ve koordinat bilgilerini kaydeder.
    Args:
        patches: HOG özelliklerini çıkarmak için kullanılan yamalar.
        patch_info: Her patch için koordinatlar.
        output_file: Kaydedilecek dosya yolu.
    """
    hog_features = []
    coords = []

    for patch, info in zip(patches, patch_info):
        # HOG özelliğini çıkar
        fd, _ = hog(patch, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)
        hog_features.append(fd)
        coords.append(info)

    # Özellikleri ve koordinatları dosyaya kaydet
    np.savez_compressed(output_file, hog_features=hog_features, coords=coords)

# Görüntüler ve isimleri
sharpened_images = sharpened_images
image_names = ['test_image6', 'test_image7', 'test_image8', 'test_image9', 'test_image10']
output_directory = r"C:\Users\yakup\Desktop\sifthogdosyasi"

# Her bir görüntü için patch'leri al ve HOG özelliklerini kaydet
for img, img_name in zip(sharpened_images, image_names):
    # Siyah olmayan pikselleri al
    non_black_pixels = GetNonBlackPixels(img, sparsity_factor=300, circle_radius=10, draw=False)  # Noktaları al

    # Patch'leri al
    patches, patch_info = GetPatchsFromNonBlackPixels(img, non_black_pixels, PatchSize=30, draw=False)

    # HOG özelliklerini kaydet
    output_file = os.path.join(output_directory, f"{img_name}_hog_features_with_coords.npz")
    save_hog_features_with_coords(patches, patch_info, output_file)

    # Başarı mesajı
    print(f"Kayıt başarılı: {output_file}")

#DOSYADA Kİ KAYITLI KLASÖRÜN ANAHTARINI SORGULAYAN KOD

# Dosyanın içeriğini kontrol etme
hog_data = np.load(r"C:\Users\yakup\Desktop\sifthogdosyasi\test_image6_hog_features_with_coords.npz")
print(hog_data.files)  # Dosyanın içinde hangi anahtarların bulunduğunu gösterir

import numpy as np
import cv2
import matplotlib.pyplot as plt
from scipy.spatial.distance import cdist

# Optimize edilmiş çapraz korelasyon fonksiyonu
def compute_cross_correlation_optimized(vectors1, vectors2):
    return 1 - cdist(vectors1, vectors2, metric='correlation')  # Korelasyon mesafesi

# HDD'deki referans HOG vektörlerini yükleme
stored_hog_vectors = np.load(r"C:\Users\yakup\Desktop\sifthogdosyasi\hog_features_with_coords.npz")['features']

# İşlenecek test görüntüleri, etiketler ve HOG dosyalarının yolları
test_image_paths = [
    r"C:\Users\yakup\Desktop\demirci\image (6).jpg",
    r"C:\Users\yakup\Desktop\demirci\image (7).jpg",
    r"C:\Users\yakup\Desktop\demirci\image (8).jpg",
    r"C:\Users\yakup\Desktop\demirci\image (9).jpg",
    r"C:\Users\yakup\Desktop\demirci\image (10).jpg"
]

label_image_paths = [
   r"C:\Users\yakup\Desktop\labels\image (6).png",
    r"C:\Users\yakup\Desktop\labels\image (7).png",
    r"C:\Users\yakup\Desktop\labels\image (8).png",
    r"C:\Users\yakup\Desktop\labels\image (9).png",
    r"C:\Users\yakup\Desktop\labels\image (10).png"
]

hog_files = [
    r"C:\Users\yakup\Desktop\sifthogdosyasi\test_image6_hog_features_with_coords.npz",
    r"C:\Users\yakup\Desktop\sifthogdosyasi\test_image7_hog_features_with_coords.npz",
    r"C:\Users\yakup\Desktop\sifthogdosyasi\test_image8_hog_features_with_coords.npz",
    r"C:\Users\yakup\Desktop\sifthogdosyasi\test_image9_hog_features_with_coords.npz",
    r"C:\Users\yakup\Desktop\sifthogdosyasi\test_image10_hog_features_with_coords.npz"
]

# Görüntü işleme ve korelasyon hesaplama
plt.figure(figsize=(15, len(test_image_paths) * 5))
for idx, (test_image_path, label_image_path, hog_file) in enumerate(zip(test_image_paths, label_image_paths, hog_files)):
    # Test HOG vektörlerini ve koordinatlarını yükleme
    hog_data = np.load(hog_file)
    test_hog_vectors = hog_data['hog_features']
    test_coords = hog_data['coords']

    # Test görüntüsünü yükleme
    test_image = cv2.imread(test_image_path)
    output_img = np.zeros_like(test_image)  # Siyah bir görüntü oluşturma

    # Etiket görüntüsünü yükleme
    label_image = cv2.imread(label_image_path)

    # Çapraz korelasyonu hızlı hesaplama
    correlations_matrix = compute_cross_correlation_optimized(test_hog_vectors, stored_hog_vectors)
    threshold = 0.30
    high_correlation_indices = np.argwhere(correlations_matrix >= threshold)

    # Yüksek korelasyon eşleşmelerini işleme
    matching_coords_count = 0
    for test_idx, stored_idx in high_correlation_indices:
        coord = test_coords[test_idx]
        x, y = int(coord[0]), int(coord[1])
        cv2.circle(output_img, (x, y), 12, (255, 255, 255), -1)
        matching_coords_count += 1

    # Görüntü adını dosya yolundan çıkarma
    image_name = test_image_path.split("\\")[-1]

    # Orijinal görüntü, etiket ve çıktı görselleştirme
    plt.subplot(len(test_image_paths), 3, idx * 3 + 1)
    plt.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))
    plt.title(f"Original - {image_name}")
    plt.axis('off')

    plt.subplot(len(test_image_paths), 3, idx * 3 + 2)
    plt.imshow(cv2.cvtColor(label_image, cv2.COLOR_BGR2RGB))
    plt.title(f"Label - {image_name}")
    plt.axis('off')

    plt.subplot(len(test_image_paths), 3, idx * 3 + 3)
    plt.imshow(cv2.cvtColor(output_img, cv2.COLOR_BGR2RGB))
    plt.title(f"Output_test_img{idx + 6} (Eşleşme Sayısı: {matching_coords_count})")
    plt.axis('off')

plt.tight_layout()
plt.show()

#ELDE ETTİĞİMİZ 5 TEST GÖRSELİNİN lABELLERLE KARŞILAŞTIRMASINI YAPARAK IoU HESAPLAMASINI YAPIYORUZ.

import matplotlib.pyplot as plt

# IoU hesaplama fonksiyonu
def calculate_iou(predicted_image, label_image):
    # İkili görüntüye dönüştürme (thresholding)
    _, pred_binary = cv2.threshold(cv2.cvtColor(predicted_image, cv2.COLOR_BGR2GRAY), 127, 255, cv2.THRESH_BINARY)
    _, label_binary = cv2.threshold(cv2.cvtColor(label_image, cv2.COLOR_BGR2GRAY), 127, 255, cv2.THRESH_BINARY)

    # Kesişim ve birleşim
    intersection = np.logical_and(pred_binary > 0, label_binary > 0).sum()
    union = np.logical_or(pred_binary > 0, label_binary > 0).sum()

    # IoU hesaplama
    iou = intersection / union if union != 0 else 0
    return iou

# IoU hesaplama ve çıktı
ious = []
for idx, (test_image_path, label_image_path, hog_file) in enumerate(zip(test_image_paths, label_image_paths, hog_files)):
    # Çıkış görüntüsü
    output_img = np.zeros_like(cv2.imread(test_image_path))
    hog_data = np.load(hog_file)
    test_hog_vectors = hog_data['hog_features']
    test_coords = hog_data['coords']

    correlations_matrix = compute_cross_correlation_optimized(test_hog_vectors, stored_hog_vectors)
    high_correlation_indices = np.argwhere(correlations_matrix >= threshold)

    for test_idx, _ in high_correlation_indices:
        coord = test_coords[test_idx]
        x, y = int(coord[0]), int(coord[1])
        cv2.circle(output_img, (x, y), 12, (255, 255, 255), -1)

    # Etiket görüntüsünü yükleme
    label_image = cv2.imread(label_image_path)

    # IoU hesaplama
    iou = calculate_iou(output_img, label_image)
    ious.append(iou)
    print(f"Test Image {idx + 6}: IoU = {iou:.4f}")

# Ortalama IoU
mean_iou = np.mean(ious)
print(f"\n(Görüntü + Lbp + Hog + Cross Kolerasyon)Ortalama IoU: {mean_iou:.4f}")

# IoU Grafik Çıktısı
image_names = [f"Image {i+6}" for i in range(len(ious))]
plt.figure(figsize=(10, 6))
plt.bar(image_names, ious, color='skyblue', edgecolor='black')
plt.axhline(mean_iou, color='red', linestyle='--', label=f'Ortalama IoU = {mean_iou:.4f}')
plt.xlabel('Görüntüler')
plt.ylabel('IoU Değeri')
plt.title('(Görüntü + Lbp + Hog + Cross Kolerasyon)IoU Değerleri ve Ortalama IoU')
plt.legend()
plt.tight_layout()
plt.show()

# M = 2*PatchSize + 1,  MxM = 101x101

#TEK HOG DOSYASI İLE TEST EDİYORUZ

#5 Görüntüyü ÖN İŞLEMLERDEN GEÇİRİYORUZ

#5 görselden noktalar alıyoruz

#her görüntüden ayrı ayrı hog al

#EROSİON YARDIMIYLA SEGMENTASYON.

#5) Label'i Erosion ile küçült, her bir label pikselini kullanarak img'den mxm boyutlu patch al, kodla ve Hdd ye kaydet. Burada hog vektör ortalaması veya normalizasyonu düşünebilirsin.

#KÜTÜPHANE

import numpy as np
import matplotlib.pyplot as plt
import cv2
import math
import numpy as np
from kymatio import Scattering2D
from skimage import measure

#ön işleme + Erosion

import cv2
import numpy as np
from matplotlib import pyplot as plt

# Görüntü dosyalarının yolları
image_paths = [
    r"C:\Users\yakup\Desktop\demirci\image (3).jpg",
    r"C:\Users\yakup\Desktop\demirci\image (4).jpg",
    r"C:\Users\yakup\Desktop\demirci\image (5).jpg"
]

label_paths = [
    r"C:\Users\yakup\Desktop\labels\image (3).png",
    r"C:\Users\yakup\Desktop\labels\image (4).png",
    r"C:\Users\yakup\Desktop\labels\image (5).png"
]

# Adım 1: L2 Norm Normalizasyonu
def normalize_image(image):
    norm = np.linalg.norm(image)  # L2 normu hesapla
    normalized_image = image / norm  # Görüntüyü normalleştir
    return (normalized_image * 255).astype(np.uint8)  # [0, 255] aralığına geri çevir

# Adım 2: Adaptif Median Filtresi
def adaptive_median_filter(image, max_kernel_size=7):
    return cv2.medianBlur(image, max_kernel_size)  # Adaptif median filtreleme

# Adım 3: Parlaklık Artırma
def increase_brightness(image, brightness_increase=25):
    return cv2.add(image, np.full_like(image, brightness_increase))

# Etiketli bölgeyi çıkarma işlemi
def process_image(image_path, label_path):
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    label_image = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)  # Etiket (tek kanallı)

# Erozyon işlemi
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (10, 10))  # 3x3 boyutunda bir çekirdek
    eroded_label = cv2.erode(label_image, kernel, iterations=1)  # Etiketi erozyona uğrat

    # Adım 1: Normalizasyon
    normalized_image = normalize_image(image)

    # Adım 2: Adaptif Median Filtresi
    adaptive_median_filtered = adaptive_median_filter(normalized_image, max_kernel_size=7)

    # Adım 3: Parlaklık Artırma
    brightened_image = increase_brightness(adaptive_median_filtered, brightness_increase=25)

    # Etiketli bölgeyi çıkarma (Aşındırma işlemi yok)
    masked_image = cv2.bitwise_and(brightened_image, brightened_image, mask=label_image)

    return image, label_image, masked_image

# Görselleri işleme
processed_images = [process_image(image_paths[i], label_paths[i]) for i in range(3)]

# masked_image'leri adlandırma
masked_image, masked_image2, masked_image3 = [masked for _, _, masked in processed_images]

# Sonuçları görselleştirme
plt.figure(figsize=(15, 15))

for i, (original, label, masked) in enumerate(processed_images):
    plt.subplot(3, 3, i*3+1)
    plt.title(f"Orijinal Görüntü {i+1}")
    plt.imshow(original, cmap="gray")
    plt.axis("off")

    plt.subplot(3, 3, i*3+2)
    plt.title(f"Erozyon Uygulanmış Etiket {i+1}")
    plt.imshow(label, cmap="gray")
    plt.axis("off")

    plt.subplot(3, 3, i*3+3)
    plt.title(f"L2 Norm + AdaptifMedian + Parlaklık {i+1}")
    plt.imshow(masked, cmap="gray")
    plt.axis("off")

plt.show()

# masked_image'leri kullanabilirsiniz:
print(f"masked_image Boyutları: {masked_image.shape}")
print(f"masked_image2 Boyutları: {masked_image2.shape}")
print(f"masked_image3 Boyutları: {masked_image3.shape}")

#FONKSİYONLAR

def Drawing(img, EdgePoints=None, EdgeLines=None, EdgePatchs=None, title=None, circle_radius=10):
    output_img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)

    if EdgePoints is not None:
        for point in EdgePoints:
            x, y = int(point[1]), int(point[0])  # x ve y koordinatları ters çevrilir
            cv2.circle(output_img, (x, y), circle_radius, (0, 0, 255), -1)  # Kırmızı daire

    if EdgeLines is not None:
        for Line in EdgeLines:
            start_point = Line["StartPointYX"]
            stop_point = Line["StopPointYX"]
            cv2.line(output_img, start_point[::-1], stop_point[::-1], color=(255, 255, 0), thickness=2)

    if EdgePatchs is not None:
        # Img üzerine Patch çiz
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 1
        color = (255, 0, 0)
        thickness = 2
        for k, (x, y, PatchSize) in enumerate(EdgePatchs):  # (x, y, PatchSize) bekleniyor
            top_left = (x - PatchSize, y - PatchSize)
            bottom_right = (x + PatchSize, y + PatchSize)
            cv2.rectangle(output_img, top_left, bottom_right, (0, 0, 255), 2)
            cv2.putText(output_img, str(k), (x, y - 10), font, font_scale, color, thickness, cv2.LINE_AA)

    # Görüntü boyutlarına göre figsize hesaplama
    height, width = img.shape[:2]
    aspect_ratio = width / height
    figsize = (15 * aspect_ratio, 15)  # Oranı koruyarak uygun bir ölçekleme

    plt.figure(figsize=figsize)
    plt.imshow(cv2.cvtColor(output_img, cv2.COLOR_BGR2RGB))
    if title is not None:
        plt.title(title, fontsize=30)
    plt.axis('off')
    plt.show()

#Noktalar alıyoruz

import matplotlib.pyplot as plt
import numpy as np

def GetNonBlackPixels(img, sparsity_factor=1, draw=False, circle_radius=10):


    # Siyah olmayan piksellerin koordinatlarını al
    y, x = np.where(img > 0)
    pixels = np.vstack((y, x)).T  # (y, x) -> [[y1, x1], [y2, x2], ...]

    # Sparsity factor ile seyrekleştirme
    if sparsity_factor > 1:
        pixels = pixels[::sparsity_factor]

    # Çizim yapmak istenirse
    if draw:
        Drawing(img, EdgePoints=pixels, circle_radius=circle_radius)

    return pixels

# Görselleri ve isimlerini listeleyin
masked_images = [masked_image, masked_image2, masked_image3]
image_titles = ["Masked Image 1", "Masked Image 2", "Masked Image 3"]

# Noktalar işaretlenmiş görselleri tutmak için
point_masked_images1 = masked_image.copy()
point_masked_images2 = masked_image2.copy()
point_masked_images3 = masked_image3.copy()

# Görselleştirme
plt.figure(figsize=(15, 5))

# Her bir görüntü için noktaları işaretleyin
for i, masked_image in enumerate(masked_images):
    # Siyah olmayan pikselleri al ve noktaları çiz
    if i == 0:
        img_Points1 = GetNonBlackPixels(point_masked_images1, sparsity_factor=200, circle_radius=10, draw=True)
    elif i == 1:
        img_Points2 = GetNonBlackPixels(point_masked_images2, sparsity_factor=200, circle_radius=10, draw=True)
    elif i == 2:
        img_Points3 = GetNonBlackPixels(point_masked_images3, sparsity_factor=200, circle_radius=10, draw=True)



plt.tight_layout()
plt.show()

#pachler alıyoruz

def GetPatchsFromNonBlackPixels(img, NonBlackPixels, PatchSize=11, draw=True):

    Patchs = []
    PatchsInfo = []
    rows, cols = img.shape

    for y, x in NonBlackPixels:
        # Yamayı sınır kontrolü yaparak al
        y_start, y_end = y - PatchSize, y + PatchSize + 1
        x_start, x_end = x - PatchSize, x + PatchSize + 1

        if y_start < 0 or y_end > rows or x_start < 0 or x_end > cols:
            # Yama görüntü sınırlarının dışında, atla
            continue

        Patch = img[y_start:y_end, x_start:x_end]
        Patchs.append(Patch)
        PatchsInfo.append((x, y, PatchSize))

    if draw:
        Drawing(img, EdgePoints=NonBlackPixels, EdgePatchs=PatchsInfo)

    return Patchs, PatchsInfo

# GetPatchsFromNonBlackPixels fonksiyonunu kullanarak her bir görselde patch'ler alalım
img_Patchs1, img_PatchsInfo1 = GetPatchsFromNonBlackPixels(point_masked_images1, img_Points1, PatchSize=30, draw=True)
img_Patchs2, img_PatchsInfo2 = GetPatchsFromNonBlackPixels(point_masked_images2, img_Points2, PatchSize=30, draw=True)
img_Patchs3, img_PatchsInfo3 = GetPatchsFromNonBlackPixels(point_masked_images3, img_Points3, PatchSize=30, draw=True)

# Örnek olarak, her bir görselde alınan patch'leri görmek için:
print(f"Image 1 Patch Sayısı: {len(img_Patchs1)}")
print(f"Image 2 Patch Sayısı: {len(img_Patchs2)}")
print(f"Image 3 Patch Sayısı: {len(img_Patchs3)}")

# Patch'leri görselleştirme
plt.figure(figsize=(15, 5))

# Her bir görsel için yamaları görselleştir
for i, (img_Patchs, img_PatchsInfo) in enumerate(zip([img_Patchs1, img_Patchs2, img_Patchs3],
                                                    [img_PatchsInfo1, img_PatchsInfo2, img_PatchsInfo3])):
    plt.subplot(1, 3, i + 1)
    plt.imshow(img_Patchs[0], cmap='gray')  # İlk yamayı görüntüleyelim
    plt.title(f"Image {i + 1} - Patch")
    plt.axis('off')

plt.tight_layout()
plt.show()

#Toplam 6983 patch HOG ile kodlandı.

import cv2
import numpy as np
import os

# HOG özelliklerini hesaplayan fonksiyon
def compute_hog_features(image, cell_size=(8, 8), block_size=(2, 2), nbins=9):

    hog = cv2.HOGDescriptor(
        _winSize=(image.shape[1] // cell_size[1] * cell_size[1],
                  image.shape[0] // cell_size[0] * cell_size[0]),
        _blockSize=(block_size[1] * cell_size[1], block_size[0] * cell_size[0]),
        _blockStride=(cell_size[1], cell_size[0]),
        _cellSize=(cell_size[1], cell_size[0]),
        _nbins=nbins
    )
    features = hog.compute(image)
    return features.flatten()

# HOG özelliklerini ve koordinatlarını kaydeden fonksiyon
def save_hog_features_with_coords(patches, patch_info, output_path, cell_size=(8, 8), block_size=(2, 2), nbins=9):

    all_features = []
    all_coords = []

    for i, (patch, info) in enumerate(zip(patches, patch_info)):
        features = compute_hog_features(patch, cell_size, block_size, nbins)
        all_features.append(features)
        all_coords.append(info)

    all_features = np.array(all_features)
    all_coords = np.array(all_coords)

    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    np.savez(output_path, features=all_features, coords=all_coords)
    print(f"HOG özellikleri ve koordinatlar kaydedildi: {output_path}")

# GetPatchsFromNonBlackPixels fonksiyonunu kullanarak her bir görselde patch'ler alalım
img_Patchs1, img_PatchsInfo1 = GetPatchsFromNonBlackPixels(point_masked_images1, img_Points1, PatchSize=30, draw=True)
img_Patchs2, img_PatchsInfo2 = GetPatchsFromNonBlackPixels(point_masked_images2, img_Points2, PatchSize=30, draw=True)
img_Patchs3, img_PatchsInfo3 = GetPatchsFromNonBlackPixels(point_masked_images3, img_Points3, PatchSize=30, draw=True)

# Tüm patch'leri ve koordinatları birleştir
all_patches = img_Patchs1 + img_Patchs2 + img_Patchs3
all_patch_info = img_PatchsInfo1 + img_PatchsInfo2 + img_PatchsInfo3

# HOG özelliklerini kaydetme
output_file_with_coords = r"C:\Users\yakup\OneDrive\Desktop\desen_5\hog_features_with_coords.npz"
save_hog_features_with_coords(all_patches, all_patch_info, output_file_with_coords)

# Sonuç olarak toplam kaç patch kodlandığını yazdır
print(f"Toplam {len(all_patches)} patch HOG ile kodlandı.")

#TEST AŞAMASI

#5 adet görüntü ile test yapıyoruz

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Görüntü ve etiketleri yükleyen fonksiyon
def GetImageLabel(imgStr, labelStr, draw=False):
    img = cv2.imread(imgStr, cv2.IMREAD_GRAYSCALE)
    label = cv2.imread(labelStr, cv2.IMREAD_GRAYSCALE)
    if draw:
        # Görüntü ve etiketleri yan yana çiz
        plt.figure(figsize=(12, 6))  # Şekil boyutunu ayarla
        plt.subplot(1, 2, 1)  # 1 satır, 2 sütun, ilk eksen
        plt.imshow(img, cmap='gray')  # img görüntüsünü göster
        plt.title(imgStr)  # Başlık
        plt.axis('off')  # Eksenleri kapat

        plt.subplot(1, 2, 2)  # 1 satır, 2 sütun, ikinci eksen
        plt.imshow(label, cmap='gray')  # label görüntüsünü göster
        plt.title(labelStr)  # Başlık
        plt.axis('off')  # Eksenleri kapat

        plt.tight_layout()
        plt.show()  # Şekli göster
    return img, label

# Görüntü dosyalarının yolları
image_paths = [
    r"C:\Users\yakup\OneDrive\Desktop\image_demirci\image (6).jpg",
    r"C:\Users\yakup\OneDrive\Desktop\image_demirci\image (7).jpg",
    r"C:\Users\yakup\OneDrive\Desktop\image_demirci\image (8).jpg",
    r"C:\Users\yakup\OneDrive\Desktop\image_demirci\image (9).jpg",
    r"C:\Users\yakup\OneDrive\Desktop\image_demirci\image (10).jpg"
]

label_paths = [
    r"C:\Users\yakup\OneDrive\Desktop\label_demirci\image (6).png",
    r"C:\Users\yakup\OneDrive\Desktop\label_demirci\image (7).png",
    r"C:\Users\yakup\OneDrive\Desktop\label_demirci\image (8).png",
    r"C:\Users\yakup\OneDrive\Desktop\label_demirci\image (9).png",
    r"C:\Users\yakup\OneDrive\Desktop\label_demirci\image (10).png"
]

# Adımlar
def process_image(image_path, label_path):
    # Görüntüyü ve etiketi yükle
    img, label = GetImageLabel(image_path, label_path, draw=False)

    # I1 Norm Normalizasyonu
    normalized_image = img / 255.0  # Piksel değerlerini [0, 1] aralığına getir
    normalized_image = (normalized_image * 255).astype(np.uint8)  # [0, 255] aralığına geri çevir

    #  Keskinleştirme (Unsharp Masking)
    def mean_filter(image, kernel_size=5):
        return cv2.blur(image, (kernel_size, kernel_size))  # Ortalama filtre uygula

    mean_filtered = mean_filter(normalized_image, kernel_size=5)

    # Ortalama (Mean) Filtreleme
    brightness_increase = 20  # Parlaklık artırma miktarı
    brightened_image = cv2.add(mean_filtered, np.full_like(mean_filtered, brightness_increase))

    # Parlaklık Artırma
    def sharpen_image(image):
        blurred = cv2.GaussianBlur(image, (5, 5), 1.5)  # Gaussian blur uygula
        sharpened = cv2.addWeighted(image, 1.5, blurred, -0.5, 0)  # Keskinleştirme işlemi
        return sharpened

    sharpened_image = sharpen_image(brightened_image)

    return sharpened_image, label  # Hem işlenmiş görüntü hem de label döndürülüyor

# İşlenmiş görüntüleri ve etiketleri saklamak için listeler
sharpened_images = []
labels = []

# Görüntüleri işleme ve son hali yazdırma
for i, (image_path, label_path) in enumerate(zip(image_paths, label_paths)):
    sharpened_image, label = process_image(image_path, label_path)
    sharpened_images.append(sharpened_image)  # İşlenmiş görüntüyü listeye ekle
    labels.append(label)  # Etiketi listeye ekle

    # Görüntüleri ve etiketleri yan yana çiz
    plt.figure(figsize=(12, 6))
    plt.subplot(1, 2, 1)
    plt.imshow(sharpened_image, cmap='gray')
    plt.title(f"Processed Image {i+6}")
    plt.axis('off')  # Eksenleri kapat

    plt.subplot(1, 2, 2)
    plt.imshow(label, cmap='gray')
    plt.title(f"Label {i+6}")
    plt.axis('off')  # Eksenleri kapat

    plt.tight_layout()
    plt.show()

#NOKTALAR ALIYORUZ

# Önceden tanımlı Drawing fonksiyonu
def Drawing(img, EdgePoints, circle_radius=10):

    img_copy = img.copy()
    for point in EdgePoints:
        cv2.circle(img_copy, tuple(point[::-1]), circle_radius, (0, 0, 255), -1)  # Kırmızı nokta çizer
    plt.imshow(img_copy, cmap='gray')
    plt.axis('off')  # Eksenleri kapat
    plt.show()

# Siyah olmayan pikselleri alan fonksiyon
def GetNonBlackPixels(img, sparsity_factor=1, draw=False, circle_radius=10):

    # Görüntünün boyutlarını al
    height, width = img.shape

    # Görüntüyü yukarı ve aşağı olarak iki bölgeye ayır
    top_half = img[:height // 2, :]
    bottom_half = img[height // 2:, :]

    # Yukarı bölge için eşikleme
    y_top, x_top = np.where(top_half > 130)
    pixels_top = np.vstack((y_top, x_top)).T

    # Aşağı bölge için eşikleme
    y_bottom, x_bottom = np.where(bottom_half > 130)
    y_bottom += height // 2  # Aşağı bölgenin y koordinatını düzelt
    pixels_bottom = np.vstack((y_bottom, x_bottom)).T

    # Yukarı ve aşağı bölgelerin piksellerini birleştir
    pixels = np.vstack((pixels_top, pixels_bottom))

    # Sparsity factor ile seyrekleştirme
    if sparsity_factor > 1:
        pixels = pixels[::sparsity_factor]

    # Çizim yapmak istenirse
    if draw:
        Drawing(img, EdgePoints=pixels, circle_radius=circle_radius)

    return pixels

# Her bir işlenmiş görüntü için siyah olmayan pikselleri al ve çiz
for i, img in enumerate(sharpened_images, start=6):
    # Siyah olmayan pikselleri al
    test_img_Points = GetNonBlackPixels(img, sparsity_factor=200, circle_radius=10, draw=True)

#5 görseli ayrı ayrı hogla kodluyoruz

import cv2
import numpy as np
import os
from skimage.feature import hog

# HOG özelliklerini çıkaran ve kaydeden fonksiyon
def save_hog_features_with_coords(patches, patch_info, output_file):

    hog_features = []
    coords = []

    for patch, info in zip(patches, patch_info):
        # HOG özelliğini çıkar
        fd, _ = hog(patch, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)
        hog_features.append(fd)
        coords.append(info)

    # Özellikleri ve koordinatları dosyaya kaydet
    np.savez_compressed(output_file, hog_features=hog_features, coords=coords)

# Görüntüler ve isimleri
sharpened_images = sharpened_images
image_names = ['test_image6', 'test_image7', 'test_image8', 'test_image9', 'test_image10']
output_directory = r"C:\Users\yakup\OneDrive\Desktop\desen_5"

# Her bir görüntü için patch'leri al ve HOG özelliklerini kaydet
for img, img_name in zip(sharpened_images, image_names):
    # Siyah olmayan pikselleri al
    non_black_pixels = GetNonBlackPixels(img, sparsity_factor=300, circle_radius=10, draw=False)  # Noktaları al

    # Patch'leri al
    patches, patch_info = GetPatchsFromNonBlackPixels(img, non_black_pixels, PatchSize=30, draw=False)

    # HOG özelliklerini kaydet
    output_file = os.path.join(output_directory, f"{img_name}_hog_features_with_coords.npz")
    save_hog_features_with_coords(patches, patch_info, output_file)

    # Başarı mesajı
    print(f"Kayıt başarılı: {output_file}")

#cross kolerasyon uyguluyoruz

import numpy as np
import cv2
import matplotlib.pyplot as plt
from scipy.spatial.distance import cdist

# Optimize edilmiş çapraz korelasyon fonksiyonu
def compute_cross_correlation_optimized(vectors1, vectors2):
    return 1 - cdist(vectors1, vectors2, metric='correlation')  # Korelasyon mesafesi

# HDD'deki referans HOG vektörlerini yükleme
stored_hog_vectors = np.load(r"C:\Users\yakup\OneDrive\Desktop\desen_5\hog_features_with_coords.npz")['features']

# İşlenecek test görüntüleri, etiketler ve HOG dosyalarının yolları
test_image_paths = [
    r"C:\Users\yakup\OneDrive\Desktop\image_demirci\image (6).jpg",
    r"C:\Users\yakup\OneDrive\Desktop\image_demirci\image (7).jpg",
    r"C:\Users\yakup\OneDrive\Desktop\image_demirci\image (8).jpg",
    r"C:\Users\yakup\OneDrive\Desktop\image_demirci\image (9).jpg",
    r"C:\Users\yakup\OneDrive\Desktop\image_demirci\image (10).jpg"
]

label_image_paths = [
    r"C:\Users\yakup\OneDrive\Desktop\label_demirci\image (6).png",
    r"C:\Users\yakup\OneDrive\Desktop\label_demirci\image (7).png",
    r"C:\Users\yakup\OneDrive\Desktop\label_demirci\image (8).png",
    r"C:\Users\yakup\OneDrive\Desktop\label_demirci\image (9).png",
    r"C:\Users\yakup\OneDrive\Desktop\label_demirci\image (10).png"
]

hog_files = [
    r"C:\Users\yakup\OneDrive\Desktop\desen_5\test_image6_hog_features_with_coords.npz",
    r"C:\Users\yakup\OneDrive\Desktop\desen_5\test_image7_hog_features_with_coords.npz",
    r"C:\Users\yakup\OneDrive\Desktop\desen_5\test_image8_hog_features_with_coords.npz",
    r"C:\Users\yakup\OneDrive\Desktop\desen_5\test_image9_hog_features_with_coords.npz",
    r"C:\Users\yakup\OneDrive\Desktop\desen_5\test_image10_hog_features_with_coords.npz"
]

# Görüntü işleme ve korelasyon hesaplama
plt.figure(figsize=(15, len(test_image_paths) * 5))
for idx, (test_image_path, label_image_path, hog_file) in enumerate(zip(test_image_paths, label_image_paths, hog_files)):
    # Test HOG vektörlerini ve koordinatlarını yükleme
    hog_data = np.load(hog_file)
    test_hog_vectors = hog_data['hog_features']
    test_coords = hog_data['coords']

    # Test görüntüsünü yükleme
    test_image = cv2.imread(test_image_path)
    output_img = np.zeros_like(test_image)  # Siyah bir görüntü oluşturma

    # Etiket görüntüsünü yükleme
    label_image = cv2.imread(label_image_path)

    # Çapraz korelasyonu hızlı hesaplama
    correlations_matrix = compute_cross_correlation_optimized(test_hog_vectors, stored_hog_vectors)
    threshold = 0.30
    high_correlation_indices = np.argwhere(correlations_matrix >= threshold)

    # Yüksek korelasyon eşleşmelerini işleme
    matching_coords_count = 0
    for test_idx, stored_idx in high_correlation_indices:
        coord = test_coords[test_idx]
        x, y = int(coord[0]), int(coord[1])
        cv2.circle(output_img, (x, y), 12, (255, 255, 255), -1)
        matching_coords_count += 1

    # Görüntü adını dosya yolundan çıkarma
    image_name = test_image_path.split("\\")[-1]

    # Orijinal görüntü, etiket ve çıktı görselleştirme
    plt.subplot(len(test_image_paths), 3, idx * 3 + 1)
    plt.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))
    plt.title(f"Original - {image_name}")
    plt.axis('off')

    plt.subplot(len(test_image_paths), 3, idx * 3 + 2)
    plt.imshow(cv2.cvtColor(label_image, cv2.COLOR_BGR2RGB))
    plt.title(f"Label - {image_name}")
    plt.axis('off')

    plt.subplot(len(test_image_paths), 3, idx * 3 + 3)
    plt.imshow(cv2.cvtColor(output_img, cv2.COLOR_BGR2RGB))
    plt.title(f"Output_test_img{idx + 6} (Eşleşme Sayısı: {matching_coords_count})")
    plt.axis('off')

plt.tight_layout()
plt.show()

#IoU HESAPLIYORUZ

import matplotlib.pyplot as plt

# IoU hesaplama fonksiyonu
def calculate_iou(predicted_image, label_image):
    # İkili görüntüye dönüştürme (thresholding)
    _, pred_binary = cv2.threshold(cv2.cvtColor(predicted_image, cv2.COLOR_BGR2GRAY), 127, 255, cv2.THRESH_BINARY)
    _, label_binary = cv2.threshold(cv2.cvtColor(label_image, cv2.COLOR_BGR2GRAY), 127, 255, cv2.THRESH_BINARY)

    # Kesişim ve birleşim
    intersection = np.logical_and(pred_binary > 0, label_binary > 0).sum()
    union = np.logical_or(pred_binary > 0, label_binary > 0).sum()

    # IoU hesaplama
    iou = intersection / union if union != 0 else 0
    return iou

# IoU hesaplama ve çıktı
ious = []
for idx, (test_image_path, label_image_path, hog_file) in enumerate(zip(test_image_paths, label_image_paths, hog_files)):
    # Çıkış görüntüsü
    output_img = np.zeros_like(cv2.imread(test_image_path))
    hog_data = np.load(hog_file)
    test_hog_vectors = hog_data['hog_features']
    test_coords = hog_data['coords']

    correlations_matrix = compute_cross_correlation_optimized(test_hog_vectors, stored_hog_vectors)
    high_correlation_indices = np.argwhere(correlations_matrix >= threshold)

    for test_idx, _ in high_correlation_indices:
        coord = test_coords[test_idx]
        x, y = int(coord[0]), int(coord[1])
        cv2.circle(output_img, (x, y), 12, (255, 255, 255), -1)

    # Etiket görüntüsünü yükleme
    label_image = cv2.imread(label_image_path)

    # IoU hesaplama
    iou = calculate_iou(output_img, label_image)
    ious.append(iou)
    print(f"Test Image {idx + 6}: IoU = {iou:.4f}")

# Ortalama IoU
mean_iou = np.mean(ious)
print(f"\n(Görüntü + Lbp + Hog + Cross Kolerasyon)Ortalama IoU: {mean_iou:.4f}")

# IoU Grafik Çıktısı
image_names = [f"Image {i+6}" for i in range(len(ious))]
plt.figure(figsize=(10, 6))
plt.bar(image_names, ious, color='skyblue', edgecolor='black')
plt.axhline(mean_iou, color='red', linestyle='--', label=f'Ortalama IoU = {mean_iou:.4f}')
plt.xlabel('Görüntüler')
plt.ylabel('IoU Değeri')
plt.title('5) IoU Değerleri ve Ortalama IoU')
plt.legend()
plt.tight_layout()
plt.show()

