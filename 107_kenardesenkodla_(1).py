# -*- coding: utf-8 -*-
"""107_KenarDesenKodla (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DcxdNdnbQMrHOUsd9WJkwUXrROSn737S
"""

#----------------------------1.madde--------------------------------------------------------------------------------------------

#MADDE1  [BOUNDARY ÇİZGİLERİ +  HOG + SOBEL NOKTA +  CROSS KOLERASYON + IoU] Final Image IoU: 0.2699
#Her bir kenar noktasından X uzunluğunda çizgi al ve kodla.

#kütüphaneler

import numpy as np
import matplotlib.pyplot as plt
import cv2
import math
import numpy as np
from kymatio import Scattering2D
from skimage import measure
import importlib
import utils
importlib.reload(utils)
from utils import *

# EN İYİ ÖNİŞLEME PİPELİNE ı uyguladık : L2 Norm + AdaptifMedian + Parlaklık

import cv2
import numpy as np
import matplotlib.pyplot as plt

# L2 Norm Normalizasyonu
def normalize_image(image):
    norm = np.linalg.norm(image)  # L2 normunu hesapla
    normalized_image = image / norm  # Görüntüyü normalleştir
    return (normalized_image * 255).astype(np.uint8)  # [0, 255] aralığına geri çevir

# Adaptif Median Filtresi
def adaptive_median_filter(image, max_kernel_size=7):
    return cv2.medianBlur(image, max_kernel_size)  # Median filtre uygula

# Parlaklık Artırma
def increase_brightness(image, brightness_increase=25):
    return cv2.add(image, np.full_like(image, brightness_increase))

# Ön işleme ve normalizasyon fonksiyonu
def ConvertAndNormalize(img, apply_preprocessing=True):
    # Eğer görüntü renkli ise gri tonlamaya çevir
    if len(img.shape) == 3 and img.shape[2] == 3:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # L2 Norm Normalizasyonu
    normalized_image = normalize_image(img)

    if apply_preprocessing:
        # Adım 2: Adaptif Median Filtresi
        adaptive_median_filtered = adaptive_median_filter(normalized_image, max_kernel_size=7)

        # Adım 3: Parlaklık Artırma
        brightened_image = increase_brightness(adaptive_median_filtered, brightness_increase=25)
        return brightened_image

    return normalized_image

# Görüntü ve etiket işleme fonksiyonu
def GetImageLabel(imgStr, labelStr, draw=False):
    img = cv2.imread(imgStr, cv2.IMREAD_GRAYSCALE)
    img = ConvertAndNormalize(img)
    label = cv2.imread(labelStr, cv2.IMREAD_GRAYSCALE)  # Etiket

    if draw:

        plt.subplot(1, 2, 2)
        plt.imshow(label, cmap='gray')
        plt.title("Etiket")
        plt.axis('off')

        plt.tight_layout()
        plt.show()

    return img, label

# Görüntü ve etiket dosyalarını al
img, label = GetImageLabel(
    r"C:\Users\yakup\Desktop\demirci\image (6).jpg",
    r"C:\Users\yakup\Desktop\labels\image (6).png",
    draw=True
)

#FONKSİYONLAR

def Drawing(img, EdgePoints=None, EdgeLines=None, EdgePatchs=None, title=None, circle_radius = 10):
    output_img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)

    if EdgePoints is not None:
        for point in EdgePoints:
            x, y = int(point[1]), int(point[0])
            cv2.circle(output_img, (x, y), circle_radius, (0, 0, 255), -1)

    if EdgeLines is not None:
        for Line in EdgeLines:
            start_point = Line["StartPointYX"]
            stop_point = Line["StopPointYX"]
            cv2.line(output_img, start_point[::-1], stop_point[::-1], color = (255, 255, 0) , thickness = 2)

    if EdgePatchs is not None:

        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 1
        color = (255, 0, 0)
        thickness = 2
        for k, (x,y,PatchSize,angle) in enumerate(EdgePatchs):
            rect = cv2.boxPoints(((float(x), float(y)), (PatchSize, PatchSize), angle))
            rect = np.int0(rect)
            cv2.drawContours(output_img, [rect], 0, (0, 0, 255), 2)

            # Draw a line indicating the angle
            end_x = int(x + (PatchSize / 2) * np.cos(np.radians(angle)))
            end_y = int(y + (PatchSize / 2) * np.sin(np.radians(angle)))
            cv2.line(output_img, (x, y), (end_x, end_y), (0, 0, 255), 2)
            cv2.putText(output_img, str(k), (x, y - 10), font, font_scale, color, thickness, cv2.LINE_AA)

    height, width = img.shape[:2]
    aspect_ratio = width / height
    figsize = (15 * aspect_ratio, 15)  # Oranı koruyarak uygun bir ölçekleme

    plt.figure(figsize=figsize)
    plt.imshow(cv2.cvtColor(output_img, cv2.COLOR_BGR2RGB))
    if title is not None:
        plt.title(title, fontsize=30)
    plt.axis('off')
    plt.show()

#CANNY VE SOBEL DEĞİL BOUNDARY İLE NOKTA BULDUK

def GetLabelEdgePoints(img, sparsity_factor=1, circle_radius = 10, draw=False):
    contours = measure.find_contours(img, level=0.5)
    # Tüm sınır piksellerini birleştir
    boundary_points = np.vstack(contours)

    # Sparsity factor ile seyrekleştirme
    if sparsity_factor > 1:
        boundary_points = boundary_points[::sparsity_factor]

    if draw:
        Drawing(img, EdgePoints=boundary_points, circle_radius=circle_radius)

    return boundary_points.astype(int)

# Kenar Gorsellerini Kodla
img_EdgePoints = GetLabelEdgePoints(label, sparsity_factor=50, circle_radius=10, draw=True)

#ÇİZGİLER ALIYORUZ

from skimage import measure
import numpy as np
import math

def GetLabelEdgePoints(img, sparsity_factor=1, circle_radius=10, draw=False):
    contours = measure.find_contours(img, level=0.5)
    # Tüm sınır piksellerini birleştir
    boundary_points = np.vstack(contours)

    # Sparsity factor ile seyrekleştirme
    if sparsity_factor > 1:
        boundary_points = boundary_points[::sparsity_factor]

    if draw:
        Drawing(img, EdgePoints=boundary_points, circle_radius=circle_radius)

    return boundary_points.astype(int)

img_EdgePoints = GetLabelEdgePoints(label, sparsity_factor=50, circle_radius=10, draw=True)

def GetLinePatchs(img, EdgePoints, LineLength=15, PatchSize=11, draw=True):
    LinePatchs = []
    LinePatchsInfo = []
    for i in range(len(EdgePoints)):
        # Kenar noktasının koordinatları
        y, x = EdgePoints[i]

        # Çizginin yönü: Beyaz alana doğru
        prev_idx = (i - 1) % len(EdgePoints)
        next_idx = (i + 1) % len(EdgePoints)
        y1, x1 = EdgePoints[prev_idx]
        y2, x2 = EdgePoints[next_idx]
        dx = x2 - x1
        dy = y2 - y1
        if dx == 0 and dy == 0:
            continue
        angle = math.atan2(-dx, dy)

        # Çizginin başından 15 piksel uzaklıkta bir hedef nokta
        line_end_x = x + LineLength * math.cos(angle)
        line_end_y = y + LineLength * math.sin(angle)

        # Çizgiyi oluştur
        line_points = []
        for t in range(LineLength):
            line_x = int(x + t * math.cos(angle))
            line_y = int(y + t * math.sin(angle))
            if 0 <= line_x < img.shape[1] and 0 <= line_y < img.shape[0]:
                line_points.append((line_y, line_x))

        # Çizgi üzerinde her bir noktadan patch al
        for point in line_points:
            line_y, line_x = point

            # Patch al
            y_start, y_end = line_y - PatchSize, line_y + PatchSize + 1
            x_start, x_end = line_x - PatchSize, line_x + PatchSize + 1

            if y_start < 0 or y_end > img.shape[0] or x_start < 0 or x_end > img.shape[1]:
                continue

            LinePatch = img[y_start:y_end, x_start:x_end]
            LinePatchs.append(LinePatch)
            LinePatchsInfo.append([line_x, line_y, PatchSize, np.degrees(angle)])

    if draw:
        # Çizgileri görselleştir
        EdgeLines = []
        for i in range(len(EdgePoints)):
            y, x = EdgePoints[i]
            prev_idx = (i - 1) % len(EdgePoints)
            next_idx = (i + 1) % len(EdgePoints)
            y1, x1 = EdgePoints[prev_idx]
            y2, x2 = EdgePoints[next_idx]
            dx = x2 - x1
            dy = y2 - y1
            if dx == 0 and dy == 0:
                continue
            angle = math.atan2(-dx, dy)

            line_end_x = x + LineLength * math.cos(angle)
            line_end_y = y + LineLength * math.sin(angle)

            EdgeLines.append({"StartPointYX": (y, x), "StopPointYX": (int(line_end_y), int(line_end_x))})

        Drawing(img, EdgePoints=EdgePoints, EdgeLines=EdgeLines, EdgePatchs=LinePatchsInfo)

    return LinePatchs, LinePatchsInfo

# Kenar noktalarından beyaz alana doğru çizgiler çiz ve patch'ler al
img_LinePatchs, img_LinePatchsInfo = GetLinePatchs(img, img_EdgePoints, LineLength=10, PatchSize=20, draw=True)

#PACHLERİ GÖRSELLEŞTİRDİK

def DisplayPatches(EdgePatchs, max_cols=10, max_patches=100):
    # Toplam patch sayısı
    num_patches = min(len(EdgePatchs), max_patches)  # En fazla max_patches kadar göster

    # Sütun sayısı
    cols = min(max_cols, num_patches)

    # Satır sayısını hesapla
    rows = math.ceil(num_patches / cols)

    # Şekil oluşturma
    fig, axes = plt.subplots(rows, cols, figsize=(cols * 2, rows * 2))
    axes = np.array(axes).reshape(-1)

    for i, ax in enumerate(axes):
        if i < num_patches:
            ax.imshow(EdgePatchs[i], cmap='gray')
            ax.text(5, 10, str(i), color='red', fontsize=18, ha='left', va='top')
            ax.axis('off')
        else:
            ax.axis('off')

    plt.tight_layout()
    plt.show()

DisplayPatches(img_LinePatchs, max_patches=200)

#Toplam 3710 patch HOG ile kodlandı.

import cv2
import numpy as np
import os
import math

# HOG özelliklerini hesaplayan fonksiyon
def compute_hog_features(image, cell_size=(8, 8), block_size=(2, 2), nbins=9):

    #Verilen görüntü için HOG özelliklerini hesaplar.

    hog = cv2.HOGDescriptor(
        _winSize=(image.shape[1] // cell_size[1] * cell_size[1],
                  image.shape[0] // cell_size[0] * cell_size[0]),
        _blockSize=(block_size[1] * cell_size[1], block_size[0] * cell_size[0]),
        _blockStride=(cell_size[1], cell_size[0]),
        _cellSize=(cell_size[1], cell_size[0]),
        _nbins=nbins
    )
    features = hog.compute(image)
    return features.flatten()

# HOG özelliklerini ve koordinatlarını kaydeden fonksiyon
def save_hog_features_with_coords(patches, patch_info, output_path, cell_size=(8, 8), block_size=(2, 2), nbins=9):

    #Patch'lerin HOG özelliklerini ve koordinatlarını HDD'ye kaydeder.

    all_features = []
    all_coords = []

    for i, (patch, info) in enumerate(zip(patches, patch_info)):
        features = compute_hog_features(patch, cell_size, block_size, nbins)
        all_features.append(features)
        all_coords.append(info)

    all_features = np.array(all_features)
    all_coords = np.array(all_coords)

    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    np.savez(output_path, features=all_features, coords=all_coords)
    print(f"HOG özellikleri ve koordinatlar kaydedildi: {output_path}")



# Görüntüyü ve kenar noktalarını al
img = cv2.imread(r"C:\Users\yakup\OneDrive\Desktop\image_demirci\image (6).jpg", cv2.IMREAD_GRAYSCALE)



# HOG özelliklerini kaydetme
output_file_with_coords = r"C:\Users\yakup\OneDrive\Desktop\kenar_1\hog_features_with_coords.npz"
save_hog_features_with_coords(img_LinePatchs, img_LinePatchsInfo, output_file_with_coords)

# Sonuç olarak toplam kaç patch kodlandığını yazdır
print(f"Toplam {len(img_LinePatchs)} patch HOG ile kodlandı.")



#TEST KISMI

import cv2
import numpy as np
import matplotlib.pyplot as plt

def ConvertAndNormalize(img, apply_preprocessing=True):
    # Eğer görüntü renkli ise gri tonlamaya çevir
    if len(img.shape) == 3 and img.shape[2] == 3:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # I1 Norm Normalizasyonu
    normalized_image = img / 255.0
    normalized_image = (normalized_image * 255).astype(np.uint8)

    # Ön işleme işlemleri
    if apply_preprocessing:

        # Keskinleştirme (Unsharp Masking)
        def sharpen_image(image):
            blurred = cv2.GaussianBlur(image, (5, 5), 1.5)
            sharpened = cv2.addWeighted(image, 1.5, blurred, -0.5, 0)
            return sharpened

        # Ortalama (Mean) Filtreleme
        def mean_filter(image, kernel_size=5):
            return cv2.blur(image, (kernel_size, kernel_size))
        mean_filtered = mean_filter(normalized_image, kernel_size=5)

        # Parlaklık Artırma
        brightness_increase = 20
        brightened_image = cv2.add(mean_filtered, np.full_like(mean_filtered, brightness_increase))



        sharpened_image = sharpen_image(brightened_image)

    return sharpened_image

def GetImageLabel(imgStr, labelStr, draw=False):
    img = cv2.imread(imgStr, cv2.IMREAD_GRAYSCALE); img = ConvertAndNormalize(img)
    label = cv2.imread(labelStr, cv2.IMREAD_GRAYSCALE)
    if draw:
        plt.figure(figsize=(12, 6))
        plt.subplot(1, 2, 1)
        plt.imshow(img, cmap='gray')
        plt.title(imgStr)
        plt.axis('off')

        plt.subplot(1, 2, 2)
        plt.imshow(label, cmap='gray')
        plt.title(labelStr)
        plt.axis('off')

        plt.tight_layout()
        plt.show()
    return img, label

# img ve label gorselleri al
test_img, test_label = GetImageLabel(
    r"C:\Users\yakup\OneDrive\Desktop\image_demirci\image (9).jpg",
    r"C:\Users\yakup\OneDrive\Desktop\label_demirci\image (9).png",
    draw=True
)

#SOBEL İLE NOKTA BULDUM

def GetSobelEdgePoints(img, sparsity_factor=1, draw=False):
    # Sobel filtrelerini uygula (yatay ve dikey gradyanlar)
    grad_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)
    grad_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3)

    # Gradyan büyüklüğünü hesapla
    grad_magnitude = cv2.magnitude(grad_x, grad_y)

    # Gradyan büyüklüğünü eşik değerine göre ikili görüntüye dönüştür
    _, edges = cv2.threshold(grad_magnitude, 50, 255, cv2.THRESH_BINARY)
    edges = edges.astype(np.uint8)

    # Kenar noktalarını bul
    SobelEdgePoints, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)

    EdgePoints = []
    for ObjPoints in SobelEdgePoints:
        EdgePoints = EdgePoints + [(point[0][1], point[0][0]) for i, point in enumerate(ObjPoints) if i % sparsity_factor == 0]

    if draw:
        Drawing(img, EdgePoints=EdgePoints)

    print(f"Toplam Kenar Noktası Sayısı: {len(EdgePoints)}")
    return EdgePoints

# Sobel ile kenarları bulma
test_img_EdgePoints = GetSobelEdgePoints(test_img, sparsity_factor=25, draw=True)   # EdgePoints --> [p,2] --> (y,x)

#NOKTALARDAN PACH ALIYOR

def GetEdgePatchs(img, EdgePoints, PatchSize=11, draw=True):
    EdgePatchs = []
    EdgePatchsInfo = []
    for i in range(len(EdgePoints)):
        # Çizginin başlangıç noktası
        y, x = EdgePoints[i]

        # Çizginin yönü
        prev_idx = (i - 1) % len(EdgePoints)
        next_idx = (i + 1) % len(EdgePoints)
        y1, x1 = EdgePoints[prev_idx]
        y2, x2 = EdgePoints[next_idx]
        dx = x2 - x1
        dy = y2 - y1
        if dx == 0 and dy == 0:
            continue
        angle = math.atan2(-dx, dy)

        # Patch al
        center = (float(x), float(y))
        rotation_matrix = cv2.getRotationMatrix2D(center, np.degrees(angle), scale=1.0)
        rows, cols = img.shape
        rotated_image = cv2.warpAffine(img, rotation_matrix, (cols, rows), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=0)
        # Patch sınırlarını kontrol et
        y_start, y_end = y - PatchSize, y + PatchSize + 1
        x_start, x_end = x - PatchSize, x + PatchSize + 1

        if y_start < 0 or y_end > rows or x_start < 0 or x_end > cols:
            # Patch görüntü sınırlarının dışında, atla
            continue

        EdgePatch = rotated_image[y-PatchSize:y+PatchSize+1, x-PatchSize:x+PatchSize+1]

        EdgePatchs.append(EdgePatch)
        EdgePatchsInfo.append([x,y,PatchSize,np.degrees(angle)])

    if draw:
        Drawing(img, EdgePoints=EdgePoints, EdgePatchs = EdgePatchsInfo)

    return EdgePatchs, EdgePatchsInfo


test_img_EdgePatchs, test_img_EdgePatchsInfo = GetEdgePatchs(test_img, test_img_EdgePoints, PatchSize=20, draw=True)

#PACHLERİ HOG İLE KODLUYOR

import cv2
import numpy as np
import os
import math

def compute_hog_features(image, cell_size=(8, 8), block_size=(2, 2), nbins=9):

    hog = cv2.HOGDescriptor(
        _winSize=(image.shape[1] // cell_size[1] * cell_size[1],
                  image.shape[0] // cell_size[0] * cell_size[0]),
        _blockSize=(block_size[1] * cell_size[1], block_size[0] * cell_size[0]),
        _blockStride=(cell_size[1], cell_size[0]),
        _cellSize=(cell_size[1], cell_size[0]),
        _nbins=nbins
    )
    features = hog.compute(image)
    return features.flatten()

# HOG özelliklerini ve koordinatlarını kaydeden fonksiyon
def save_hog_features_with_coords(patches, patch_info, output_path, cell_size=(8, 8), block_size=(2, 2), nbins=9):

    all_features = []
    all_coords = []

    for i, (patch, info) in enumerate(zip(patches, patch_info)):
        features = compute_hog_features(patch, cell_size, block_size, nbins)
        all_features.append(features)
        all_coords.append(info)

    all_features = np.array(all_features)
    all_coords = np.array(all_coords)

    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    np.savez(output_path, features=all_features, coords=all_coords)
    print(f"HOG özellikleri ve koordinatlar kaydedildi: {output_path}")

# Görüntüyü ve kenar noktalarını al
img = cv2.imread(r"C:\Users\yakup\OneDrive\Desktop\image_demirci\image (9).jpg", cv2.IMREAD_GRAYSCALE)

# HOG özelliklerini kaydetme
output_file_with_coords = r"C:\Users\yakup\OneDrive\Desktop\kenar_1\test_image9_hog_features_with_coords.npz"
save_hog_features_with_coords(test_img_EdgePatchs, test_img_EdgePatchsInfo, output_file_with_coords)

# Sonuç olarak toplam kaç patch kodlandığını yazdır
print(f"Toplam {len(test_img_EdgePatchs)} patch HOG ile kodlandı.")

#CROSS COLERASYON İLE HOG KODLARINI KARŞILAŞTIRIYOR.

import numpy as np
import cv2
import matplotlib.pyplot as plt
from scipy.spatial.distance import cdist

# Optimize edilmiş çapraz korelasyon fonksiyonu
def compute_cross_correlation_optimized(vectors1, vectors2):
    return 1 - cdist(vectors1, vectors2, metric='correlation')

# HDD'deki referans HOG vektörlerini yükleme
stored_hog_vectors = np.load(r"C:\Users\yakup\OneDrive\Desktop\kenar_1\hog_features_with_coords.npz")['features']

# İşlenecek test görüntüleri, etiketler ve HOG dosyalarının yolları
test_image_paths = [
    r"C:\Users\yakup\OneDrive\Desktop\image_demirci\image (9).jpg"
]

label_image_paths = [
    r"C:\Users\yakup\OneDrive\Desktop\label_demirci\image (9).png"
]

hog_files = [
    r"C:\Users\yakup\OneDrive\Desktop\kenar_1\test_image9_hog_features_with_coords.npz"
]

# Görüntü işleme ve korelasyon hesaplama
plt.figure(figsize=(15, len(test_image_paths) * 5))
output_images = []  # Sonuç görsellerini tutmak için bir liste oluştur
for idx, (test_image_path, label_image_path, hog_file) in enumerate(zip(test_image_paths, label_image_paths, hog_files)):
    # Test HOG vektörlerini ve koordinatlarını yükleme
    hog_data = np.load(hog_file)
    test_hog_vectors = hog_data['features']
    test_coords = hog_data['coords']

    # Test görüntüsünü yükleme
    test_image = cv2.imread(test_image_path)
    output_img = np.zeros_like(test_image)

    # Etiket görüntüsünü yükleme
    label_image = cv2.imread(label_image_path)

    # Çapraz korelasyonu hızlı hesaplama
    correlations_matrix = compute_cross_correlation_optimized(test_hog_vectors, stored_hog_vectors)
    threshold = 0.50
    high_correlation_indices = np.argwhere(correlations_matrix >= threshold)

    # Yüksek korelasyon eşleşmelerini işleme
    matching_coords_count = 0
    for test_idx, stored_idx in high_correlation_indices:
        coord = test_coords[test_idx]
        x, y = int(coord[0]), int(coord[1])
        cv2.circle(output_img, (x, y), 12, (255, 255, 255), -1)
        matching_coords_count += 1

    # Görüntü adını dosya yolundan çıkarma
    image_name = test_image_path.split("\\")[-1]

    # Sonuç görselini output_images listesine ekleme
    output_images.append(output_img)

    # Orijinal görüntü, etiket ve çıktı görselleştirme
    plt.subplot(len(test_image_paths), 3, idx * 3 + 1)
    plt.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))
    plt.title(f"Original - {image_name}")
    plt.axis('off')

    plt.subplot(len(test_image_paths), 3, idx * 3 + 2)
    plt.imshow(cv2.cvtColor(label_image, cv2.COLOR_BGR2RGB))
    plt.title(f"Label - {image_name}")
    plt.axis('off')

    plt.subplot(len(test_image_paths), 3, idx * 3 + 3)
    plt.imshow(cv2.cvtColor(output_img, cv2.COLOR_BGR2RGB))
    plt.title(f"Output_test_img{idx + 6} (Eşleşme Sayısı: {matching_coords_count})")
    plt.axis('off')

plt.tight_layout()
plt.show()

# Sonuç görsellerini bir değişkende tutma
final_output_image = output_images[-1]

#MORFOLOJİK DÜZELTMELER

import cv2
import numpy as np
import matplotlib.pyplot as plt


if isinstance(final_output_image, np.ndarray):
    if len(final_output_image.shape) == 3:
        image = cv2.cvtColor(final_output_image, cv2.COLOR_BGR2GRAY)
    else:
        image = final_output_image
else:
    image = cv2.imread(final_output_image, cv2.IMREAD_GRAYSCALE)

if image is None:
    raise ValueError("Görüntü yüklenemedi.")

# --- Ayarlanabilir Eşik Değerleri ---
threshold_value_initial = 20
blur_kernel_size = 3
morph_kernel_size = 3
dilate_iterations =3
distance_threshold_value = 20


_, binary_image = cv2.threshold(image, threshold_value_initial, 255, cv2.THRESH_BINARY)


blurred_image = cv2.GaussianBlur(binary_image, (blur_kernel_size, blur_kernel_size), 0)

#Morfolojik İşlemler
kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (morph_kernel_size, morph_kernel_size))
morphed_image = cv2.morphologyEx(blurred_image, cv2.MORPH_CLOSE, kernel)

#Dilatasyon ile Noktaları Birleştirme
dilated_image = cv2.dilate(morphed_image, kernel, iterations=dilate_iterations)

#Distance Transform
distance_transform = cv2.distanceTransform(dilated_image, cv2.DIST_L2, 5)
_, distance_thresholded = cv2.threshold(distance_transform, distance_threshold_value, 255, cv2.THRESH_BINARY)
distance_thresholded = distance_thresholded.astype(np.uint8)

#Bağlantılı Bileşen Analizi
num_labels, labels_im = cv2.connectedComponents(distance_thresholded)

#Konturları Bulma ve Poligon Oluşturma
contours, _ = cv2.findContours(dilated_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
polygon_image = np.zeros_like(dilated_image)

for contour in contours:

    cv2.fillPoly(polygon_image, [contour], 255)

# Poligon içindeki alanları beyaz yap
final_image = cv2.bitwise_or(dilated_image, polygon_image)

#Sonuçları Görselleştirme
plt.figure(figsize=(18, 12))

# Orijinal Görüntü
plt.subplot(3, 3, 1)
plt.imshow(image, cmap='gray')
plt.title("Original Image")
plt.axis('off')

# İlk Eşiklenmiş Görüntü
plt.subplot(3, 3, 2)
plt.imshow(binary_image, cmap='gray')
plt.title(f"Binary Image (Threshold: {threshold_value_initial})")
plt.axis('off')

# Bulanıklaştırılmış Görüntü
plt.subplot(3, 3, 3)
plt.imshow(blurred_image, cmap='gray')
plt.title(f"Blurred Image (Kernel: {blur_kernel_size}x{blur_kernel_size})")
plt.axis('off')

# Morfolojik İşlemler
plt.subplot(3, 3, 4)
plt.imshow(morphed_image, cmap='gray')
plt.title(f"Morphed Image (Kernel: {morph_kernel_size}x{morph_kernel_size})")
plt.axis('off')

# Dilatasyon Sonrası Görüntü
plt.subplot(3, 3, 5)
plt.imshow(dilated_image, cmap='gray')
plt.title(f"Dilated Image (Iterations: {dilate_iterations})")
plt.axis('off')

# Distance Transform Sonrası Görüntü
plt.subplot(3, 3, 6)
plt.imshow(distance_transform, cmap='hot')
plt.title("Distance Transform")
plt.axis('off')

# Distance Threshold Sonrası Görüntü
plt.subplot(3, 3, 7)
plt.imshow(distance_thresholded, cmap='gray')
plt.title(f"Distance Thresholded (Threshold: {distance_threshold_value})")
plt.axis('off')

# Poligon İçinde Beyaz Alanlar
plt.subplot(3, 3, 8)
plt.imshow(polygon_image, cmap='gray')
plt.title("Polygon Filled Image")
plt.axis('off')

# Final Görüntü
plt.subplot(3, 3, 9)
plt.imshow(final_image, cmap='gray')
plt.title("Final Image")
plt.axis('off')

plt.tight_layout()
plt.show()

#IoU HESAPLAMA

import cv2
import numpy as np
import matplotlib.pyplot as plt

# IoU hesapla
def calculate_iou(predicted_image, label_image):
    _, pred_binary = cv2.threshold(predicted_image, 127, 255, cv2.THRESH_BINARY)
    _, label_binary = cv2.threshold(label_image, 127, 255, cv2.THRESH_BINARY)

    # Kesişim ve birleşim
    intersection = np.logical_and(pred_binary > 0, label_binary > 0).sum()
    union = np.logical_or(pred_binary > 0, label_binary > 0).sum()

    # IoU hesaplama
    iou = intersection / union if union != 0 else 0
    return iou

# final_image
if final_image is None:
    print("Final yüklenemedi!")
else:

    _, final_binary = cv2.threshold(final_image, 127, 255, cv2.THRESH_BINARY)

# Etiket görüntüsünü yükleme ve kontrol etme
label_image = cv2.imread(r"C:\Users\yakup\OneDrive\Desktop\label_demirci\image (9).png", cv2.IMREAD_GRAYSCALE)
if label_image is None:
    print("Görüntü yüklenemedi!")
else:
    # Etiket görüntüsünü ikili hale getirme
    _, label_binary = cv2.threshold(label_image, 127, 255, cv2.THRESH_BINARY)


# IoU
if final_image is not None and label_image is not None:
    iou = calculate_iou(final_binary, label_binary)
    print(f"Final Image IoU: {iou:.4f}")

    # IoU Grafik
    plt.figure(figsize=(2, 6))
    plt.bar(["Final Image"], [iou], color='skyblue', edgecolor='black')
    plt.axhline(iou, color='red', linestyle='--', label=f"IoU = {iou:.4f}")
    plt.xlabel('Görüntüler')
    plt.ylabel('IoU Değeri')
    plt.title('IoU Değeri')
    plt.legend()
    plt.tight_layout()
    plt.show()

#1.madde bitti,boundary ile x uzunlugunda cizgi alındı ve kodlantı. test sonucu gösterildi.

#------------------------------------------3.madde başlangıc---------------------------------------------------------------------------------------

#KÜTÜPHANE

import numpy as np
import matplotlib.pyplot as plt
import cv2
import math
import numpy as np
from kymatio import Scattering2D

from skimage import measure
import importlib
import utils
importlib.reload(utils)
from utils import *

# EN İYİ ÖNİŞLEME PİPELİNE ı uyguladık : L2 Norm + AdaptifMedian + Parlaklık

import cv2
import numpy as np
import matplotlib.pyplot as plt

def ConvertAndNormalize(img, apply_preprocessing=True):
    # Eğer görüntü renkli ise gri tonlamaya çevir
    if len(img.shape) == 3 and img.shape[2] == 3:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # I2 Norm Normalizasyonu
    normalized_image = img / 255.0  # Piksel değerlerini [0, 1] aralığına getir
    normalized_image = (normalized_image * 255).astype(np.uint8)  # [0, 255] aralığına geri çevir

    # Ön işleme işlemleri
    if apply_preprocessing:
        # Ortalama (Mean) Filtreleme
        def mean_filter(image, kernel_size=5):
            return cv2.blur(image, (kernel_size, kernel_size))  # Ortalama filtre uygula

        mean_filtered = mean_filter(normalized_image, kernel_size=5)

        # Parlaklık Artırma
        brightness_increase = 25  # Parlaklık artırma miktarı
        brightened_image = cv2.add(mean_filtered, np.full_like(mean_filtered, brightness_increase))


        def sharpen_image(image):
            blurred = cv2.GaussianBlur(image, (5, 5), 1.5)  # Gaussian blur uygula
            sharpened = cv2.addWeighted(image, 1.5, blurred, -0.5, 0)  # Keskinleştirme işlemi
            return sharpened

        sharpened_image = sharpen_image(brightened_image)

    # Normalize edilmiş görüntü döndürülür
    return sharpened_image

def GetImageLabel(imgStr, labelStr, draw=False):
    img = cv2.imread(imgStr, cv2.IMREAD_GRAYSCALE); img = ConvertAndNormalize(img)
    label = cv2.imread(labelStr, cv2.IMREAD_GRAYSCALE)
    if draw:
        plt.figure(figsize=(12, 6))
        plt.subplot(1, 2, 1)
        plt.imshow(img, cmap='gray')
        plt.title(imgStr)
        plt.axis('off')

        plt.subplot(1, 2, 2)
        plt.imshow(label, cmap='gray')
        plt.title(labelStr)
        plt.axis('off')

        plt.tight_layout()
        plt.show()
    return img, label

# img ve label gorselleri al
img, label = GetImageLabel(
   r"C:\Users\yakup\Desktop\demirci\image (6).jpg",
    r"C:\Users\yakup\Desktop\labels\image (6).png",    draw=True
)

#FONKSİYONLAR

def Drawing(img, EdgePoints=None, EdgeLines=None, EdgePatchs=None, title=None, circle_radius = 10):
    output_img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)

    if EdgePoints is not None:
        for point in EdgePoints:
            x, y = int(point[1]), int(point[0])
            cv2.circle(output_img, (x, y), circle_radius, (0, 0, 255), -1)

    if EdgeLines is not None:
        for Line in EdgeLines:
            start_point = Line["StartPointYX"]
            stop_point = Line["StopPointYX"]
            cv2.line(output_img, start_point[::-1], stop_point[::-1], color = (255, 255, 0) , thickness = 2)

    if EdgePatchs is not None:

        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 1
        color = (255, 0, 0)
        thickness = 2
        for k, (x, y, PatchSize, angle) in enumerate(EdgePatchs):
            rect = cv2.boxPoints(((float(x), float(y)), (PatchSize, PatchSize), angle))
            rect = np.int32(rect)  # Burada np.int0 yerine np.int32 kullanıldı
            cv2.drawContours(output_img, [rect], 0, (0, 0, 255), 2)


            # Draw a line indicating the angle
            end_x = int(x + (PatchSize / 2) * np.cos(np.radians(angle)))
            end_y = int(y + (PatchSize / 2) * np.sin(np.radians(angle)))
            cv2.line(output_img, (x, y), (end_x, end_y), (0, 0, 255), 2)
            cv2.putText(output_img, str(k), (x, y - 10), font, font_scale, color, thickness, cv2.LINE_AA)

    height, width = img.shape[:2]
    aspect_ratio = width / height
    figsize = (15 * aspect_ratio, 15)  # Oranı koruyarak uygun bir ölçekleme

    plt.figure(figsize=figsize)
    plt.imshow(cv2.cvtColor(output_img, cv2.COLOR_BGR2RGB))
    if title is not None:
        plt.title(title, fontsize=30)
    plt.axis('off')
    plt.show()

#k ÇAPLI DAİRESEL ALAN KADAR KENAR NOKTALARINı ALDIK



import cv2
import numpy as np
import matplotlib.pyplot as plt

def GetExpandedRegionPoints(label, k=10, sparsity_factor=1, draw=False):
    # Dairesel yapısal element oluştur
    struct_elem = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2 * k + 1, 2 * k + 1))

    # Label genişletme (dilate)
    dilated_label = cv2.dilate(label, struct_elem)

    # Genişletilmiş label'den orijinal label'i çıkar
    expanded_region = cv2.subtract(dilated_label, label)

    # Eklenen bölgenin tüm piksellerini al
    points = np.column_stack(np.where(expanded_region > 0))  # Tüm beyaz piksellerin koordinatları

    # Sparsity factor ile seyrekleştirme
    if sparsity_factor > 1:
        points = points[::sparsity_factor]

    # Çizim yapılacaksa
    if draw:
        plt.figure(figsize=(8, 8))
        plt.imshow(label, cmap='gray')
        for point in points:
            y, x = point
            plt.plot(x, y, 'ro', markersize=5)
        plt.title(f"Eklenen Bölge Noktaları (k={k}, Sparsity={sparsity_factor})")
        plt.axis('off')
        plt.show()

    return points

# Kullanım
# img ve label, GetImageLabel fonksiyonu ile alındıktan sonra aşağıdaki kod çalıştırılabilir
expanded_points = GetExpandedRegionPoints(label, k=10, sparsity_factor=50, draw=True)

# Bulunan noktaların sayısını yazdır
print(f"Bulunan Eklenen Noktaların Sayısı: {len(expanded_points)}")





#k ÇAPLI DAİRESEL ALAN KADAR KENAR NOKTALARINDAN PACHLER ALDIK

def GetEdgePatchs(img, EdgePoints, PatchSize=11, draw=True):
    EdgePatchs = []
    EdgePatchsInfo = []
    for i in range(len(EdgePoints)):
        # Çizginin başlangıç noktası
        y, x = EdgePoints[i]

        # Çizginin yönü
        prev_idx = (i - 1) % len(EdgePoints)
        next_idx = (i + 1) % len(EdgePoints)
        y1, x1 = EdgePoints[prev_idx]
        y2, x2 = EdgePoints[next_idx]
        dx = x2 - x1
        dy = y2 - y1
        if dx == 0 and dy == 0:
            continue
        angle = math.atan2(-dx, dy)

        # Patch al
        center = (float(x), float(y))
        rotation_matrix = cv2.getRotationMatrix2D(center, np.degrees(angle), scale=1.0)
        rows, cols = img.shape
        rotated_image = cv2.warpAffine(img, rotation_matrix, (cols, rows), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=0)
        # Patch sınırlarını kontrol et
        y_start, y_end = y - PatchSize, y + PatchSize + 1
        x_start, x_end = x - PatchSize, x + PatchSize + 1

        if y_start < 0 or y_end > rows or x_start < 0 or x_end > cols:
            # Patch görüntü sınırlarının dışında, atla
            continue

        EdgePatch = rotated_image[y-PatchSize:y+PatchSize+1, x-PatchSize:x+PatchSize+1]

        EdgePatchs.append(EdgePatch)
        EdgePatchsInfo.append([x, y, PatchSize, np.degrees(angle)])

    if draw:
        Drawing(img, EdgePoints=EdgePoints, EdgePatchs=EdgePatchsInfo)

    total_patches = len(EdgePatchs)  # Toplam patch sayısını hesapla
    return EdgePatchs, EdgePatchsInfo, total_patches

# expanded_points --> img_EdgePatchs
img_EdgePatchs, img_EdgePatchsInfo, total_patches = GetEdgePatchs(img, expanded_points, PatchSize=30, draw=True)  # M = 2*PatchSize + 1,  MxM = 101x101
print(f"Toplam alınan patch sayısı: {total_patches}")

#PACH LERİ GÖRSELLEŞTİRDİK

def DisplayPatches(EdgePatchs, max_cols=10, max_patches=100):
    # Toplam patch sayısı
    num_patches = min(len(EdgePatchs), max_patches)  # En fazla max_patches kadar göster

    # Sütun sayısı (max_cols ile sınırlı)
    cols = min(max_cols, num_patches)

    # Satır sayısını hesapla
    rows = math.ceil(num_patches / cols)

    # Şekil oluşturma
    fig, axes = plt.subplots(rows, cols, figsize=(cols * 2, rows * 2))
    axes = np.array(axes).reshape(-1)  # Tek boyutlu diziye dönüştür

    for i, ax in enumerate(axes):
        if i < num_patches:
            ax.imshow(EdgePatchs[i], cmap='gray')
            ax.text(5, 10, str(i), color='red', fontsize=18, ha='left', va='top')
            ax.axis('off')
        else:
            ax.axis('off')  # Fazla eksenleri kapat

    plt.tight_layout()
    plt.show()


# img_EdgePatchs gorsellerini tek figurede gör (ilk 100 patch)
DisplayPatches(img_EdgePatchs, max_patches=100)

#TÜM PACHLERİ HOG İLE KODLAYIP KAYIT ETTİK

import cv2
import numpy as np
import os
import math

# HOG özelliklerini hesaplayan fonksiyon
def compute_hog_features(image, cell_size=(8, 8), block_size=(2, 2), nbins=9):
    """
    Verilen görüntü için HOG özelliklerini hesaplar.
    """
    hog = cv2.HOGDescriptor(
        _winSize=(image.shape[1] // cell_size[1] * cell_size[1],
                  image.shape[0] // cell_size[0] * cell_size[0]),
        _blockSize=(block_size[1] * cell_size[1], block_size[0] * cell_size[0]),
        _blockStride=(cell_size[1], cell_size[0]),
        _cellSize=(cell_size[1], cell_size[0]),
        _nbins=nbins
    )
    features = hog.compute(image)
    return features.flatten()

# HOG özelliklerini ve koordinatlarını kaydeden fonksiyon
def save_hog_features_with_coords(patches, patch_info, output_path, cell_size=(8, 8), block_size=(2, 2), nbins=9):
    """
    Patch'lerin HOG özelliklerini ve koordinatlarını HDD'ye kaydeder.
    """
    all_features = []
    all_coords = []

    for i, (patch, info) in enumerate(zip(patches, patch_info)):
        features = compute_hog_features(patch, cell_size, block_size, nbins)
        all_features.append(features)
        all_coords.append(info)

    all_features = np.array(all_features)
    all_coords = np.array(all_coords)

    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    np.savez(output_path, features=all_features, coords=all_coords)
    print(f"HOG özellikleri ve koordinatlar kaydedildi: {output_path}")



# Görüntüyü ve kenar noktalarını al (örneğin, img_EdgePoints burada)
img = cv2.imread(r"C:\Users\yakup\Desktop\labels\image (1).png", cv2.IMREAD_GRAYSCALE)



# HOG özelliklerini kaydetme
output_file_with_coords = r"C:\Users\yakup\Desktop\sifthogdosyasi\hog_features_with_coords.npz"
save_hog_features_with_coords(img_EdgePatchs, img_EdgePatchsInfo, output_file_with_coords)

# Sonuç olarak toplam kaç patch kodlandığını yazdır
print(f"Toplam {len(img_EdgePatchs)} patch HOG ile kodlandı.")

#TEST GÖRSELİNİ ÖN İŞLEMDEN GEÇİRİP GÖRÜNTÜLEDİK
#BURDA DİKEY KEMİKLERDE DAHA ÇOK KENAR NOKTASI ÇIKARACAĞIMIZ EŞLEŞMENİN DAHA ÇOK OLACAĞINI DÜŞÜNDÜĞÜMÜZ İÇİN BU TEST GÖRSELİNİ SEÇTİK

import cv2
import numpy as np
import matplotlib.pyplot as plt

def ConvertAndNormalize(img, apply_preprocessing=True):
    # Eğer görüntü renkli ise gri tonlamaya çevir
    if len(img.shape) == 3 and img.shape[2] == 3:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # I1 Norm Normalizasyonu
    normalized_image = img / 255.0  # Piksel değerlerini [0, 1] aralığına getir
    normalized_image = (normalized_image * 255).astype(np.uint8)  # [0, 255] aralığına geri çevir

    # Ön işleme işlemleri
    if apply_preprocessing:
        # Ortalama (Mean) Filtreleme
        def mean_filter(image, kernel_size=5):
            return cv2.blur(image, (kernel_size, kernel_size))  # Ortalama filtre uygula

        mean_filtered = mean_filter(normalized_image, kernel_size=5)

        # Parlaklık Artırma
        brightness_increase = 20  # Parlaklık artırma miktarı
        brightened_image = cv2.add(mean_filtered, np.full_like(mean_filtered, brightness_increase))

        # Keskinleştirme (Unsharp Masking)
        def sharpen_image(image):
            blurred = cv2.GaussianBlur(image, (5, 5), 1.5)  # Gaussian blur uygula
            sharpened = cv2.addWeighted(image, 1.5, blurred, -0.5, 0)  # Keskinleştirme işlemi
            return sharpened

        sharpened_image = sharpen_image(brightened_image)

    # Normalize edilmiş görüntü döndürülür
    return sharpened_image

def GetImageLabel(imgStr, labelStr, draw=False):
    img = cv2.imread(imgStr, cv2.IMREAD_GRAYSCALE); img = ConvertAndNormalize(img)
    label = cv2.imread(labelStr, cv2.IMREAD_GRAYSCALE)
    if draw:
        plt.figure(figsize=(12, 6))
        plt.subplot(1, 2, 1)
        plt.imshow(img, cmap='gray')
        plt.title(imgStr)
        plt.axis('off')

        plt.subplot(1, 2, 2)
        plt.imshow(label, cmap='gray')
        plt.title(labelStr)
        plt.axis('off')

        plt.tight_layout()
        plt.show()
    return img, label

# img ve label gorselleri al
test_img, test_label = GetImageLabel(
    r"C:\Users\yakup\Desktop\demirci\image (3).jpg",
    r"C:\Users\yakup\Desktop\labels\image (3).png",
    draw=True
)

#CANNY İLE KENAR ÇIKARMA

def GetCannyEdgePoints(img, sparsity_factor=1, draw=False):
    blurimg = cv2.GaussianBlur(img, (5, 5), 0)
    edges = cv2.Canny(blurimg, 25, 75)
    CannyEdgePoints, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)

    EdgePoints = []
    for ObjPoints in CannyEdgePoints:
        EdgePoints = EdgePoints + [(point[0][1], point[0][0]) for i, point in enumerate(ObjPoints) if i % sparsity_factor == 0]

    if draw:
        Drawing(img, EdgePoints=EdgePoints)

    return EdgePoints

test_img_EdgePoints = GetCannyEdgePoints(test_img, sparsity_factor=20, draw=True)   # EdgePoints --> [p,2] --> (y,x)



#BU NOKTALARDAN PACHLER ALDIK

def GetEdgePatchs(img, EdgePoints, PatchSize=11, draw=True):
    EdgePatchs = []
    EdgePatchsInfo = []
    for i in range(len(EdgePoints)):
        # Çizginin başlangıç noktası
        y, x = EdgePoints[i]

        # Çizginin yönü
        prev_idx = (i - 1) % len(EdgePoints)
        next_idx = (i + 1) % len(EdgePoints)
        y1, x1 = EdgePoints[prev_idx]
        y2, x2 = EdgePoints[next_idx]
        dx = x2 - x1
        dy = y2 - y1
        if dx == 0 and dy == 0:
            continue
        angle = math.atan2(-dx, dy)

        # Patch al
        center = (float(x), float(y))
        rotation_matrix = cv2.getRotationMatrix2D(center, np.degrees(angle), scale=1.0)
        rows, cols = img.shape
        rotated_image = cv2.warpAffine(img, rotation_matrix, (cols, rows), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=0)
        # Patch sınırlarını kontrol et
        y_start, y_end = y - PatchSize, y + PatchSize + 1
        x_start, x_end = x - PatchSize, x + PatchSize + 1

        if y_start < 0 or y_end > rows or x_start < 0 or x_end > cols:
            # Patch görüntü sınırlarının dışında, atla
            continue

        EdgePatch = rotated_image[y-PatchSize:y+PatchSize+1, x-PatchSize:x+PatchSize+1]

        EdgePatchs.append(EdgePatch)
        EdgePatchsInfo.append([x,y,PatchSize,np.degrees(angle)])

    if draw:
        Drawing(img, EdgePoints=EdgePoints, EdgePatchs = EdgePatchsInfo)

    return EdgePatchs, EdgePatchsInfo


test_img_EdgePatchs, test_img_EdgePatchsInfo = GetEdgePatchs(test_img, test_img_EdgePoints, PatchSize=30, draw=True)

#hog ile kodla

import cv2
import numpy as np
import os
import math

# HOG özelliklerini hesaplayan fonksiyon
def compute_hog_features(image, cell_size=(8, 8), block_size=(2, 2), nbins=9):
    """
    Verilen görüntü için HOG özelliklerini hesaplar.
    """
    hog = cv2.HOGDescriptor(
        _winSize=(image.shape[1] // cell_size[1] * cell_size[1],
                  image.shape[0] // cell_size[0] * cell_size[0]),
        _blockSize=(block_size[1] * cell_size[1], block_size[0] * cell_size[0]),
        _blockStride=(cell_size[1], cell_size[0]),
        _cellSize=(cell_size[1], cell_size[0]),
        _nbins=nbins
    )
    features = hog.compute(image)
    return features.flatten()

# HOG özelliklerini ve koordinatlarını kaydeden fonksiyon
def save_hog_features_with_coords(patches, patch_info, output_path, cell_size=(8, 8), block_size=(2, 2), nbins=9):
    """
    Patch'lerin HOG özelliklerini ve koordinatlarını HDD'ye kaydeder.
    """
    all_features = []
    all_coords = []

    for i, (patch, info) in enumerate(zip(patches, patch_info)):
        features = compute_hog_features(patch, cell_size, block_size, nbins)
        all_features.append(features)
        all_coords.append(info)

    all_features = np.array(all_features)
    all_coords = np.array(all_coords)

    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    np.savez(output_path, features=all_features, coords=all_coords)
    print(f"HOG özellikleri ve koordinatlar kaydedildi: {output_path}")



# Görüntüyü ve kenar noktalarını al (örneğin, img_EdgePoints burada)
img = cv2.imread(r"C:\Users\yakup\Desktop\labels\image (3).png", cv2.IMREAD_GRAYSCALE)



# HOG özelliklerini kaydetme
output_file_with_coords = r"C:\Users\yakup\Desktop\sifthogdosyasi\test_image3_hog_features_with_coords.npz"
save_hog_features_with_coords(img_EdgePatchs, img_EdgePatchsInfo, output_file_with_coords)

# Sonuç olarak toplam kaç patch kodlandığını yazdır
print(f"Toplam {len(img_EdgePatchs)} patch HOG ile kodlandı.")

# Dosyanın içeriğini kontrol etme
hog_data = np.load(r"C:\Users\yakup\Desktop\sifthogdosyasi\hog_features_with_coords.npz")
print(hog_data.files)  # Dosyanın içinde hangi anahtarların bulunduğunu gösterir

import numpy as np
import cv2
import matplotlib.pyplot as plt
from scipy.spatial.distance import cdist

# Optimize edilmiş çapraz korelasyon fonksiyonu
def compute_cross_correlation_optimized(vectors1, vectors2):
    return 1 - cdist(vectors1, vectors2, metric='correlation')  # Korelasyon mesafesi

# HDD'deki referans HOG vektörlerini yükleme
stored_hog_vectors = np.load(r"C:\Users\yakup\Desktop\sifthogdosyasi\hog_features_with_coords.npz")['features']

# İşlenecek test görüntüleri, etiketler ve HOG dosyalarının yolları
test_image_paths = [
    r"C:\Users\yakup\Desktop\demirci\image (3).jpg"
]

label_image_paths = [
    r"C:\Users\yakup\Desktop\labels\image (3).png"
]

hog_files = [
    r"C:\Users\yakup\Desktop\sifthogdosyasi\test_image3_hog_features_with_coords.npz"
]

# Görüntü işleme ve korelasyon hesaplama
plt.figure(figsize=(15, len(test_image_paths) * 5))
output_images = []  # Sonuç görsellerini tutmak için bir liste oluştur
for idx, (test_image_path, label_image_path, hog_file) in enumerate(zip(test_image_paths, label_image_paths, hog_files)):
    # Test HOG vektörlerini ve koordinatlarını yükleme
    hog_data = np.load(hog_file)
    test_hog_vectors = hog_data['features']
    test_coords = hog_data['coords']

    # Test görüntüsünü yükleme
    test_image = cv2.imread(test_image_path)
    output_img = np.zeros_like(test_image)  # Siyah bir görüntü oluşturma

    # Etiket görüntüsünü yükleme
    label_image = cv2.imread(label_image_path)

    # Çapraz korelasyonu hızlı hesaplama
    correlations_matrix = compute_cross_correlation_optimized(test_hog_vectors, stored_hog_vectors)
    threshold = 0.30
    high_correlation_indices = np.argwhere(correlations_matrix >= threshold)

    # Yüksek korelasyon eşleşmelerini işleme
    matching_coords_count = 0
    for test_idx, stored_idx in high_correlation_indices:
        coord = test_coords[test_idx]
        x, y = int(coord[0]), int(coord[1])
        cv2.circle(output_img, (x, y), 12, (255, 255, 255), -1)
        matching_coords_count += 1

    # Görüntü adını dosya yolundan çıkarma
    image_name = test_image_path.split("\\")[-1]

    # Sonuç görselini output_images listesine ekleme
    output_images.append(output_img)

    # Orijinal görüntü, etiket ve çıktı görselleştirme
    plt.subplot(len(test_image_paths), 3, idx * 3 + 1)
    plt.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))
    plt.title(f"Original - {image_name}")
    plt.axis('off')

    plt.subplot(len(test_image_paths), 3, idx * 3 + 2)
    plt.imshow(cv2.cvtColor(label_image, cv2.COLOR_BGR2RGB))
    plt.title(f"Label - {image_name}")
    plt.axis('off')

    plt.subplot(len(test_image_paths), 3, idx * 3 + 3)
    plt.imshow(cv2.cvtColor(output_img, cv2.COLOR_BGR2RGB))
    plt.title(f"Output_test_img{idx + 6} (Eşleşme Sayısı: {matching_coords_count})")
    plt.axis('off')

plt.tight_layout()
plt.show()

# Sonuç görsellerini bir değişkende tutma
final_output_image = output_images[-1]  # Son görseli tutan değişken

#FİNAL GÖRÜNTÜSÜNE MORFOLOJİK MÜDAHALELER

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Görüntüyü yükleme ve gri tonlamaya dönüştürme
if isinstance(final_output_image, np.ndarray):
    if len(final_output_image.shape) == 3:  # Eğer görüntü renkli ise gri tonlamaya dönüştür
        image = cv2.cvtColor(final_output_image, cv2.COLOR_BGR2GRAY)
    else:
        image = final_output_image  # Zaten gri tonlamalı
else:
    image = cv2.imread(final_output_image, cv2.IMREAD_GRAYSCALE)

if image is None:
    raise ValueError("Görüntü yüklenemedi. Lütfen doğru yolu kontrol edin veya geçerli bir NumPy dizisi kullanın.")

# --- Ayarlanabilir Eşik Değerleri ---
threshold_value_initial = 30  # İlk eşik değeri (örneğin kenar tespiti için)
blur_kernel_size = 9          # Bulanıklaştırma için kernel boyutu
morph_kernel_size = 3         # Morfolojik işlemler için kernel boyutu
dilate_iterations = 2        # Dilatasyon iterasyon sayısı
distance_threshold_value = 30 # Distance transform için eşik değeri

# --- Kenarları Tespit Etme ---
_, binary_image = cv2.threshold(image, threshold_value_initial, 255, cv2.THRESH_BINARY)

# --- Bulanıklaştırma ---
blurred_image = cv2.GaussianBlur(binary_image, (blur_kernel_size, blur_kernel_size), 0)

# --- Morfolojik İşlemler: Closing ---
kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (morph_kernel_size, morph_kernel_size))
morphed_image = cv2.morphologyEx(blurred_image, cv2.MORPH_CLOSE, kernel)

# --- Dilatasyon ile Noktaları Birleştirme ---
dilated_image = cv2.dilate(morphed_image, kernel, iterations=dilate_iterations)

# --- Distance Transform ---
distance_transform = cv2.distanceTransform(dilated_image, cv2.DIST_L2, 5)
_, distance_thresholded = cv2.threshold(distance_transform, distance_threshold_value, 255, cv2.THRESH_BINARY)
distance_thresholded = distance_thresholded.astype(np.uint8)

# --- Bağlantılı Bileşen Analizi ---
num_labels, labels_im = cv2.connectedComponents(distance_thresholded)

# --- Konturları Bulma ve Poligon Oluşturma ---
contours, _ = cv2.findContours(dilated_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
polygon_image = np.zeros_like(dilated_image)

for contour in contours:
    # Konturların içini beyaz yap (poligon şekli)
    cv2.fillPoly(polygon_image, [contour], 255)

# Poligon içindeki alanları beyaz yap
final_image = cv2.bitwise_or(dilated_image, polygon_image)

# --- Sonuçları Görselleştirme ---
plt.figure(figsize=(18, 12))

# Orijinal Görüntü
plt.subplot(3, 3, 1)
plt.imshow(image, cmap='gray')
plt.title("Original Image")
plt.axis('off')

# İlk Eşiklenmiş Görüntü
plt.subplot(3, 3, 2)
plt.imshow(binary_image, cmap='gray')
plt.title(f"Binary Image (Threshold: {threshold_value_initial})")
plt.axis('off')

# Bulanıklaştırılmış Görüntü
plt.subplot(3, 3, 3)
plt.imshow(blurred_image, cmap='gray')
plt.title(f"Blurred Image (Kernel: {blur_kernel_size}x{blur_kernel_size})")
plt.axis('off')

# Morfolojik İşlemler Sonrası Görüntü
plt.subplot(3, 3, 4)
plt.imshow(morphed_image, cmap='gray')
plt.title(f"Morphed Image (Kernel: {morph_kernel_size}x{morph_kernel_size})")
plt.axis('off')

# Dilatasyon Sonrası Görüntü
plt.subplot(3, 3, 5)
plt.imshow(dilated_image, cmap='gray')
plt.title(f"Dilated Image (Iterations: {dilate_iterations})")
plt.axis('off')

# Distance Transform Sonrası Görüntü
plt.subplot(3, 3, 6)
plt.imshow(distance_transform, cmap='hot')
plt.title("Distance Transform")
plt.axis('off')

# Distance Threshold Sonrası Görüntü
plt.subplot(3, 3, 7)
plt.imshow(distance_thresholded, cmap='gray')
plt.title(f"Distance Thresholded (Threshold: {distance_threshold_value})")
plt.axis('off')

# Poligon İçinde Beyaz Alanlar
plt.subplot(3, 3, 8)
plt.imshow(polygon_image, cmap='gray')
plt.title("Polygon Filled Image")
plt.axis('off')

# Final Görüntü
plt.subplot(3, 3, 9)
plt.imshow(final_image, cmap='gray')
plt.title("Final Image")
plt.axis('off')

plt.tight_layout()
plt.show()

#IoU HESAPLAMA

import cv2
import numpy as np
import matplotlib.pyplot as plt

# IoU hesaplama fonksiyonu
def calculate_iou(predicted_image, label_image):
    # İkili görüntüye dönüştürme (thresholding)
    _, pred_binary = cv2.threshold(predicted_image, 127, 255, cv2.THRESH_BINARY)
    _, label_binary = cv2.threshold(label_image, 127, 255, cv2.THRESH_BINARY)

    # Kesişim ve birleşim
    intersection = np.logical_and(pred_binary > 0, label_binary > 0).sum()
    union = np.logical_or(pred_binary > 0, label_binary > 0).sum()

    # IoU hesaplama
    iou = intersection / union if union != 0 else 0
    return iou

# final_image'i kontrol etme
if final_image is None:
    print("Final görüntüsü yüklenemedi!")
else:
    # Eğer final_image zaten gri tonlamalıysa, doğrudan eşikleme yapabilirsiniz
    _, final_binary = cv2.threshold(final_image, 127, 255, cv2.THRESH_BINARY)

# Etiket görüntüsünü yükleme ve kontrol etme
label_image = cv2.imread(r"C:\Users\yakup\Desktop\labels\image (3).png", cv2.IMREAD_GRAYSCALE)  # Etiket görüntüsünün yolu buraya girilmeli
if label_image is None:
    print("Etiket görüntüsü yüklenemedi!")
else:
    # Etiket görüntüsünü ikili hale getirme
    _, label_binary = cv2.threshold(label_image, 127, 255, cv2.THRESH_BINARY)


# IoU hesaplama
if final_image is not None and label_image is not None:
    iou = calculate_iou(final_binary, label_binary)
    print(f"Final Image IoU: {iou:.4f}")

    # IoU Grafik Çıktısı
    plt.figure(figsize=(10, 6))
    plt.bar(["Final Image"], [iou], color='skyblue', edgecolor='black')
    plt.axhline(iou, color='red', linestyle='--', label=f"IoU = {iou:.4f}")
    plt.xlabel('Görüntüler')
    plt.ylabel('IoU Değeri')
    plt.title('LABEL KENARI K ÇAPLI + BOUNDARY + HOG + CROSS KOLERASYON IoU Değeri')
    plt.legend()
    plt.tight_layout()
    plt.show()

#-------------------------------------------------3.madde bitti------------------------------------------------------

#MADDE 2

#CANNY VE SOBEL DEĞİL BOUNDARY İLE NOKTA BULDUK

def GetLabelEdgePoints(img, sparsity_factor=1, circle_radius = 10, draw=False):
    contours = measure.find_contours(img, level=0.5)
    # Tüm sınır piksellerini birleştir
    boundary_points = np.vstack(contours)

    # Sparsity factor ile seyrekleştirme
    if sparsity_factor > 1:
        boundary_points = boundary_points[::sparsity_factor]

    if draw:
        Drawing(img, EdgePoints=boundary_points, circle_radius=circle_radius)

    return boundary_points.astype(int)

# Kenar Gorsellerini Kodla
img_EdgePoints = GetLabelEdgePoints(label, sparsity_factor=50, circle_radius=10, draw=True)   # EdgePoints --> [p,2] --> (y,x)

#PACH ALIYORUZ

def GetEdgePatchs(img, EdgePoints, PatchSize=11, draw=True):
    EdgePatchs = []
    EdgePatchsInfo = []
    for i in range(len(EdgePoints)):
        # Çizginin başlangıç noktası
        y, x = EdgePoints[i]

        # Çizginin yönü
        prev_idx = (i - 1) % len(EdgePoints)
        next_idx = (i + 1) % len(EdgePoints)
        y1, x1 = EdgePoints[prev_idx]
        y2, x2 = EdgePoints[next_idx]
        dx = x2 - x1
        dy = y2 - y1
        if dx == 0 and dy == 0:
            continue
        angle = math.atan2(-dx, dy)

        # Patch al
        center = (float(x), float(y))
        rotation_matrix = cv2.getRotationMatrix2D(center, np.degrees(angle), scale=1.0)
        rows, cols = img.shape
        rotated_image = cv2.warpAffine(img, rotation_matrix, (cols, rows), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=0)
        # Patch sınırlarını kontrol et
        y_start, y_end = y - PatchSize, y + PatchSize + 1
        x_start, x_end = x - PatchSize, x + PatchSize + 1

        if y_start < 0 or y_end > rows or x_start < 0 or x_end > cols:
            # Patch görüntü sınırlarının dışında, atla
            continue

        EdgePatch = rotated_image[y-PatchSize:y+PatchSize+1, x-PatchSize:x+PatchSize+1]

        EdgePatchs.append(EdgePatch)
        EdgePatchsInfo.append([x,y,PatchSize,np.degrees(angle)])

    if draw:
        Drawing(img, EdgePoints=EdgePoints, EdgePatchs = EdgePatchsInfo)

    return EdgePatchs, EdgePatchsInfo

# img_EdgePoints --> img_EdgePatchs
img_EdgePatchs, img_EdgePatchsInfo = GetEdgePatchs(img, img_EdgePoints, PatchSize=50, draw=True)  # M = 2*PatchSize + 1,  MxM = 101x101

#PACH LERİ GÖRSELLEŞTİRDİK

def DisplayPatches(EdgePatchs, max_cols=10):
    # Toplam patch sayısı
    num_patches = len(EdgePatchs)

    # Sütun sayısı (max_cols ile sınırlı)
    cols = min(max_cols, num_patches)

    # Satır sayısını hesapla
    rows = math.ceil(num_patches / cols)

    # Şekil oluşturma
    fig, axes = plt.subplots(rows, cols, figsize=(cols * 2, rows * 2))
    axes = np.array(axes).reshape(-1)  # Tek boyutlu diziye dönüştür

    for i, ax in enumerate(axes):
        if i < num_patches:
            ax.imshow(EdgePatchs[i], cmap='gray')
            ax.text(5, 10, str(i), color='red', fontsize=18, ha='left', va='top')
            ax.axis('off')
        else:
            ax.axis('off')  # Fazla eksenleri kapat

    plt.tight_layout()
    plt.show()


# img_EdgePatchs gorsellerini tek figurede gor (donmusmuyu kontrol et)
DisplayPatches(img_EdgePatchs)

#Toplam 367 patch HOG ile kodlandı.

import cv2
import numpy as np
import os
import math

# HOG özelliklerini hesaplayan fonksiyon
def compute_hog_features(image, cell_size=(8, 8), block_size=(2, 2), nbins=9):
    """
    Verilen görüntü için HOG özelliklerini hesaplar.
    """
    hog = cv2.HOGDescriptor(
        _winSize=(image.shape[1] // cell_size[1] * cell_size[1],
                  image.shape[0] // cell_size[0] * cell_size[0]),
        _blockSize=(block_size[1] * cell_size[1], block_size[0] * cell_size[0]),
        _blockStride=(cell_size[1], cell_size[0]),
        _cellSize=(cell_size[1], cell_size[0]),
        _nbins=nbins
    )
    features = hog.compute(image)
    return features.flatten()

# HOG özelliklerini ve koordinatlarını kaydeden fonksiyon
def save_hog_features_with_coords(patches, patch_info, output_path, cell_size=(8, 8), block_size=(2, 2), nbins=9):
    """
    Patch'lerin HOG özelliklerini ve koordinatlarını HDD'ye kaydeder.
    """
    all_features = []
    all_coords = []

    for i, (patch, info) in enumerate(zip(patches, patch_info)):
        features = compute_hog_features(patch, cell_size, block_size, nbins)
        all_features.append(features)
        all_coords.append(info)

    all_features = np.array(all_features)
    all_coords = np.array(all_coords)

    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    np.savez(output_path, features=all_features, coords=all_coords)
    print(f"HOG özellikleri ve koordinatlar kaydedildi: {output_path}")



# Görüntüyü ve kenar noktalarını al (örneğin, img_EdgePoints burada)
img = cv2.imread(r"C:\Users\yakup\OneDrive\Desktop\image_demirci\image (6).jpg", cv2.IMREAD_GRAYSCALE)



# HOG özelliklerini kaydetme
output_file_with_coords = r"C:\Users\yakup\OneDrive\Desktop\kenar_2\hog_features_with_coords.npz"
save_hog_features_with_coords(img_EdgePatchs, img_EdgePatchsInfo, output_file_with_coords)

# Sonuç olarak toplam kaç patch kodlandığını yazdır
print(f"Toplam {len(img_EdgePatchs)} patch HOG ile kodlandı.")



#TEST

#ÖN İŞLEME

import cv2
import numpy as np
import matplotlib.pyplot as plt

def ConvertAndNormalize(img, apply_preprocessing=True):
    # Eğer görüntü renkli ise gri tonlamaya çevir
    if len(img.shape) == 3 and img.shape[2] == 3:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # I1 Norm Normalizasyonu
    normalized_image = img / 255.0
    normalized_image = (normalized_image * 255).astype(np.uint8)

    # Ön işleme işlemleri
    if apply_preprocessing:

        # Keskinleştirme (Unsharp Masking)
        def sharpen_image(image):
            blurred = cv2.GaussianBlur(image, (5, 5), 1.5)
            sharpened = cv2.addWeighted(image, 1.5, blurred, -0.5, 0)
            return sharpened

        # Ortalama (Mean) Filtreleme
        def mean_filter(image, kernel_size=5):
            return cv2.blur(image, (kernel_size, kernel_size))
        mean_filtered = mean_filter(normalized_image, kernel_size=5)

        # Parlaklık Artırma
        brightness_increase = 20
        brightened_image = cv2.add(mean_filtered, np.full_like(mean_filtered, brightness_increase))



        sharpened_image = sharpen_image(brightened_image)

    return sharpened_image

def GetImageLabel(imgStr, labelStr, draw=False):
    img = cv2.imread(imgStr, cv2.IMREAD_GRAYSCALE); img = ConvertAndNormalize(img)
    label = cv2.imread(labelStr, cv2.IMREAD_GRAYSCALE)
    if draw:
        plt.figure(figsize=(12, 6))
        plt.subplot(1, 2, 1)
        plt.imshow(img, cmap='gray')
        plt.title(imgStr)
        plt.axis('off')

        plt.subplot(1, 2, 2)
        plt.imshow(label, cmap='gray')
        plt.title(labelStr)
        plt.axis('off')

        plt.tight_layout()
        plt.show()
    return img, label

# img ve label gorselleri al
test_img, test_label = GetImageLabel(
    r"C:\Users\yakup\OneDrive\Desktop\image_demirci\image (9).jpg",
    r"C:\Users\yakup\OneDrive\Desktop\label_demirci\image (9).png",
    draw=True
)

#CANY İLE NOKTALAR ALDIK

def GetCannyEdgePoints(img, sparsity_factor=1, draw=False):
    blurimg = cv2.GaussianBlur(img, (5, 5), 0)
    edges = cv2.Canny(blurimg, 25, 75)
    CannyEdgePoints, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)

    EdgePoints = []
    for ObjPoints in CannyEdgePoints:
        EdgePoints = EdgePoints + [(point[0][1], point[0][0]) for i, point in enumerate(ObjPoints) if i % sparsity_factor == 0]

    if draw:
        Drawing(img, EdgePoints=EdgePoints)

    return EdgePoints

test_img_EdgePoints = GetCannyEdgePoints(test_img, sparsity_factor=70, draw=True)   # EdgePoints --> [p,2] --> (y,x)

#PACH ALIYORUZ

def GetEdgePatchs(img, EdgePoints, PatchSize=11, draw=True):
    EdgePatchs = []
    EdgePatchsInfo = []
    for i in range(len(EdgePoints)):
        # Çizginin başlangıç noktası
        y, x = EdgePoints[i]

        # Çizginin yönü
        prev_idx = (i - 1) % len(EdgePoints)
        next_idx = (i + 1) % len(EdgePoints)
        y1, x1 = EdgePoints[prev_idx]
        y2, x2 = EdgePoints[next_idx]
        dx = x2 - x1
        dy = y2 - y1
        if dx == 0 and dy == 0:
            continue
        angle = math.atan2(-dx, dy)

        # Patch al
        center = (float(x), float(y))
        rotation_matrix = cv2.getRotationMatrix2D(center, np.degrees(angle), scale=1.0)
        rows, cols = img.shape
        rotated_image = cv2.warpAffine(img, rotation_matrix, (cols, rows), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=0)
        # Patch sınırlarını kontrol et
        y_start, y_end = y - PatchSize, y + PatchSize + 1
        x_start, x_end = x - PatchSize, x + PatchSize + 1

        if y_start < 0 or y_end > rows or x_start < 0 or x_end > cols:
            # Patch görüntü sınırlarının dışında, atla
            continue

        EdgePatch = rotated_image[y-PatchSize:y+PatchSize+1, x-PatchSize:x+PatchSize+1]

        EdgePatchs.append(EdgePatch)
        EdgePatchsInfo.append([x,y,PatchSize,np.degrees(angle)])

    if draw:
        Drawing(img, EdgePoints=EdgePoints, EdgePatchs = EdgePatchsInfo)

    return EdgePatchs, EdgePatchsInfo


test_img_EdgePatchs, test_img_EdgePatchsInfo = GetEdgePatchs(test_img, test_img_EdgePoints, PatchSize=50, draw=True)

#Toplam 3236 patch HOG ile kodlandı.

import cv2
import numpy as np
import os
import math

def compute_hog_features(image, cell_size=(8, 8), block_size=(2, 2), nbins=9):

    hog = cv2.HOGDescriptor(
        _winSize=(image.shape[1] // cell_size[1] * cell_size[1],
                  image.shape[0] // cell_size[0] * cell_size[0]),
        _blockSize=(block_size[1] * cell_size[1], block_size[0] * cell_size[0]),
        _blockStride=(cell_size[1], cell_size[0]),
        _cellSize=(cell_size[1], cell_size[0]),
        _nbins=nbins
    )
    features = hog.compute(image)
    return features.flatten()

# HOG özelliklerini ve koordinatlarını kaydeden fonksiyon
def save_hog_features_with_coords(patches, patch_info, output_path, cell_size=(8, 8), block_size=(2, 2), nbins=9):

    all_features = []
    all_coords = []

    for i, (patch, info) in enumerate(zip(patches, patch_info)):
        features = compute_hog_features(patch, cell_size, block_size, nbins)
        all_features.append(features)
        all_coords.append(info)

    all_features = np.array(all_features)
    all_coords = np.array(all_coords)

    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    np.savez(output_path, features=all_features, coords=all_coords)
    print(f"HOG özellikleri ve koordinatlar kaydedildi: {output_path}")

# Görüntüyü ve kenar noktalarını al
img = cv2.imread(r"C:\Users\yakup\OneDrive\Desktop\image_demirci\image (9).jpg", cv2.IMREAD_GRAYSCALE)

# HOG özelliklerini kaydetme
output_file_with_coords = r"C:\Users\yakup\OneDrive\Desktop\kenar_2\test_image9_hog_features_with_coords.npz"
save_hog_features_with_coords(test_img_EdgePatchs, test_img_EdgePatchsInfo, output_file_with_coords)

# Sonuç olarak toplam kaç patch kodlandığını yazdır
print(f"Toplam {len(test_img_EdgePatchs)} patch HOG ile kodlandı.")

#cross kolerasyonla 0.30 ve üzeri benzerliği işaretliyoruz

import numpy as np
import cv2
import matplotlib.pyplot as plt
from scipy.spatial.distance import cdist

# Optimize edilmiş çapraz korelasyon fonksiyonu
def compute_cross_correlation_optimized(vectors1, vectors2):
    return 1 - cdist(vectors1, vectors2, metric='correlation')

# HDD'deki referans HOG vektörlerini yükleme
stored_hog_vectors = np.load(r"C:\Users\yakup\OneDrive\Desktop\kenar_2\hog_features_with_coords.npz")['features']

# İşlenecek test görüntüleri, etiketler ve HOG dosyalarının yolları
test_image_paths = [
    r"C:\Users\yakup\OneDrive\Desktop\image_demirci\image (9).jpg"
]

label_image_paths = [
    r"C:\Users\yakup\OneDrive\Desktop\label_demirci\image (9).png"
]

hog_files = [
    r"C:\Users\yakup\OneDrive\Desktop\kenar_2\test_image9_hog_features_with_coords.npz"
]

# Görüntü işleme ve korelasyon hesaplama
plt.figure(figsize=(15, len(test_image_paths) * 5))
output_images = []  # Sonuç görsellerini tutmak için bir liste oluştur
for idx, (test_image_path, label_image_path, hog_file) in enumerate(zip(test_image_paths, label_image_paths, hog_files)):
    # Test HOG vektörlerini ve koordinatlarını yükleme
    hog_data = np.load(hog_file)
    test_hog_vectors = hog_data['features']
    test_coords = hog_data['coords']

    # Test görüntüsünü yükleme
    test_image = cv2.imread(test_image_path)
    output_img = np.zeros_like(test_image)

    # Etiket görüntüsünü yükleme
    label_image = cv2.imread(label_image_path)

    # Çapraz korelasyonu hızlı hesaplama
    correlations_matrix = compute_cross_correlation_optimized(test_hog_vectors, stored_hog_vectors)
    threshold = 0.30
    high_correlation_indices = np.argwhere(correlations_matrix >= threshold)

    # Yüksek korelasyon eşleşmelerini işleme
    matching_coords_count = 0
    for test_idx, stored_idx in high_correlation_indices:
        coord = test_coords[test_idx]
        x, y = int(coord[0]), int(coord[1])
        cv2.circle(output_img, (x, y), 12, (255, 255, 255), -1)
        matching_coords_count += 1

    # Görüntü adını dosya yolundan çıkarma
    image_name = test_image_path.split("\\")[-1]

    # Sonuç görselini output_images listesine ekleme
    output_images.append(output_img)

    # Orijinal görüntü, etiket ve çıktı görselleştirme
    plt.subplot(len(test_image_paths), 3, idx * 3 + 1)
    plt.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))
    plt.title(f"Original - {image_name}")
    plt.axis('off')

    plt.subplot(len(test_image_paths), 3, idx * 3 + 2)
    plt.imshow(cv2.cvtColor(label_image, cv2.COLOR_BGR2RGB))
    plt.title(f"Label - {image_name}")
    plt.axis('off')

    plt.subplot(len(test_image_paths), 3, idx * 3 + 3)
    plt.imshow(cv2.cvtColor(output_img, cv2.COLOR_BGR2RGB))
    plt.title(f"Output_test_img{idx + 6} (Eşleşme Sayısı: {matching_coords_count})")
    plt.axis('off')

plt.tight_layout()
plt.show()

# Sonuç görsellerini bir değişkende tutma
final_output_image = output_images[-1]

#MORFOLOJİK DÜZELTMELER

import cv2
import numpy as np
import matplotlib.pyplot as plt


if isinstance(final_output_image, np.ndarray):
    if len(final_output_image.shape) == 3:
        image = cv2.cvtColor(final_output_image, cv2.COLOR_BGR2GRAY)
    else:
        image = final_output_image
else:
    image = cv2.imread(final_output_image, cv2.IMREAD_GRAYSCALE)

if image is None:
    raise ValueError("Görüntü yüklenemedi.")

# --- Ayarlanabilir Eşik Değerleri ---
threshold_value_initial = 20
blur_kernel_size = 5
morph_kernel_size = 5
dilate_iterations =2
distance_threshold_value = 20


_, binary_image = cv2.threshold(image, threshold_value_initial, 255, cv2.THRESH_BINARY)


blurred_image = cv2.GaussianBlur(binary_image, (blur_kernel_size, blur_kernel_size), 0)

#Morfolojik İşlemler
kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (morph_kernel_size, morph_kernel_size))
morphed_image = cv2.morphologyEx(blurred_image, cv2.MORPH_CLOSE, kernel)

#Dilatasyon ile Noktaları Birleştirme
dilated_image = cv2.dilate(morphed_image, kernel, iterations=dilate_iterations)

#Distance Transform
distance_transform = cv2.distanceTransform(dilated_image, cv2.DIST_L2, 5)
_, distance_thresholded = cv2.threshold(distance_transform, distance_threshold_value, 255, cv2.THRESH_BINARY)
distance_thresholded = distance_thresholded.astype(np.uint8)

#Bağlantılı Bileşen Analizi
num_labels, labels_im = cv2.connectedComponents(distance_thresholded)

#Konturları Bulma ve Poligon Oluşturma
contours, _ = cv2.findContours(dilated_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
polygon_image = np.zeros_like(dilated_image)

for contour in contours:

    cv2.fillPoly(polygon_image, [contour], 255)

# Poligon içindeki alanları beyaz yap
final_image = cv2.bitwise_or(dilated_image, polygon_image)

#Sonuçları Görselleştirme
plt.figure(figsize=(18, 12))

# Orijinal Görüntü
plt.subplot(3, 3, 1)
plt.imshow(image, cmap='gray')
plt.title("Original Image")
plt.axis('off')

# İlk Eşiklenmiş Görüntü
plt.subplot(3, 3, 2)
plt.imshow(binary_image, cmap='gray')
plt.title(f"Binary Image (Threshold: {threshold_value_initial})")
plt.axis('off')

# Bulanıklaştırılmış Görüntü
plt.subplot(3, 3, 3)
plt.imshow(blurred_image, cmap='gray')
plt.title(f"Blurred Image (Kernel: {blur_kernel_size}x{blur_kernel_size})")
plt.axis('off')

# Morfolojik İşlemler
plt.subplot(3, 3, 4)
plt.imshow(morphed_image, cmap='gray')
plt.title(f"Morphed Image (Kernel: {morph_kernel_size}x{morph_kernel_size})")
plt.axis('off')

# Dilatasyon Sonrası Görüntü
plt.subplot(3, 3, 5)
plt.imshow(dilated_image, cmap='gray')
plt.title(f"Dilated Image (Iterations: {dilate_iterations})")
plt.axis('off')

# Distance Transform Sonrası Görüntü
plt.subplot(3, 3, 6)
plt.imshow(distance_transform, cmap='hot')
plt.title("Distance Transform")
plt.axis('off')

# Distance Threshold Sonrası Görüntü
plt.subplot(3, 3, 7)
plt.imshow(distance_thresholded, cmap='gray')
plt.title(f"Distance Thresholded (Threshold: {distance_threshold_value})")
plt.axis('off')

# Poligon İçinde Beyaz Alanlar
plt.subplot(3, 3, 8)
plt.imshow(polygon_image, cmap='gray')
plt.title("Polygon Filled Image")
plt.axis('off')

# Final Görüntü
plt.subplot(3, 3, 9)
plt.imshow(final_image, cmap='gray')
plt.title("Final Image")
plt.axis('off')

plt.tight_layout()
plt.show()

#IoU HESAPLIYORUZ

import cv2
import numpy as np
import matplotlib.pyplot as plt

# IoU hesapla
def calculate_iou(predicted_image, label_image):
    _, pred_binary = cv2.threshold(predicted_image, 127, 255, cv2.THRESH_BINARY)
    _, label_binary = cv2.threshold(label_image, 127, 255, cv2.THRESH_BINARY)

    # Kesişim ve birleşim
    intersection = np.logical_and(pred_binary > 0, label_binary > 0).sum()
    union = np.logical_or(pred_binary > 0, label_binary > 0).sum()

    # IoU hesaplama
    iou = intersection / union if union != 0 else 0
    return iou

# final_image
if final_image is None:
    print("Final yüklenemedi!")
else:

    _, final_binary = cv2.threshold(final_image, 127, 255, cv2.THRESH_BINARY)

# Etiket görüntüsünü yükleme ve kontrol etme
label_image = cv2.imread(r"C:\Users\yakup\OneDrive\Desktop\label_demirci\image (9).png", cv2.IMREAD_GRAYSCALE)
if label_image is None:
    print("Görüntü yüklenemedi!")
else:
    # Etiket görüntüsünü ikili hale getirme
    _, label_binary = cv2.threshold(label_image, 127, 255, cv2.THRESH_BINARY)


# IoU
if final_image is not None and label_image is not None:
    iou = calculate_iou(final_binary, label_binary)
    print(f"Final Image IoU: {iou:.4f}")

    # IoU Grafik
    plt.figure(figsize=(2, 6))
    plt.bar(["Final Image"], [iou], color='skyblue', edgecolor='black')
    plt.axhline(iou, color='red', linestyle='--', label=f"IoU = {iou:.4f}")
    plt.xlabel('Görüntüler')
    plt.ylabel('IoU Değeri')
    plt.title('IoU Değeri')
    plt.legend()
    plt.tight_layout()
    plt.show()







